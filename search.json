[
  {
    "objectID": "interactive/teal.html",
    "href": "interactive/teal.html",
    "title": "teal applications",
    "section": "",
    "text": "teal is a Shiny-based framework that streamlines the process of creating an application for clinical trials data. App developers are required to specify input data as well as analysis modules choosing from a wide range of available modules or creating their own module.\nThe main features of a teal app include:\n\nfilter panel allowing to filtering input data for e.g. subgroup analysis\nreproducibility code for each output\nreporter to export the results\nand more…\n\nPlease visit teal package webpage to see more. Please also see teal.gallery for more examples.\nBelow you can find a few examples using WebR (via Shinylive). This will run applications directly in the browser without any server in the background. You are free to change the source code and the application will refresh accordingly.\n\nA simple example for non-clinical trials data with custom module\n#| standalone: true\n#| viewerHeight: 800\n#| components: [viewer, editor]\n#| layout: vertical\nlibrary(teal)\n\napp &lt;- init(\n  data = teal_data(iris = iris),\n  modules = list(\n    module(\n      label = \"iris histogram\",\n      server = function(input, output, session, data) {\n        updateSelectInput(session = session,\n                          inputId =  \"var\",\n                          choices = names(data()[[\"iris\"]])[1:4])\n\n        output$hist &lt;- renderPlot({\n          req(input$var)\n          hist(\n            x = data()[[\"iris\"]][[input$var]],\n            main = sprintf(\"Histogram of %s\", input$var),\n            xlab = input$var\n          )\n        })\n      },\n      ui = function(id) {\n        ns &lt;- NS(id)\n        list(\n          selectInput(inputId = ns(\"var\"),\n                      label =  \"Column name\",\n                      choices = NULL),\n          plotOutput(outputId = ns(\"hist\"))\n        )\n      }\n    )\n  )\n)\n\nshinyApp(app$ui, app$server)\n\n\nA simple example for clinical trials data with custom module\n#| standalone: true\n#| viewerHeight: 800\n#| components: [viewer, editor]\n#| layout: vertical\nlibrary(teal)\nlibrary(tern)\nlibrary(dplyr)\n\nadsl &lt;- tern_ex_adsl %&gt;%\n  df_explicit_na()\n\napp &lt;- init(\n  data = cdisc_data(\n    adsl = adsl\n  ),\n  modules = list(\n    module(\n      \"demographic table\",\n      server = function(input, output, session, data) {\n        output$table &lt;- renderUI({\n          validate(need(input$vars, \"Please select summary variables\"))\n\n          lyt &lt;- basic_table(show_colcounts = TRUE) %&gt;%\n            split_cols_by(var = \"ACTARM\") %&gt;%\n            add_overall_col(\"All Patients\") %&gt;%\n            analyze_vars(\n                vars = input$vars,\n                var_labels = var_labels(data()[[\"adsl\"]][, input$vars])\n            )\n\n            result &lt;- build_table(lyt, adsl)\n\n            as_html(result)\n        })\n      },\n      ui = function(id) {\n        ns &lt;- NS(id)\n        list(\n          shiny::selectInput(\n            ns(\"vars\"),\n            \"Summary variables\",\n            choices = c(\"AGE\", \"SEX\", \"RACE\", \"STRATA1\", \"STRATA2\", \"BMRKR1\", \"BMRKR2\"),\n            selected = c(\"AGE\", \"SEX\", \"RACE\"),\n            multiple = TRUE\n          ),\n          uiOutput(ns(\"table\"))\n        )\n      }\n    )\n  )\n)\n\nshinyApp(app$ui, app$server)\n\n\nUse pre-created modules\n#| standalone: true\n#| viewerHeight: 800\n#| components: [viewer, editor]\n#| layout: vertical\nlibrary(teal.modules.clinical)\nlibrary(teal.modules.general)\nlibrary(sparkline)\nlibrary(magrittr)\n\ndata &lt;- cdisc_data() %&gt;%\n  within({\n    ADSL &lt;- tmc_ex_adsl\n    ADTTE &lt;- tmc_ex_adtte\n  })\ndatanames(data) &lt;- c(\"ADSL\", \"ADTTE\")\njoin_keys(data) &lt;- default_cdisc_join_keys[datanames(data)]\n\nADSL &lt;- data[[\"ADSL\"]]\nADTTE &lt;- data[[\"ADTTE\"]]\n\narm_vars &lt;- c(\"ARM\", \"ARMCD\", \"ACTARMCD\")\nstrata_vars &lt;- c(\"STRATA1\", \"STRATA2\")\nfacet_vars &lt;- c(\"BMRKR2\", \"SEX\", \"COUNTRY\")\n\ncs_arm_var &lt;- choices_selected(\n  choices = variable_choices(ADSL, subset = arm_vars),\n  selected = \"ARM\"\n)\n\ncs_strata_var &lt;- choices_selected(\n  choices = variable_choices(ADSL, subset = strata_vars),\n  selected = \"STRATA1\"\n)\n\ncs_facet_var &lt;- choices_selected(\n  choices = variable_choices(ADSL, subset = facet_vars),\n  selected = \"BMRKR2\"\n)\n\ncs_paramcd_tte &lt;- choices_selected(\n  choices = value_choices(ADTTE, \"PARAMCD\", \"PARAM\"),\n  selected = \"OS\"\n)\n\ndate_vars_asl &lt;- names(ADSL)[vapply(ADSL, function(x) inherits(x, c(\"Date\", \"POSIXct\", \"POSIXlt\")), logical(1))]\ndemog_vars_asl &lt;- names(ADSL)[!(names(ADSL) %in% c(\"USUBJID\", \"STUDYID\", date_vars_asl))]\n\narm_ref_comp &lt;- list(\n  ACTARMCD = list(\n    ref = \"ARM B\",\n    comp = c(\"ARM A\", \"ARM C\")\n  ),\n  ARM = list(\n    ref = \"B: Placebo\",\n    comp = c(\"A: Drug X\", \"C: Combination\")\n  )\n)\n\n\napp &lt;- init(\n  data = data,\n  modules = list(\n    tm_data_table(\"Data Table\"),\n    tm_variable_browser(\"Variable Browser\"),\n    tm_t_summary(\n      label = \"Demographic Table\",\n      dataname = \"ADSL\",\n      arm_var = cs_arm_var,\n      summarize_vars = choices_selected(\n        choices = variable_choices(ADSL, demog_vars_asl),\n        selected = c(\"SEX\", \"AGE\", \"RACE\")\n      )\n    ),\n    tm_g_km(\n      label = \"Kaplan Meier Plot\",\n      dataname = \"ADTTE\",\n      arm_var = cs_arm_var,\n      arm_ref_comp = arm_ref_comp,\n      paramcd = cs_paramcd_tte,\n      facet_var = cs_facet_var,\n      strata_var = cs_strata_var,\n      plot_height = c(1800L, 200L, 4000L)\n    ),\n    tm_t_tte(\n      label = \"Time To Event Table\",\n      dataname = \"ADTTE\",\n      arm_var = cs_arm_var,\n      arm_ref_comp = arm_ref_comp,\n      paramcd = cs_paramcd_tte,\n      strata_var = cs_strata_var,\n      time_points = choices_selected(c(182, 243), 182),\n      event_desc_var = choices_selected(\n        variable_choices(ADTTE, \"EVNTDESC\"),\n        \"EVNTDESC\",\n        fixed = TRUE\n      )\n    )\n  )\n)\n\nshinyApp(app$ui, app$server)",
    "crumbs": [
      "Interactive",
      "`teal` applications"
    ]
  },
  {
    "objectID": "logging/logging.html",
    "href": "logging/logging.html",
    "title": "The Difference Between logr, logrx, and whirl",
    "section": "",
    "text": "The logr package for R aims to provide a straightforward logging system tailored for everyday users, such as statisticians and educators, emphasizing simplicity in recording program execution. In contrast, logrx offers an advanced logging mechanism designed specifically for clinical reporting, featuring easy traceability and reproducibility of R script executions with capabilities suited for more technical users. whirl differs in that the package provides functionalities for executing scripts in batch and simultaneously getting a log from the individual executions. In contrast the other two logging packages, the default logs are HTML reports making it easier to read, and they include the results printed in the programs being logged.\nAll three packages are used for keeping a record of what happens when R scripts are run, but they differ in what they offer and who they’re for. When choosing between them, you should consider what you need for your particular situation.\n\nExecution\nEach package differs notably in the approach to generating a log file. The logr package adopts a method similar to SAS, where the log is manually constructed at intermediary steps within the R script. Conversely, the logrx package allows for the creation of a log file through a single command from the R terminal, offering added compatibility for command line submission. whirl also provides a single function to create log files, and it should be noted that the execution is done through Quarto, which enables the HTML reports, but also make it more heavier on external dependencies.\n\nlogrlogrxwhirl\n\n\n\n# file: script.R\nlibrary(dplyr)\nlibrary(logr)\n\nfile_path &lt;- \"script.log\"\nlog_file &lt;- log_open(file_path)\n\nlog_print(\"Analyzing Fuel Efficiency Trends in Cars\")\n\naverage_mpg &lt;- mtcars %&gt;%\n  group_by(cyl) %&gt;%\n  summarise(average_mpg = mean(mpg, na.rm = TRUE))\n\nlog_print(average_mpg)\n\nmodel &lt;- lm(mpg ~ wt, data = mtcars)\nsummary(model)\n\nlog_print(model)\n\nlog_close() # log file path: log/script.log\n\n\n\n=========================================================================\nLog Path: ./log/script.log\nWorking Directory: /Users/davidblair/My Drive/Appsilon/Work Projects/examples\nUser Name: davidblair\nR Version: 4.3.3 (2024-02-29)\nMachine: Davids-Air.localdomain arm64\nOperating System: Darwin 23.4.0 Darwin Kernel Version 23.4.0: Fri Mar 15 00:12:41 PDT 2024; root:xnu-10063.101.17~1/RELEASE_ARM64_T8103\nBase Packages: stats graphics grDevices utils datasets methods base\nOther Packages: dplyr_1.1.4 logr_1.3.6\nLog Start Time: 2024-04-08 13:25:53.22436\n=========================================================================\n\nAnalyzing Fuel Efficiency Trends in Cars\n\nNOTE: Log Print Time:  2024-04-08 13:25:53.226347\nNOTE: Elapsed Time: 0.00139403343200684 secs\n\n# A tibble: 3 × 2\n    cyl average_mpg\n  &lt;dbl&gt;       &lt;dbl&gt;\n1     4        26.7\n2     6        19.7\n3     8        15.1\n\nNOTE: Data frame has 3 rows and 2 columns.\n\nNOTE: Log Print Time:  2024-04-08 13:25:53.254377\nNOTE: Elapsed Time: 0.0280299186706543 secs\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt\n     37.285       -5.344\n\n\nNOTE: Log Print Time:  2024-04-08 13:25:53.267483\nNOTE: Elapsed Time: 0.013106107711792 secs\n\n=========================================================================\nLog End Time: 2024-04-08 13:25:53.286294\nLog Elapsed Time: 0 00:00:00\n=========================================================================\n\n\n\nFrom the R terminal:\n\nlogrx::axecute(\"script.R\")\n\nFrom the Command Line:\n\nRscript -e \"logrx::axecute('script.R')\"\n\n\n--------------------------------------------------------------------------------\n-                                logrx Metadata                                -\n--------------------------------------------------------------------------------\nThis log was generated using logrx 0.3.0\nlogrx package version: 0.3.0\nlogrx build: CRAN (R 4.3.1)\nlogrx link to repository: https://github.com/pharmaverse/logrx\n--------------------------------------------------------------------------------\n-                          User and File Information                           -\n--------------------------------------------------------------------------------\nUser: davidblair\nFile Name: script.R\nFile Path: /Users/davidblair/My Drive/Appsilon/Work Projects/examples/logging\nFile HashSum: 76f9dd029df25ba4f65de72631fac248fa30d7d5\n--------------------------------------------------------------------------------\n-                             Session Information                              -\n--------------------------------------------------------------------------------\n─ Session info ─────────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.3 (2024-02-29)\n os       macOS Sonoma 14.4.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2024-04-08\n pandoc   NA\n\n─ Packages ─────────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n   cachem        1.0.8   2023-05-01 [1] CRAN (R 4.3.0)\n   callr         3.7.6   2024-03-25 [1] CRAN (R 4.3.1)\n   cli           3.6.2   2023-12-11 [1] CRAN (R 4.3.1)\n   common        1.1.2   2024-03-05 [1] CRAN (R 4.3.1)\n   curl          5.2.1   2024-03-01 [1] CRAN (R 4.3.1)\n   desc          1.4.3   2023-12-10 [1] CRAN (R 4.3.1)\n   devtools      2.4.5   2022-10-11 [1] CRAN (R 4.3.0)\n   digest        0.6.35  2024-03-11 [1] CRAN (R 4.3.1)\n   dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.3.1)\n   ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.3.0)\n   fansi         1.0.6   2023-12-08 [1] CRAN (R 4.3.1)\n   fastmap       1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n   fs            1.6.3   2023-07-20 [1] CRAN (R 4.3.0)\n   generics      0.1.3   2022-07-05 [1] CRAN (R 4.3.0)\n   glue          1.7.0   2024-01-09 [1] CRAN (R 4.3.1)\n   htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.3.1)\n   htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.3.1)\n   httpuv        1.6.15  2024-03-26 [1] CRAN (R 4.3.1)\n   later         1.3.2   2023-12-06 [1] CRAN (R 4.3.1)\n   lifecycle     1.0.4   2023-11-07 [1] CRAN (R 4.3.1)\n V logr        * 1.3.7   2024-02-24 [1] CRAN (R 4.3.1) (on disk 1.3.6)\n   logrx         0.3.0   2023-10-17 [1] CRAN (R 4.3.1)\n   magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.3.0)\n   memoise       2.0.1   2021-11-26 [1] CRAN (R 4.3.0)\n   mime          0.12    2021-09-28 [1] CRAN (R 4.3.0)\n   miniUI        0.1.1.1 2018-05-18 [1] CRAN (R 4.3.0)\n   pillar        1.9.0   2023-03-22 [1] CRAN (R 4.3.0)\n   pkgbuild      1.4.4   2024-03-17 [1] CRAN (R 4.3.1)\n   pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.3.0)\n   pkgload       1.3.4   2024-01-16 [1] CRAN (R 4.3.1)\n   processx      3.8.4   2024-03-16 [1] CRAN (R 4.3.1)\n   profvis       0.3.8   2023-05-02 [1] CRAN (R 4.3.0)\n   promises      1.2.1   2023-08-10 [1] CRAN (R 4.3.0)\n   ps            1.7.6   2024-01-18 [1] CRAN (R 4.3.1)\n   purrr         1.0.2   2023-08-10 [1] CRAN (R 4.3.0)\n   R6            2.5.1   2021-08-19 [1] CRAN (R 4.3.0)\n   Rcpp          1.0.12  2024-01-09 [1] CRAN (R 4.3.1)\n   remotes       2.4.2.1 2023-07-18 [1] CRAN (R 4.3.0)\n   rlang         1.1.3   2024-01-10 [1] CRAN (R 4.3.1)\n   rstudioapi    0.15.0  2023-07-07 [1] CRAN (R 4.3.0)\n   sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n   shiny         1.8.1.1 2024-04-02 [1] CRAN (R 4.3.1)\n   stringi       1.8.3   2023-12-11 [1] CRAN (R 4.3.1)\n   stringr       1.5.1   2023-11-14 [1] CRAN (R 4.3.1)\n   tibble        3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n   tidyr         1.3.1   2024-01-24 [1] CRAN (R 4.3.1)\n   tidyselect    1.2.1   2024-03-11 [1] CRAN (R 4.3.1)\n   urlchecker    1.0.1   2021-11-30 [1] CRAN (R 4.3.0)\n   usethis       2.2.3   2024-02-19 [1] CRAN (R 4.3.1)\n   utf8          1.2.4   2023-10-22 [1] CRAN (R 4.3.1)\n   vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.3.1)\n   waiter        0.2.5   2022-01-03 [1] CRAN (R 4.3.0)\n   withr         3.0.0   2024-01-16 [1] CRAN (R 4.3.1)\n   xtable        1.8-4   2019-04-21 [1] CRAN (R 4.3.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n\n V ── Loaded and on-disk version mismatch.\n\n─ External software ────────────────────────────────────────────────────────────\n setting        value\n cairo\n cairoFT\n pango\n png\n jpeg\n tiff\n tcl\n curl           8.4.0\n zlib           1.2.12\n bzlib          1.0.8, 13-Jul-2019\n xz             5.4.4\n PCRE           10.42 2022-12-11\n ICU            74.1\n TRE            TRE 0.8.0 R_fixes (BSD)\n iconv          Apple or GNU libiconv 1.11\n readline       5.2\n\n      BLAS           /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib\n\n      lapack         /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib\n lapack_version 3.11.0\n\n─ Python configuration ─────────────────────────────────────────────────────────\n Python is not available\n\n────────────────────────────────────────────────────────────────────────────────\n--------------------------------------------------------------------------------\n-                               Masked Functions                               -\n--------------------------------------------------------------------------------\nfunction `filter` from {package:stats} by package:dplyr\nfunction `lag` from {package:stats} by package:dplyr\nfunction `intersect` from {package:base} by package:dplyr\nfunction `setdiff` from {package:base} by package:dplyr\nfunction `setequal` from {package:base} by package:dplyr\nfunction `union` from {package:base} by package:dplyr\nfunction `plot` from {package:base} by package:graphics\nfunction `body&lt;-` from {package:base} by package:methods\nfunction `kronecker` from {package:base} by package:methods\n--------------------------------------------------------------------------------\n-                          Used Package and Functions                          -\n--------------------------------------------------------------------------------\n{package:base} library, mean, summary\n{package:dplyr} %&gt;%, group_by, summarise\n{package:stats} lm\n--------------------------------------------------------------------------------\n-                         Program Run Time Information                         -\n--------------------------------------------------------------------------------\nStart time: 2024-04-08 14:15:26 BST\nEnd time: 2024-04-08 14:15:26 BST\nRun time: 0 seconds\n--------------------------------------------------------------------------------\n-                             Errors and Warnings                              -\n--------------------------------------------------------------------------------\nErrors:\n\n\nWarnings:\n\n--------------------------------------------------------------------------------\n-                         Messages, Output, and Result                         -\n--------------------------------------------------------------------------------\nMessages:\n\nOutput:\n\n\nResult:\n\n    Call:\n    lm(formula = mpg ~ wt, data = mtcars)\n\n    Residuals:\n        Min      1Q  Median      3Q     Max\n    -4.5432 -2.3647 -0.1252  1.4096  6.8727\n\n    Coefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n    (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\n    wt           -5.3445     0.5591  -9.559 1.29e-10 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    Residual standard error: 3.046 on 30 degrees of freedom\n    Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446\n    F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n--------------------------------------------------------------------------------\n-                               Log Output File                                -\n--------------------------------------------------------------------------------\nLog name: script.log\nLog path: /Users/davidblair/My Drive/Appsilon/Work Projects/examples/logging\n\n\n\nUse whirl::run() to execute scripts and create logs:\n\nwhirl::run(\"logging/script.R\", summary_file = NULL)\n\n✔ script.R: Completed succesfully. See log html.\n\n\nWhen running scripts the overall status is reported in the console. In this example we are choosing not to create a summary log, since we are only running a single script.\nThe HTML log is created with the name script_log.html and can be viewed below:\n\n\n\n\n\n\nInformation in the Log\nThe logrx package offers more detailed output compared to logr, as outlined in the following table. A key distinction is that logrx automatically logs code output. In logr, the user has control over what does or does not get logged. The user can specify which variables, objects, or datasets to send to the log. If the ‘autolog’ feature is activated, output from dplyr and sassy functions are logged automatically.\n\n\n\n\nlogr\nlogrx\nwhirl\n\n\n\n\nLog Path\n✔\n✔\n✔\n\n\nWorking Directory\n✔\n✔\n\n\n\nUser Name\n✔\n✔\n\n\n\nR Version\n✔\n✔\n✔\n\n\nMachine\n✔\n✔\n✔\n\n\nOperating System\n✔\n✔\n✔\n\n\nBase Packages\n✔\n✔\n\n\n\nOther Packages\n✔\n✔\n✔\n\n\nLog Start Time\n✔\n✔\n\n\n\nLog End Time.\n✔\n✔\n✔\n\n\nElapsed Time\n✔\n✔\n\n\n\nWarnings and Errors\n✔\n✔\n✔\n\n\nFile Hash\n\n✔\n\n\n\nPackage Dependencies\n\n✔\n✔\n\n\nExternal Software\n\n✔\n(✔)*\n\n\nMasked Functions\n\n✔\n\n\n\nRenv status\n\n\n✔\n\n\nSummary status\n\n\n✔\n\n\nInput/output files\n\n\n✔\n\n\n\n\nOnly selected external software, such as Pandoc, Quarto, and Python versions.\n\n\n\nLinting\nThe logrx tool enables the inclusion of lintR output within log messages (line 146 - 165 below). To utilize this feature, configure the log.rx.lint global option with a selection of lint rules. A comprehensive list of available rules can be accessed here.\n\noptions(log.rx.lint = list(\n  lintr::line_length_linter(20)\n))\n\nlibrary(logrx)\naxecute(\"script.R\")\n\n\n--------------------------------------------------------------------------------\n-                                logrx Metadata                                -\n--------------------------------------------------------------------------------\nThis log was generated using logrx 0.3.0\nlogrx package version: 0.3.0\nlogrx build: CRAN (R 4.3.1)\nlogrx link to repository: https://github.com/pharmaverse/logrx\n--------------------------------------------------------------------------------\n-                          User and File Information                           -\n--------------------------------------------------------------------------------\nUser: davidblair\nFile Name: script.R\nFile Path: /Users/davidblair/My Drive/Appsilon/Work Projects/examples/logging\nFile HashSum: 76f9dd029df25ba4f65de72631fac248fa30d7d5\n--------------------------------------------------------------------------------\n-                             Session Information                              -\n--------------------------------------------------------------------------------\n─ Session info ─────────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.3 (2024-02-29)\n os       macOS Sonoma 14.4.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2024-04-08\n pandoc   NA\n\n─ Packages ─────────────────────────────────────────────────────────────────────\n ! package      * version date (UTC) lib source\n   backports      1.4.1   2021-12-13 [1] CRAN (R 4.3.0)\n   cachem         1.0.8   2023-05-01 [1] CRAN (R 4.3.0)\n   callr          3.7.6   2024-03-25 [1] CRAN (R 4.3.1)\n   cli            3.6.2   2023-12-11 [1] CRAN (R 4.3.1)\n   common         1.1.2   2024-03-05 [1] CRAN (R 4.3.1)\n   crayon         1.5.2   2022-09-29 [1] CRAN (R 4.3.0)\n   curl           5.2.1   2024-03-01 [1] CRAN (R 4.3.1)\n   cyclocomp      1.1.1   2023-08-30 [1] CRAN (R 4.3.0)\n   desc           1.4.3   2023-12-10 [1] CRAN (R 4.3.1)\n   devtools       2.4.5   2022-10-11 [1] CRAN (R 4.3.0)\n   digest         0.6.35  2024-03-11 [1] CRAN (R 4.3.1)\n   dplyr        * 1.1.4   2023-11-17 [1] CRAN (R 4.3.1)\n   ellipsis       0.3.2   2021-04-29 [1] CRAN (R 4.3.0)\n   fansi          1.0.6   2023-12-08 [1] CRAN (R 4.3.1)\n   fastmap        1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n   fs             1.6.3   2023-07-20 [1] CRAN (R 4.3.0)\n   generics       0.1.3   2022-07-05 [1] CRAN (R 4.3.0)\n   glue           1.7.0   2024-01-09 [1] CRAN (R 4.3.1)\n   htmltools      0.5.8.1 2024-04-04 [1] CRAN (R 4.3.1)\n   htmlwidgets    1.6.4   2023-12-06 [1] CRAN (R 4.3.1)\n   httpuv         1.6.15  2024-03-26 [1] CRAN (R 4.3.1)\n   later          1.3.2   2023-12-06 [1] CRAN (R 4.3.1)\n   lazyeval       0.2.2   2019-03-15 [1] CRAN (R 4.3.0)\n   lifecycle      1.0.4   2023-11-07 [1] CRAN (R 4.3.1)\n   lintr          3.1.2   2024-03-25 [1] CRAN (R 4.3.1)\n V logr         * 1.3.7   2024-02-24 [1] CRAN (R 4.3.1) (on disk 1.3.6)\n   logrx        * 0.3.0   2023-10-17 [1] CRAN (R 4.3.1)\n   magrittr       2.0.3   2022-03-30 [1] CRAN (R 4.3.0)\n   memoise        2.0.1   2021-11-26 [1] CRAN (R 4.3.0)\n   mime           0.12    2021-09-28 [1] CRAN (R 4.3.0)\n   miniUI         0.1.1.1 2018-05-18 [1] CRAN (R 4.3.0)\n   pillar         1.9.0   2023-03-22 [1] CRAN (R 4.3.0)\n   pkgbuild       1.4.4   2024-03-17 [1] CRAN (R 4.3.1)\n   pkgconfig      2.0.3   2019-09-22 [1] CRAN (R 4.3.0)\n   pkgload        1.3.4   2024-01-16 [1] CRAN (R 4.3.1)\n   processx       3.8.4   2024-03-16 [1] CRAN (R 4.3.1)\n   profvis        0.3.8   2023-05-02 [1] CRAN (R 4.3.0)\n   promises       1.2.1   2023-08-10 [1] CRAN (R 4.3.0)\n   ps             1.7.6   2024-01-18 [1] CRAN (R 4.3.1)\n   purrr          1.0.2   2023-08-10 [1] CRAN (R 4.3.0)\n   R6             2.5.1   2021-08-19 [1] CRAN (R 4.3.0)\n   Rcpp           1.0.12  2024-01-09 [1] CRAN (R 4.3.1)\n   remotes        2.4.2.1 2023-07-18 [1] CRAN (R 4.3.0)\n   rex            1.2.1   2021-11-26 [1] CRAN (R 4.3.0)\n   rlang          1.1.3   2024-01-10 [1] CRAN (R 4.3.1)\n   rstudioapi     0.15.0  2023-07-07 [1] CRAN (R 4.3.0)\n   sessioninfo    1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n   shiny          1.8.1.1 2024-04-02 [1] CRAN (R 4.3.1)\n   stringi        1.8.3   2023-12-11 [1] CRAN (R 4.3.1)\n   stringr        1.5.1   2023-11-14 [1] CRAN (R 4.3.1)\n   tibble         3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n   tidyr          1.3.1   2024-01-24 [1] CRAN (R 4.3.1)\n   tidyselect     1.2.1   2024-03-11 [1] CRAN (R 4.3.1)\n   urlchecker     1.0.1   2021-11-30 [1] CRAN (R 4.3.0)\n   usethis        2.2.3   2024-02-19 [1] CRAN (R 4.3.1)\n   utf8           1.2.4   2023-10-22 [1] CRAN (R 4.3.1)\n   vctrs          0.6.5   2023-12-01 [1] CRAN (R 4.3.1)\n   waiter         0.2.5   2022-01-03 [1] CRAN (R 4.3.0)\n   withr          3.0.0   2024-01-16 [1] CRAN (R 4.3.1)\n   xml2           1.3.6   2023-12-04 [1] CRAN (R 4.3.1)\n   xmlparsedata   1.0.5   2021-03-06 [1] CRAN (R 4.3.0)\n   xtable         1.8-4   2019-04-21 [1] CRAN (R 4.3.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n\n V ── Loaded and on-disk version mismatch.\n\n─ External software ────────────────────────────────────────────────────────────\n setting        value\n cairo\n cairoFT\n pango\n png\n jpeg\n tiff\n tcl\n curl           8.4.0\n zlib           1.2.12\n bzlib          1.0.8, 13-Jul-2019\n xz             5.4.4\n PCRE           10.42 2022-12-11\n ICU            74.1\n TRE            TRE 0.8.0 R_fixes (BSD)\n iconv          Apple or GNU libiconv 1.11\n readline       5.2\n\n      BLAS           /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib\n\n      lapack         /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib\n lapack_version 3.11.0\n\n─ Python configuration ─────────────────────────────────────────────────────────\n Python is not available\n\n────────────────────────────────────────────────────────────────────────────────\n--------------------------------------------------------------------------------\n-                               Masked Functions                               -\n--------------------------------------------------------------------------------\nfunction `filter` from {package:stats} by package:dplyr\nfunction `lag` from {package:stats} by package:dplyr\nfunction `intersect` from {package:base} by package:dplyr\nfunction `setdiff` from {package:base} by package:dplyr\nfunction `setequal` from {package:base} by package:dplyr\nfunction `union` from {package:base} by package:dplyr\nfunction `plot` from {package:base} by package:graphics\nfunction `body&lt;-` from {package:base} by package:methods\nfunction `kronecker` from {package:base} by package:methods\n--------------------------------------------------------------------------------\n-                          Used Package and Functions                          -\n--------------------------------------------------------------------------------\n{package:base} library, mean, summary\n{package:dplyr} %&gt;%, group_by, summarise\n{package:stats} lm\n--------------------------------------------------------------------------------\n-                                Linter Results                                -\n--------------------------------------------------------------------------------\nLine 1 [line_length_linter] Lines should not be more than 20 characters. This\nline is 22 characters.\n\nLine 5 [line_length_linter] Lines should not be more than 20 characters. This\nline is 25 characters.\n\nLine 7 [line_length_linter] Lines should not be more than 20 characters. This\nline is 25 characters.\n\nLine 9 [line_length_linter] Lines should not be more than 20 characters. This\nline is 50 characters.\n\nLine 11 [line_length_linter] Lines should not be more than 20 characters.\nThis line is 36 characters.\n\nLine 14 [line_length_linter] Lines should not be more than 20 characters.\nThis line is 27 characters.\n--------------------------------------------------------------------------------\n-                         Program Run Time Information                         -\n--------------------------------------------------------------------------------\nStart time: 2024-04-08 15:26:12 BST\nEnd time: 2024-04-08 15:26:12 BST\nRun time: 0 seconds\n--------------------------------------------------------------------------------\n-                             Errors and Warnings                              -\n--------------------------------------------------------------------------------\nErrors:\n\n\nWarnings:\n\n--------------------------------------------------------------------------------\n-                         Messages, Output, and Result                         -\n--------------------------------------------------------------------------------\nMessages:\n\nOutput:\n\n\nResult:\n\n    Call:\n    lm(formula = mpg ~ wt, data = mtcars)\n\n    Residuals:\n        Min      1Q  Median      3Q     Max\n    -4.5432 -2.3647 -0.1252  1.4096  6.8727\n\n    Coefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n    (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\n    wt           -5.3445     0.5591  -9.559 1.29e-10 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    Residual standard error: 3.046 on 30 degrees of freedom\n    Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446\n    F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n--------------------------------------------------------------------------------\n-                               Log Output File                                -\n--------------------------------------------------------------------------------\nLog name: script.log\nLog path: /Users/davidblair/My Drive/Appsilon/Work Projects/examples/logging\n\n\n\nGlobal Options\nWe’ve previously discussed the global options in the logrx package that enable the inclusion of lintr output in the log. There are several key differences between the global options in logrx and whirl, and those in logr. The options in logr primarily focus on managing script output, whereas those in logrx and whirl influence the scope of information included, regardless of the script output.\n\nlogrlogrxwhirl\n\n\n\nlogr.autolog: Enables automatic logging for various dplyr and tidyr functions.\nlogr.compact: Removes any blanks spaces between log entries.\nlogr.traceback: Includes the full traceback for errors.\nlogr.warnings: Retrieves warnings encountered during log file generation, used with getOption.\nlogr.on: Controls whether the logr log is active.\nlogr.notes: Includes notes within the log.\n\n\n\n\nlog.rx: A blank log environment for storing log elements during execution.\nlog.rx.exec.env: The execution environment for program code.\nlog.rx.lint: Contains lintr functions/rules for script analysis.\nlog.rx.approved: Specifies the location of approved functions.\n\n\n\nThe most important options to configure whirl is listed below:\n\nwhirl.verbosity_level: Controls the level of information displayed in the console.\nwhirl.n_workers: How many parallel sessions can whirl use when running multiple scripts simultaneously.\nwhirl.track_files: Should reading, writing, and deleting files be tracked? (Only possible on Linux)\nwhirl.check_renv: Should the R environment compliance with your renv lockfile be be checked?\n\nMost are also available as direct arguments in whirl::run(). For the full list and more details see the whirl-options reference.\n\n\n\n\n\nApproved Functions\nlogrx features the ability to designate approved functions, highlighting any functions in the script not on this list within the log file. This enhances traceability of package and function use within a validated environment.\nTo utilize this feature, begin by creating a list of approved functions:\n\napproved_pkgs &lt;- list(\n  base = \"mean\",\n  dplyr = \"All\"\n)\n\nNext, build the approved_pkgs list and save its contents to a file:\n\nlibrary(logrx)\nbuild_approved(approved_pkgs, file = \"approved.rds\")\n\nFinally, assign the file to the global option log.rx.approved. This ensures the analysis is incorporated into the log (refer to lines 140 - 145 below):\n\noptions(log.rv.approved = \"approved.rds\")\n\n\naxecute(\"script.R\")\n\n\n--------------------------------------------------------------------------------\n-                                logrx Metadata                                -\n--------------------------------------------------------------------------------\nThis log was generated using logrx 0.3.0\nlogrx package version: 0.3.0\nlogrx build: CRAN (R 4.3.1)\nlogrx link to repository: https://github.com/pharmaverse/logrx\n--------------------------------------------------------------------------------\n-                          User and File Information                           -\n--------------------------------------------------------------------------------\nUser: davidblair\nFile Name: script.R\nFile Path: /Users/davidblair/My Drive/Appsilon/Work Projects/examples/logging\nFile HashSum: 76f9dd029df25ba4f65de72631fac248fa30d7d5\n--------------------------------------------------------------------------------\n-                             Session Information                              -\n--------------------------------------------------------------------------------\n─ Session info ─────────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.3 (2024-02-29)\n os       macOS Sonoma 14.4.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/London\n date     2024-04-08\n pandoc   NA\n\n─ Packages ─────────────────────────────────────────────────────────────────────\n ! package      * version date (UTC) lib source\n   backports      1.4.1   2021-12-13 [1] CRAN (R 4.3.0)\n   cachem         1.0.8   2023-05-01 [1] CRAN (R 4.3.0)\n   callr          3.7.6   2024-03-25 [1] CRAN (R 4.3.1)\n   cli            3.6.2   2023-12-11 [1] CRAN (R 4.3.1)\n   common         1.1.2   2024-03-05 [1] CRAN (R 4.3.1)\n   crayon         1.5.2   2022-09-29 [1] CRAN (R 4.3.0)\n   curl           5.2.1   2024-03-01 [1] CRAN (R 4.3.1)\n   cyclocomp      1.1.1   2023-08-30 [1] CRAN (R 4.3.0)\n   desc           1.4.3   2023-12-10 [1] CRAN (R 4.3.1)\n   devtools       2.4.5   2022-10-11 [1] CRAN (R 4.3.0)\n   digest         0.6.35  2024-03-11 [1] CRAN (R 4.3.1)\n   dplyr        * 1.1.4   2023-11-17 [1] CRAN (R 4.3.1)\n   ellipsis       0.3.2   2021-04-29 [1] CRAN (R 4.3.0)\n   fansi          1.0.6   2023-12-08 [1] CRAN (R 4.3.1)\n   fastmap        1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n   fs             1.6.3   2023-07-20 [1] CRAN (R 4.3.0)\n   generics       0.1.3   2022-07-05 [1] CRAN (R 4.3.0)\n   glue           1.7.0   2024-01-09 [1] CRAN (R 4.3.1)\n   htmltools      0.5.8.1 2024-04-04 [1] CRAN (R 4.3.1)\n   htmlwidgets    1.6.4   2023-12-06 [1] CRAN (R 4.3.1)\n   httpuv         1.6.15  2024-03-26 [1] CRAN (R 4.3.1)\n   later          1.3.2   2023-12-06 [1] CRAN (R 4.3.1)\n   lazyeval       0.2.2   2019-03-15 [1] CRAN (R 4.3.0)\n   lifecycle      1.0.4   2023-11-07 [1] CRAN (R 4.3.1)\n   lintr          3.1.2   2024-03-25 [1] CRAN (R 4.3.1)\n V logr         * 1.3.7   2024-02-24 [1] CRAN (R 4.3.1) (on disk 1.3.6)\n   logrx        * 0.3.0   2023-10-17 [1] CRAN (R 4.3.1)\n   magrittr       2.0.3   2022-03-30 [1] CRAN (R 4.3.0)\n   memoise        2.0.1   2021-11-26 [1] CRAN (R 4.3.0)\n   mime           0.12    2021-09-28 [1] CRAN (R 4.3.0)\n   miniUI         0.1.1.1 2018-05-18 [1] CRAN (R 4.3.0)\n   pillar         1.9.0   2023-03-22 [1] CRAN (R 4.3.0)\n   pkgbuild       1.4.4   2024-03-17 [1] CRAN (R 4.3.1)\n   pkgconfig      2.0.3   2019-09-22 [1] CRAN (R 4.3.0)\n   pkgload        1.3.4   2024-01-16 [1] CRAN (R 4.3.1)\n   processx       3.8.4   2024-03-16 [1] CRAN (R 4.3.1)\n   profvis        0.3.8   2023-05-02 [1] CRAN (R 4.3.0)\n   promises       1.2.1   2023-08-10 [1] CRAN (R 4.3.0)\n   ps             1.7.6   2024-01-18 [1] CRAN (R 4.3.1)\n   purrr          1.0.2   2023-08-10 [1] CRAN (R 4.3.0)\n   R6             2.5.1   2021-08-19 [1] CRAN (R 4.3.0)\n   Rcpp           1.0.12  2024-01-09 [1] CRAN (R 4.3.1)\n   remotes        2.4.2.1 2023-07-18 [1] CRAN (R 4.3.0)\n   rex            1.2.1   2021-11-26 [1] CRAN (R 4.3.0)\n   rlang          1.1.3   2024-01-10 [1] CRAN (R 4.3.1)\n   rstudioapi     0.15.0  2023-07-07 [1] CRAN (R 4.3.0)\n   sessioninfo    1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n   shiny          1.8.1.1 2024-04-02 [1] CRAN (R 4.3.1)\n   stringi        1.8.3   2023-12-11 [1] CRAN (R 4.3.1)\n   stringr        1.5.1   2023-11-14 [1] CRAN (R 4.3.1)\n   tibble         3.2.1   2023-03-20 [1] CRAN (R 4.3.0)\n   tidyr          1.3.1   2024-01-24 [1] CRAN (R 4.3.1)\n   tidyselect     1.2.1   2024-03-11 [1] CRAN (R 4.3.1)\n   urlchecker     1.0.1   2021-11-30 [1] CRAN (R 4.3.0)\n   usethis        2.2.3   2024-02-19 [1] CRAN (R 4.3.1)\n   utf8           1.2.4   2023-10-22 [1] CRAN (R 4.3.1)\n   vctrs          0.6.5   2023-12-01 [1] CRAN (R 4.3.1)\n   waiter         0.2.5   2022-01-03 [1] CRAN (R 4.3.0)\n   withr          3.0.0   2024-01-16 [1] CRAN (R 4.3.1)\n   xml2           1.3.6   2023-12-04 [1] CRAN (R 4.3.1)\n   xmlparsedata   1.0.5   2021-03-06 [1] CRAN (R 4.3.0)\n   xtable         1.8-4   2019-04-21 [1] CRAN (R 4.3.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n\n V ── Loaded and on-disk version mismatch.\n\n─ External software ────────────────────────────────────────────────────────────\n setting        value\n cairo\n cairoFT\n pango\n png\n jpeg\n tiff\n tcl\n curl           8.4.0\n zlib           1.2.12\n bzlib          1.0.8, 13-Jul-2019\n xz             5.4.4\n PCRE           10.42 2022-12-11\n ICU            74.1\n TRE            TRE 0.8.0 R_fixes (BSD)\n iconv          Apple or GNU libiconv 1.11\n readline       5.2\n\n      BLAS           /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib\n\n      lapack         /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib\n lapack_version 3.11.0\n\n─ Python configuration ─────────────────────────────────────────────────────────\n Python is not available\n\n────────────────────────────────────────────────────────────────────────────────\n--------------------------------------------------------------------------------\n-                               Masked Functions                               -\n--------------------------------------------------------------------------------\nfunction `filter` from {package:stats} by package:dplyr\nfunction `lag` from {package:stats} by package:dplyr\nfunction `intersect` from {package:base} by package:dplyr\nfunction `setdiff` from {package:base} by package:dplyr\nfunction `setequal` from {package:base} by package:dplyr\nfunction `union` from {package:base} by package:dplyr\nfunction `plot` from {package:base} by package:graphics\nfunction `body&lt;-` from {package:base} by package:methods\nfunction `kronecker` from {package:base} by package:methods\n--------------------------------------------------------------------------------\n-                          Used Package and Functions                          -\n--------------------------------------------------------------------------------\n{package:base} library, mean, summary\n{package:dplyr} %&gt;%, group_by, summarise\n{package:stats} lm\n--------------------------------------------------------------------------------\n-                       Unapproved Package and Functions                       -\n--------------------------------------------------------------------------------\n{package:base} library, summary\n{package:stats} lm\n--------------------------------------------------------------------------------\n-                                Linter Results                                -\n--------------------------------------------------------------------------------\nLine 1 [line_length_linter] Lines should not be more than 20 characters. This\nline is 22 characters.\n\nLine 5 [line_length_linter] Lines should not be more than 20 characters. This\nline is 25 characters.\n\nLine 7 [line_length_linter] Lines should not be more than 20 characters. This\nline is 25 characters.\n\nLine 9 [line_length_linter] Lines should not be more than 20 characters. This\nline is 50 characters.\n\nLine 11 [line_length_linter] Lines should not be more than 20 characters.\nThis line is 36 characters.\n\nLine 14 [line_length_linter] Lines should not be more than 20 characters.\nThis line is 27 characters.\n--------------------------------------------------------------------------------\n-                         Program Run Time Information                         -\n--------------------------------------------------------------------------------\nStart time: 2024-04-08 16:03:28 BST\nEnd time: 2024-04-08 16:03:28 BST\nRun time: 0 seconds\n--------------------------------------------------------------------------------\n-                             Errors and Warnings                              -\n--------------------------------------------------------------------------------\nErrors:\n\n\nWarnings:\n\n--------------------------------------------------------------------------------\n-                         Messages, Output, and Result                         -\n--------------------------------------------------------------------------------\nMessages:\n\nOutput:\n\n\nResult:\n\n    Call:\n    lm(formula = mpg ~ wt, data = mtcars)\n\n    Residuals:\n        Min      1Q  Median      3Q     Max\n    -4.5432 -2.3647 -0.1252  1.4096  6.8727\n\n    Coefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n    (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\n    wt           -5.3445     0.5591  -9.559 1.29e-10 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n    Residual standard error: 3.046 on 30 degrees of freedom\n    Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446\n    F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n--------------------------------------------------------------------------------\n-                               Log Output File                                -\n--------------------------------------------------------------------------------\nLog name: script.log\nLog path: /Users/davidblair/My Drive/Appsilon/Work Projects/examples/logging\n\n\n\nRun multiple scripts\nA key functionality whirl is to support the execution of entire analysis projects. It is possible to define batches of scripts to run simultaneously, and the order in which the different steps should be executed.\nIt is all controlled by a yaml configuration file (use whirl::use_whirl() to get started) such as the one below:\n_whirl.yml:\nsteps:\n  - name: \"Initial step\"\n    paths:\n      - \"setup.R\"\n  - name: \"First batch of programs\"\n    paths:\n      - \"prgA.R\"\n      - \"prgB.R\"\n  - name: \"Run all programs with 2 prefix\"\n    paths:\n      - \"2_*.R\"\nHere three steps are defined, where the first step is to run setup.R. After this we want to run prgA.R and prgB.R simultaneously, and after these two have finished we run all R scripts starting with 2_ (imagine they depend on previous output from e.g. prgA.R).\nTo run all steps you just call run() with the configuration file as input:\n\nwhirl::run(\"_whirl.yml\")\n\nIn this scenario it becomes relevant to check the summary log as well (defaults to summary.html), which have the execution status of each script, and a link to the individual logs.\n\n\nSummary\nThe decision between using logr, logrx, or whirl hinges on specific needs. logr offers greater control over the output, at the expense of detailed environmental context. Conversely, logrx provides more comprehensive details and quicker log generation, along with better support for command line execution, but offers less control over the output. whirl creates detailed logs with similar information as logrx, but by also including the script and it’s printed outputs it allows the user to include any additional information in the log, or to use run() to create analysis reports directly that also includes relevant information on the execution environment. whirl also offers a framework for execution of a project consisting of multiple scripts.",
    "crumbs": [
      "Logs",
      "The Difference Between `logr`, `logrx`, and `whirl`"
    ]
  },
  {
    "objectID": "adam/adrs.html",
    "href": "adam/adrs.html",
    "title": "ADRS",
    "section": "",
    "text": "The Response Analysis Dataset (ADRS) is an essential part of oncology clinical trials for monitoring disease response and progression. This article describes how to create an ADRS ADaM dataset, focusing on common oncology endpoint parameters based on RECIST v1.1 criteria. The primary response values include CR (Complete Response), PR (Partial Response), SD (Stable Disease), NON-CR/NON-PD (Non-CR/Non-PD), PD (Progressive Disease), and NE (Not Evaluable). See {admiral} and {admiralonco} for more information. Find other {admiral} functions and related variables by searching admiraldiscovery\nThis guide uses key pharmaverse packages along with tidyverse components to demonstrate the step-by-step process, ensuring the inclusion of metadata, validation, and exporting to a compliant SAS transport file (XPT).",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adrs.html#select-overall-response-records-and-set-parameter-details",
    "href": "adam/adrs.html#select-overall-response-records-and-set-parameter-details",
    "title": "ADRS",
    "section": "Select Overall Response Records and Set Parameter Details",
    "text": "Select Overall Response Records and Set Parameter Details\nFilter the RS domain to include only overall response records assessed by the investigator and set the parameter details accordingly.\n\nadrs_ovr &lt;- adrs_merged %&gt;%\n  filter(RSEVAL == \"INVESTIGATOR\" & RSTESTCD == \"OVRLRESP\") %&gt;%\n  mutate(\n    PARAMCD = \"OVR\",\n    PARAM = \"Overall Response by Investigator\",\n    PARCAT1 = \"Tumor Response\",\n    PARCAT2 = \"Investigator\",\n    PARCAT3 = \"RECIST 1.1\"\n  )",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adrs.html#date-imputation-and-deriving-adt-adtf-avisit",
    "href": "adam/adrs.html#date-imputation-and-deriving-adt-adtf-avisit",
    "title": "ADRS",
    "section": "Date Imputation and Deriving ADT, ADTF, AVISIT",
    "text": "Date Imputation and Deriving ADT, ADTF, AVISIT\nImpute missing dates and derive analysis dates and visits.\n\nadrs_imputed &lt;- adrs_ovr %&gt;%\n  derive_vars_dt(\n    dtc = RSDTC,\n    new_vars_prefix = \"A\",\n    highest_imputation = \"D\",\n    date_imputation = \"last\"\n  ) %&gt;%\n  mutate(AVISIT = VISIT)",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adrs.html#derive-avalc-and-aval",
    "href": "adam/adrs.html#derive-avalc-and-aval",
    "title": "ADRS",
    "section": "Derive AVALC and AVAL",
    "text": "Derive AVALC and AVAL\nPopulate AVALC with assessed values and create the numeric version AVAL.\n\nadrs_aval &lt;- adrs_imputed %&gt;%\n  mutate(\n    AVALC = RSSTRESC,\n    AVAL = aval_resp(AVALC)\n  )",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adrs.html#flag-worst-assessment-at-each-date-anl01fl",
    "href": "adam/adrs.html#flag-worst-assessment-at-each-date-anl01fl",
    "title": "ADRS",
    "section": "Flag Worst Assessment at Each Date (ANL01FL)",
    "text": "Flag Worst Assessment at Each Date (ANL01FL)\nFlag the worst assessment at each date, considering only valid assessments from the randomization date onward.\n\nworst_resp &lt;- function(arg) {\n  case_when(\n    arg == \"NE\" ~ 1,\n    arg == \"CR\" ~ 2,\n    arg == \"PR\" ~ 3,\n    arg == \"SD\" ~ 4,\n    arg == \"NON-CR/NON-PD\" ~ 5,\n    arg == \"PD\" ~ 6,\n    TRUE ~ 0\n  )\n}\n\nadrs_anl01fl &lt;- adrs_aval %&gt;%\n  restrict_derivation(\n    derivation = derive_var_extreme_flag,\n    args = params(\n      by_vars = exprs(STUDYID, USUBJID, ADT),\n      order = exprs(worst_resp(AVALC), RSSEQ),\n      new_var = ANL01FL,\n      mode = \"last\"\n    ),\n    filter = !is.na(AVAL) & ADT &gt;= RANDDT\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adrs.html#derive-progressive-disease-parameter",
    "href": "adam/adrs.html#derive-progressive-disease-parameter",
    "title": "ADRS",
    "section": "Derive Progressive Disease Parameter",
    "text": "Derive Progressive Disease Parameter\nUse the admiral::derive_extreme_records() function to find the date of first PD.\n\nadrs_pd &lt;- adrs_anl01fl %&gt;%\n  derive_extreme_records(\n    dataset_ref = adsl,\n    dataset_add = adrs_anl01fl,\n    by_vars = exprs(STUDYID, USUBJID),\n    filter_add = PARAMCD == \"OVR\" & AVALC == \"PD\" & ANL01FL == \"Y\",\n    order = exprs(ADT, RSSEQ),\n    mode = \"first\",\n    exist_flag = AVALC,\n    false_value = \"N\",\n    set_values_to = exprs(\n      PARAMCD = \"PD\",\n      PARAM = \"Disease Progression by Investigator\",\n      PARCAT1 = \"Tumor Response\",\n      PARCAT2 = \"Investigator\",\n      PARCAT3 = \"RECIST 1.1\",\n      AVAL = yn_to_numeric(AVALC),\n      ANL01FL = \"Y\"\n    )\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adrs.html#derive-death-parameter",
    "href": "adam/adrs.html#derive-death-parameter",
    "title": "ADRS",
    "section": "Derive Death Parameter",
    "text": "Derive Death Parameter\nCreate a new death parameter using the death date from ADSL.\n\nadsldth &lt;- adsl %&gt;%\n  select(STUDYID, USUBJID, DTHDT, !!!adsl_vars)\n\nadrs_death &lt;- adrs_pd %&gt;%\n  derive_extreme_records(\n    dataset_ref = adsldth,\n    dataset_add = adsldth,\n    by_vars = exprs(STUDYID, USUBJID),\n    filter_add = !is.na(DTHDT),\n    exist_flag = AVALC,\n    false_value = \"N\",\n    set_values_to = exprs(\n      PARAMCD = \"DEATH\",\n      PARAM = \"Death\",\n      PARCAT1 = \"Reference Event\",\n      AVAL = yn_to_numeric(AVALC),\n      ANL01FL = \"Y\",\n      ADT = DTHDT\n    )\n  ) %&gt;%\n  select(-DTHDT)",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adrs.html#derive-last-disease-assessment-parameter",
    "href": "adam/adrs.html#derive-last-disease-assessment-parameter",
    "title": "ADRS",
    "section": "Derive Last Disease Assessment Parameter",
    "text": "Derive Last Disease Assessment Parameter\nCreate a parameter for the last disease assessment.\n\nadrs_lsta &lt;- adrs_death %&gt;%\n  derive_extreme_records(\n    dataset_ref = adsl,\n    dataset_add = adrs_death,\n    by_vars = exprs(STUDYID, USUBJID),\n    filter_add = PARAMCD == \"OVR\" & ANL01FL == \"Y\",\n    order = exprs(ADT, RSSEQ),\n    mode = \"last\",\n    set_values_to = exprs(\n      PARAMCD = \"LSTA\",\n      PARAM = \"Last Disease Assessment by Investigator\",\n      PARCAT1 = \"Tumor Response\",\n      PARCAT2 = \"Investigator\",\n      PARCAT3 = \"RECIST 1.1\",\n      ANL01FL = \"Y\"\n    )\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADRS"
    ]
  },
  {
    "objectID": "adam/adae.html",
    "href": "adam/adae.html",
    "title": "ADAE",
    "section": "",
    "text": "This article provides a step-by-step explanation for creating an ADaM ADAE (Adverse Events) dataset using key pharmaverse packages along with tidyverse components.\nHere we try to cover the most common AE analysis dataset derivations and some of the most useful functions for these.\nFor the purpose of this example, we will use the ADSL dataset from {pharmaverseadam} and ae and ex domains from {pharmaversesdtm}.\n\n\n\nLoad Data and Required pharmaverse Packages\nLoad Specifications for Metacore\nSelect ADSL Variables\nStart Building Derivations\nDerive Analysis Dates\nDerive Duration\nDerive Date of Last Dose\nDerive Analysis Flags\nDerive Occurrence Flags\nDerive Query Variables\nAdd ADSL Variables\nApply Metadata to Create an eSub XPT and Perform Associated Checks",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#programming-flow",
    "href": "adam/adae.html#programming-flow",
    "title": "ADAE",
    "section": "",
    "text": "Load Data and Required pharmaverse Packages\nLoad Specifications for Metacore\nSelect ADSL Variables\nStart Building Derivations\nDerive Analysis Dates\nDerive Duration\nDerive Date of Last Dose\nDerive Analysis Flags\nDerive Occurrence Flags\nDerive Query Variables\nAdd ADSL Variables\nApply Metadata to Create an eSub XPT and Perform Associated Checks",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#anldates",
    "href": "adam/adae.html#anldates",
    "title": "ADAE",
    "section": "Derive Analysis Dates",
    "text": "Derive Analysis Dates\nThe first derivation step we are going to do is to compute the Analysis Date and Relative Analysis Day with the variables merged from ADSL dataset using the admiral::derive_vars_dt() and admiral::derive_vars_dy() functions.\nWhen deriving AE end date first as AENDT, we’re going to impute partial dates with missing day or month. For AE start date ASTDT then we’re going to use the same imputation, but additionally we ensure that the imputed date doesn’t go before treatment start date or after the AE end date.\nFor all of these example calls we don’t generally include the default arguments, so you should be sure to check out the full functional reference pages as then you’ll also learn what other arguments exist to allow further user control over the derivations.\n\n# Derive ASTDT/ASTDTF/ASTDY and AENDT/AENDTF/AENDY\nadae &lt;- adae %&gt;%\n  derive_vars_dt(\n    new_vars_prefix = \"AEN\",\n    dtc = AEENDTC,\n    date_imputation = \"last\",\n    highest_imputation = \"M\", # imputation is performed on missing days or months\n    flag_imputation = \"auto\" # to automatically create AENDTF variable\n  ) %&gt;%\n  derive_vars_dt(\n    new_vars_prefix = \"AST\",\n    dtc = AESTDTC,\n    highest_imputation = \"M\", # imputation is performed on missing days or months\n    flag_imputation = \"auto\", # to automatically create ASTDTF variable\n    min_dates = exprs(TRTSDT), # apply a minimum date for the imputation\n    max_dates = exprs(AENDT) # apply a maximum date for the imputation\n  ) %&gt;%\n  derive_vars_dy(\n    reference_date = TRTSDT,\n    source_vars = exprs(ASTDT, AENDT)\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#anldur",
    "href": "adam/adae.html#anldur",
    "title": "ADAE",
    "section": "Derive Duration",
    "text": "Derive Duration\nNow we have these date variables we can derive AE duration using the admiral::derive_vars_duration() function. For this function the default is to + 1 day for the calculation, but this can be controlled with the add_one argument.\n\n# Derive ADURN/ADURU\nadae &lt;- adae %&gt;%\n  derive_vars_duration(\n    new_var = ADURN,\n    new_var_unit = ADURU,\n    start_date = ASTDT,\n    end_date = AENDT\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#exdates",
    "href": "adam/adae.html#exdates",
    "title": "ADAE",
    "section": "Derive Date of Last Dose",
    "text": "Derive Date of Last Dose\nYou might need to add some exposure information from ex such as deriving the date of last dose before each AE.\nIn the below case we call this LDOSEDT and we want to look only at exposure records with a valid dose or placebo. Here we use the admiral::derive_vars_joined() function which enables more complex joins.\n\n# Derive LDOSEDT\n# In our ex data the EXDOSFRQ (frequency) is \"QD\" which stands for once daily\n# If this was not the case then we would need to use the admiral::create_single_dose_dataset() function\n# to generate single doses from aggregate dose information\n# Refer to https://pharmaverse.github.io/admiral/reference/create_single_dose_dataset.html\nex &lt;- ex %&gt;%\n  derive_vars_dt(\n    dtc = EXENDTC,\n    new_vars_prefix = \"EXEN\"\n  )\n\nadae &lt;- adae %&gt;%\n  derive_vars_joined(\n    dataset_add = ex,\n    by_vars = exprs(STUDYID, USUBJID),\n    order = exprs(EXENDT),\n    new_vars = exprs(LDOSEDT = EXENDT),\n    join_vars = exprs(EXENDT),\n    join_type = \"all\",\n    filter_add = (EXDOSE &gt; 0 | (EXDOSE == 0 & str_detect(EXTRT, \"PLACEBO\"))) & !is.na(EXENDT),\n    filter_join = EXENDT &lt;= ASTDT,\n    mode = \"last\"\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#anlflags",
    "href": "adam/adae.html#anlflags",
    "title": "ADAE",
    "section": "Derive Analysis Flags",
    "text": "Derive Analysis Flags\nNext we looks at common analysis flags such as treatment emergent and on treatment flags using the admiral::derive_var_trtemfl() and admiral::derive_var_ontrtfl() functions. For the on-treatment flag we only want to include AEs occurring until 30 days after treatment end.\n\n# Derive TRTEMFL and ONTRTFL\nadae &lt;- adae %&gt;%\n  derive_var_trtemfl(\n    start_date = ASTDT,\n    end_date = AENDT,\n    trt_start_date = TRTSDT,\n    trt_end_date = TRTEDT\n  ) %&gt;%\n  derive_var_ontrtfl(\n    start_date = ASTDT,\n    ref_start_date = TRTSDT,\n    ref_end_date = TRTEDT,\n    ref_end_window = 30\n  )\n\n\n\nSample of Data\n\n\n\n\nAt first these 2 functions may appear similar but both offer extra specific arguments for flexibility if you needed to apply more complex analysis rules to these derivations. For example, for treatment emergent you could use the intensity arguments if you also wanted to flag those AEs starting before treatment start and ending after treatment start with worsened intensity (i.e. the most extreme intensity is greater than the initial intensity).",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#occflags",
    "href": "adam/adae.html#occflags",
    "title": "ADAE",
    "section": "Derive Occurrence Flags",
    "text": "Derive Occurrence Flags\nThere can be flags that need to be derived based on AE occurrences, such as flagging the first occurrence of maximum severity per patient which in the below example we call AOCCIFL. Here we use the admiral::derive_var_extreme_flag() function.\n\n# Derive AOCCIFL\nadae &lt;- adae %&gt;%\n  # create temporary numeric ASEVN for sorting purpose\n  mutate(TEMP_AESEVN = as.integer(factor(AESEV, levels = c(\"SEVERE\", \"MODERATE\", \"MILD\")))) %&gt;%\n  derive_var_extreme_flag(\n    new_var = AOCCIFL,\n    by_vars = exprs(STUDYID, USUBJID),\n    order = exprs(TEMP_AESEVN, ASTDT, AESEQ),\n    mode = \"first\"\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#query",
    "href": "adam/adae.html#query",
    "title": "ADAE",
    "section": "Derive Query Variables",
    "text": "Derive Query Variables\nThe final set of derived flags would be around those checking for queries/baskets of AE terms, e.g. using Standardized MedDRA Queries (SMQs) or Custom Queries (CQs).\nBefore reading this section, you should read the Queries Dataset Vignette from {admiral}.\nOn a study you would need to create your own version of this queries dataset with the AE queries you need, but for the purpose of this article we use the example provided as part of {admiral} and we filter it to just one CQ and one SMQ. Then you can derive the required variables using the admiral::derive_vars_query() function.\n\nqueries &lt;- admiral::queries %&gt;%\n  filter(PREFIX %in% c(\"CQ01\", \"SMQ02\"))\n\n\n\nSample of Data\n\n\n\n\n\n# Derive CQ01NAM and SMQ02NAM\nadae &lt;- adae %&gt;%\n  derive_vars_query(dataset_queries = queries)\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adae.html#adsladd",
    "href": "adam/adae.html#adsladd",
    "title": "ADAE",
    "section": "Add ADSL Variables",
    "text": "Add ADSL Variables\nIf needed, the other ADSL variables can now be added. List of ADSL variables already merged held in vector adsl_vars.\n\nadae &lt;- adae %&gt;%\n  derive_vars_merged(\n    dataset_add = select(adsl, !!!negate_vars(adsl_vars)),\n    by_vars = exprs(STUDYID, USUBJID)\n  )",
    "crumbs": [
      "ADaM",
      "ADAE"
    ]
  },
  {
    "objectID": "adam/adpc.html",
    "href": "adam/adpc.html",
    "title": "ADPC",
    "section": "",
    "text": "The Non-compartmental analysis (NCA) ADaM uses the CDISC Implementation Guide (https://www.cdisc.org/standards/foundational/adam/adamig-non-compartmental-analysis-input-data-v1-0). This example presented uses underlying EX and PC domains where the EX and PC domains represent data as collected and the ADPC ADaM is output. For more details see the {admiral} vignette.",
    "crumbs": [
      "ADaM",
      "ADPC"
    ]
  },
  {
    "objectID": "adam/adpc.html#first-load-packages",
    "href": "adam/adpc.html#first-load-packages",
    "title": "ADPC",
    "section": "First Load Packages",
    "text": "First Load Packages\nFirst we will load the packages required for our project. We will use {admiral} for the creation of analysis data. {admiral} requires {dplyr}, {lubridate} and {stringr}. Find other {admiral} functions and related variables by searching admiraldiscovery. We will use {metacore} and {metatools} to store and manipulate metadata from our specifications. We will use {xportr} to perform checks on the final data and export to a transport file.\nThe source SDTM data will come from the CDISC pilot study data stored in {pharmaversesdtm}.\n\n# Load Packages\nlibrary(admiral)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(stringr)\nlibrary(metacore)\nlibrary(metatools)\nlibrary(xportr)\nlibrary(pharmaversesdtm)\nlibrary(pharmaverseadam)\nlibrary(reactable)",
    "crumbs": [
      "ADaM",
      "ADPC"
    ]
  },
  {
    "objectID": "adam/adpc.html#next-load-specifications-for-metacore",
    "href": "adam/adpc.html#next-load-specifications-for-metacore",
    "title": "ADPC",
    "section": "Next Load Specifications for Metacore",
    "text": "Next Load Specifications for Metacore\nWe have saved our specifications in an Excel file and will load them into {metacore} with the metacore::spec_to_metacore() function.\n\n# ---- Load Specs for Metacore ----\n\nmetacore &lt;- spec_to_metacore(\"./metadata/pk_spec.xlsx\") %&gt;%\n  select_dataset(\"ADPC\")",
    "crumbs": [
      "ADaM",
      "ADPC"
    ]
  },
  {
    "objectID": "adam/adpc.html#load-source-datasets",
    "href": "adam/adpc.html#load-source-datasets",
    "title": "ADPC",
    "section": "Load Source Datasets",
    "text": "Load Source Datasets\nWe will load are SDTM data from {pharmaversesdtm}. The main components of this will be exposure data from EX and pharmacokinetic concentration data from PC. We will use ADSL for baseline characteristics and we will derive additional baselines from vital signs VS.\n\n# ---- Load source datasets ----\n# Load PC, EX, VS, LB and ADSL\nex &lt;- pharmaversesdtm::ex\npc &lt;- pharmaversesdtm::pc\nvs &lt;- pharmaversesdtm::vs\n\nadsl &lt;- pharmaverseadam::adsl\n\nex &lt;- convert_blanks_to_na(ex)\npc &lt;- convert_blanks_to_na(pc)\nvs &lt;- convert_blanks_to_na(vs)",
    "crumbs": [
      "ADaM",
      "ADPC"
    ]
  },
  {
    "objectID": "adam/adpc.html#derivations",
    "href": "adam/adpc.html#derivations",
    "title": "ADPC",
    "section": "Derivations",
    "text": "Derivations\n\nDerive PC Dates\nHere we use {admiral} functions for working with dates and we will also create a nominal time from first dose NFRLT for PC data based on PCTPTNUM.\n\n# Get list of ADSL vars required for derivations\nadsl_vars &lt;- exprs(TRTSDT, TRTSDTM, TRT01P, TRT01A)\n\npc_dates &lt;- pc %&gt;%\n  # Join ADSL with PC (need TRTSDT for ADY derivation)\n  derive_vars_merged(\n    dataset_add = adsl,\n    new_vars = adsl_vars,\n    by_vars = exprs(STUDYID, USUBJID)\n  ) %&gt;%\n  # Derive analysis date/time\n  # Impute missing time to 00:00:00\n  derive_vars_dtm(\n    new_vars_prefix = \"A\",\n    dtc = PCDTC,\n    time_imputation = \"00:00:00\"\n  ) %&gt;%\n  # Derive dates and times from date/times\n  derive_vars_dtm_to_dt(exprs(ADTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(ADTM)) %&gt;%\n  derive_vars_dy(reference_date = TRTSDT, source_vars = exprs(ADT)) %&gt;%\n  # Derive event ID and nominal relative time from first dose (NFRLT)\n  mutate(\n    EVID = 0,\n    DRUG = PCTEST,\n    NFRLT = if_else(PCTPTNUM &lt; 0, 0, PCTPTNUM), .after = USUBJID\n  )\n\nThe default value of `ignore_seconds_flag` will change to \"TRUE\" in admiral\n1.4.0.\n\n\n\n\nSample of Data\n\n\n\n\n\n\nGet Dosing Information\nHere we also create nominal time from first dose NFRLT for EX data based on VISITDY.\n\nex_dates &lt;- ex %&gt;%\n  derive_vars_merged(\n    dataset_add = adsl,\n    new_vars = adsl_vars,\n    by_vars = exprs(STUDYID, USUBJID)\n  ) %&gt;%\n  # Keep records with nonzero dose\n  filter(EXDOSE &gt; 0) %&gt;%\n  # Add time and set missing end date to start date\n  # Impute missing time to 00:00:00\n  # Note all times are missing for dosing records in this example data\n  # Derive Analysis Start and End Dates\n  derive_vars_dtm(\n    new_vars_prefix = \"AST\",\n    dtc = EXSTDTC,\n    time_imputation = \"00:00:00\"\n  ) %&gt;%\n  derive_vars_dtm(\n    new_vars_prefix = \"AEN\",\n    dtc = EXENDTC,\n    time_imputation = \"00:00:00\"\n  ) %&gt;%\n  # Derive event ID and nominal relative time from first dose (NFRLT)\n  mutate(\n    EVID = 1,\n    NFRLT = case_when(\n      VISITDY == 1 ~ 0,\n      TRUE ~ 24 * VISITDY\n    )\n  ) %&gt;%\n  # Set missing end dates to start date\n  mutate(AENDTM = case_when(\n    is.na(AENDTM) ~ ASTDTM,\n    TRUE ~ AENDTM\n  )) %&gt;%\n  # Derive dates from date/times\n  derive_vars_dtm_to_dt(exprs(ASTDTM)) %&gt;%\n  derive_vars_dtm_to_dt(exprs(AENDTM))\n\n\n\nExpand Dosing Records\nSince there is a start date and end date for dosing records we need to expand the dosing records between the start date and end date using the function admiral::create_single_dose_dataset().\n\nex_exp &lt;- ex_dates %&gt;%\n  create_single_dose_dataset(\n    dose_freq = EXDOSFRQ,\n    start_date = ASTDT,\n    start_datetime = ASTDTM,\n    end_date = AENDT,\n    end_datetime = AENDTM,\n    nominal_time = NFRLT,\n    lookup_table = dose_freq_lookup,\n    lookup_column = CDISC_VALUE,\n    keep_source_vars = exprs(\n      STUDYID, USUBJID, EVID, EXDOSFRQ, EXDOSFRM,\n      NFRLT, EXDOSE, EXDOSU, EXTRT, ASTDT, ASTDTM, AENDT, AENDTM,\n      VISIT, VISITNUM, VISITDY,\n      TRT01A, TRT01P, DOMAIN, EXSEQ, !!!adsl_vars\n    )\n  ) %&gt;%\n  # Derive AVISIT based on nominal relative time\n  # Derive AVISITN to nominal time in whole days using integer division\n  # Define AVISIT based on nominal day\n  mutate(\n    AVISITN = NFRLT %/% 24 + 1,\n    AVISIT = paste(\"Day\", AVISITN),\n    ADTM = ASTDTM,\n    DRUG = EXTRT\n  ) %&gt;%\n  # Derive dates and times from datetimes\n  derive_vars_dtm_to_dt(exprs(ADTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(ADTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(ASTDTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(AENDTM)) %&gt;%\n  derive_vars_dy(reference_date = TRTSDT, source_vars = exprs(ADT))\n\n\n\nSample of Data\n\n\n\n\n\n\nFind First Dose\nIn this section we will find the first dose for each subject and drug.\n\nadpc_first_dose &lt;- pc_dates %&gt;%\n  derive_vars_merged(\n    dataset_add = ex_exp,\n    filter_add = (EXDOSE &gt; 0 & !is.na(ADTM)),\n    new_vars = exprs(FANLDTM = ADTM),\n    order = exprs(ADTM, EXSEQ),\n    mode = \"first\",\n    by_vars = exprs(STUDYID, USUBJID, DRUG)\n  ) %&gt;%\n  filter(!is.na(FANLDTM)) %&gt;%\n  # Derive AVISIT based on nominal relative time\n  # Derive AVISITN to nominal time in whole days using integer division\n  # Define AVISIT based on nominal day\n  mutate(\n    AVISITN = NFRLT %/% 24 + 1,\n    AVISIT = paste(\"Day\", AVISITN),\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nFind Previous Dose and Next Dose\nUse derive_vars_joined() to find the previous dose and the next dose.\n\nadpc_prev &lt;- adpc_first_dose %&gt;%\n  derive_vars_joined(\n    dataset_add = ex_exp,\n    by_vars = exprs(USUBJID),\n    order = exprs(ADTM),\n    new_vars = exprs(\n      ADTM_prev = ADTM, EXDOSE_prev = EXDOSE, AVISIT_prev = AVISIT,\n      AENDTM_prev = AENDTM\n    ),\n    join_vars = exprs(ADTM),\n    join_type = \"all\",\n    filter_add = NULL,\n    filter_join = ADTM &gt; ADTM.join,\n    mode = \"last\",\n    check_type = \"none\"\n  )\n\nadpc_next &lt;- adpc_prev %&gt;%\n  derive_vars_joined(\n    dataset_add = ex_exp,\n    by_vars = exprs(USUBJID),\n    order = exprs(ADTM),\n    new_vars = exprs(\n      ADTM_next = ADTM, EXDOSE_next = EXDOSE, AVISIT_next = AVISIT,\n      AENDTM_next = AENDTM\n    ),\n    join_vars = exprs(ADTM),\n    join_type = \"all\",\n    filter_add = NULL,\n    filter_join = ADTM &lt;= ADTM.join,\n    mode = \"first\",\n    check_type = \"none\"\n  )\n\n\n\nFind Previous and Next Nominal Dose\nUse the same method to find the previous and next nominal times.\n\nadpc_nom_prev &lt;- adpc_next %&gt;%\n  derive_vars_joined(\n    dataset_add = ex_exp,\n    by_vars = exprs(USUBJID),\n    order = exprs(NFRLT),\n    new_vars = exprs(NFRLT_prev = NFRLT),\n    join_vars = exprs(NFRLT),\n    join_type = \"all\",\n    filter_add = NULL,\n    filter_join = NFRLT &gt; NFRLT.join,\n    mode = \"last\",\n    check_type = \"none\"\n  )\n\nadpc_nom_next &lt;- adpc_nom_prev %&gt;%\n  derive_vars_joined(\n    dataset_add = ex_exp,\n    by_vars = exprs(USUBJID),\n    order = exprs(NFRLT),\n    new_vars = exprs(NFRLT_next = NFRLT),\n    join_vars = exprs(NFRLT),\n    join_type = \"all\",\n    filter_add = NULL,\n    filter_join = NFRLT &lt;= NFRLT.join,\n    mode = \"first\",\n    check_type = \"none\"\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nCombine PC and EX Data\nCombine PC and EX records and derive the additional relative time variables.\n\nadpc_arrlt &lt;- bind_rows(adpc_nom_next, ex_exp) %&gt;%\n  group_by(USUBJID, DRUG) %&gt;%\n  mutate(\n    FANLDTM = min(FANLDTM, na.rm = TRUE),\n    min_NFRLT = min(NFRLT_prev, na.rm = TRUE),\n    maxdate = max(ADT[EVID == 0], na.rm = TRUE), .after = USUBJID\n  ) %&gt;%\n  arrange(USUBJID, ADTM) %&gt;%\n  ungroup() %&gt;%\n  filter(ADT &lt;= maxdate) %&gt;%\n  # Derive Actual Relative Time from First Dose (AFRLT)\n  derive_vars_duration(\n    new_var = AFRLT,\n    start_date = FANLDTM,\n    end_date = ADTM,\n    out_unit = \"hours\",\n    floor_in = FALSE,\n    add_one = FALSE\n  ) %&gt;%\n  # Derive Actual Relative Time from Reference Dose (ARRLT)\n  derive_vars_duration(\n    new_var = ARRLT,\n    start_date = ADTM_prev,\n    end_date = ADTM,\n    out_unit = \"hours\",\n    floor_in = FALSE,\n    add_one = FALSE\n  ) %&gt;%\n  # Derive Actual Relative Time from Next Dose (AXRLT not kept)\n  derive_vars_duration(\n    new_var = AXRLT,\n    start_date = ADTM_next,\n    end_date = ADTM,\n    out_unit = \"hours\",\n    floor_in = FALSE,\n    add_one = FALSE\n  ) %&gt;%\n  mutate(\n    ARRLT = case_when(\n      EVID == 1 ~ 0,\n      is.na(ARRLT) ~ AXRLT,\n      TRUE ~ ARRLT\n    ),\n    # Derive Reference Dose Date\n    PCRFTDTM = case_when(\n      EVID == 1 ~ ADTM,\n      is.na(ADTM_prev) ~ ADTM_next,\n      TRUE ~ ADTM_prev\n    )\n  ) %&gt;%\n  # Derive dates and times from datetimes\n  derive_vars_dtm_to_dt(exprs(FANLDTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(FANLDTM)) %&gt;%\n  derive_vars_dtm_to_dt(exprs(PCRFTDTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(PCRFTDTM))\n\n\n\nDerive Nominal Reference\nFor nominal relative times we calculate the nominal relative time to reference dose NRRLT.\n\n# Derive Nominal Relative Time from Reference Dose (NRRLT)\n\nadpc_nrrlt &lt;- adpc_arrlt %&gt;%\n  mutate(\n    NRRLT = case_when(\n      EVID == 1 ~ 0,\n      is.na(NFRLT_prev) ~ NFRLT - min_NFRLT,\n      TRUE ~ NFRLT - NFRLT_prev\n    ),\n    NXRLT = case_when(\n      EVID == 1 ~ 0,\n      TRUE ~ NFRLT - NFRLT_next\n    )\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive Analysis Variables\nHere we derive the analysis variables such as AVAL and ATPTREF.\n\nadpc_aval &lt;- adpc_nrrlt %&gt;%\n  mutate(\n    PARCAT1 = PCSPEC,\n    ATPTN = case_when(\n      EVID == 1 ~ 0,\n      TRUE ~ PCTPTNUM\n    ),\n    ATPT = case_when(\n      EVID == 1 ~ \"Dose\",\n      TRUE ~ PCTPT\n    ),\n    ATPTREF = case_when(\n      EVID == 1 ~ AVISIT,\n      is.na(AVISIT_prev) ~ AVISIT_next,\n      TRUE ~ AVISIT_prev\n    ),\n    # Derive baseline flag for pre-dose records\n    ABLFL = case_when(\n      ATPT == \"Pre-dose\" ~ \"Y\",\n      TRUE ~ NA_character_\n    ),\n    # Derive BASETYPE\n    BASETYPE = paste(ATPTREF, \"Baseline\"),\n\n    # Derive Actual Dose\n    DOSEA = case_when(\n      EVID == 1 ~ EXDOSE,\n      is.na(EXDOSE_prev) ~ EXDOSE_next,\n      TRUE ~ EXDOSE_prev\n    ),\n    # Derive Planned Dose\n    DOSEP = case_when(\n      TRT01P == \"Xanomeline High Dose\" ~ 81,\n      TRT01P == \"Xanomeline Low Dose\" ~ 54\n    ),\n    DOSEU = \"mg\",\n  ) %&gt;%\n  # Derive relative time units\n  mutate(\n    FRLTU = \"h\",\n    RRLTU = \"h\",\n    # Derive PARAMCD\n    PARAMCD = coalesce(PCTESTCD, \"DOSE\"),\n    ALLOQ = PCLLOQ,\n    # Derive AVAL\n    AVAL = case_when(\n      EVID == 1 ~ EXDOSE,\n      PCSTRESC == \"&lt;BLQ\" & NFRLT == 0 ~ 0,\n      PCSTRESC == \"&lt;BLQ\" & NFRLT &gt; 0 ~ 0.5 * ALLOQ,\n      TRUE ~ PCSTRESN\n    ),\n    AVALU = case_when(\n      EVID == 1 ~ EXDOSU,\n      TRUE ~ PCSTRESU\n    ),\n    AVALCAT1 = if_else(PCSTRESC == \"&lt;BLQ\", PCSTRESC, prettyNum(signif(AVAL, digits = 3))),\n  ) %&gt;%\n  # Add SRCSEQ\n  mutate(\n    SRCDOM = DOMAIN,\n    SRCVAR = \"SEQ\",\n    SRCSEQ = coalesce(PCSEQ, EXSEQ)\n  )\n\n\n\nDerive DTYPE Copy Records\nThe CDISC ADaM Implementation Guide for Non-compartmental Analysis uses duplicated records for analysis when a record needs to be used in more than one way. In this example the 24 hour post-dose record will also be used a the pre-dose record for the “Day 2” dose.\n\ndtype &lt;- adpc_aval %&gt;%\n  filter(NFRLT &gt; 0 & NXRLT == 0 & EVID == 0 & !is.na(AVISIT_next)) %&gt;%\n  select(-PCRFTDT, -PCRFTTM) %&gt;%\n  # Re-derive variables in for DTYPE copy records\n  mutate(\n    ABLFL = NA_character_,\n    ATPTREF = AVISIT_next,\n    ARRLT = AXRLT,\n    NRRLT = NXRLT,\n    PCRFTDTM = ADTM_next,\n    DOSEA = EXDOSE_next,\n    BASETYPE = paste(AVISIT_next, \"Baseline\"),\n    ATPT = \"Pre-dose\",\n    ATPTN = NFRLT,\n    ABLFL = \"Y\",\n    DTYPE = \"COPY\"\n  ) %&gt;%\n  derive_vars_dtm_to_dt(exprs(PCRFTDTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(PCRFTDTM))\n\n\n\nSample of Data\n\n\n\n\n\n\nCombine Original and DTYPE Copy\nNow the duplicated records are combined with the original records.\n\nadpc_dtype &lt;- bind_rows(adpc_aval, dtype) %&gt;%\n  arrange(STUDYID, USUBJID, BASETYPE, ADTM, NFRLT) %&gt;%\n  mutate(\n    # Derive MRRLT, ANL01FL and ANL02FL\n    MRRLT = if_else(ARRLT &lt; 0, 0, ARRLT),\n    ANL01FL = \"Y\",\n    ANL02FL = if_else(is.na(DTYPE), \"Y\", NA_character_),\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive BASE and CHG\n\n# ---- Derive BASE and Calculate Change from Baseline ----\n\nadpc_base &lt;- adpc_dtype %&gt;%\n  derive_var_base(\n    by_vars = exprs(STUDYID, USUBJID, PARAMCD, PARCAT1, BASETYPE),\n    source_var = AVAL,\n    new_var = BASE,\n    filter = ABLFL == \"Y\"\n  )\n\nadpc_chg &lt;- derive_var_chg(adpc_base)\n\n\n\nDerive PARAM with {metatools}\nHere we derive PARAM and PARAMN using create_var_from_codelist() from {metatools}.\n\n# ---- Add ASEQ ----\n\nadpc_aseq &lt;- adpc_chg %&gt;%\n  # Calculate ASEQ\n  derive_var_obs_number(\n    new_var = ASEQ,\n    by_vars = exprs(STUDYID, USUBJID),\n    order = exprs(ADTM, BASETYPE, EVID, AVISITN, ATPTN, PARCAT1, DTYPE),\n    check_type = \"error\"\n  ) %&gt;%\n  # Derive PARAM and PARAMN using metatools\n  create_var_from_codelist(metacore, input_var = PARAMCD, out_var = PARAM) %&gt;%\n  create_var_from_codelist(metacore, input_var = PARAMCD, out_var = PARAMN)\n\n\n\nDerive Additional Baselines\nHere we derive additional baseline values from VS for baseline height HTBL and weight WTBL and compute the body mass index (BMI) with compute_bmi().\n\n#---- Derive additional baselines from VS ----\n\nadpc_baselines &lt;- adpc_aseq %&gt;%\n  derive_vars_merged(\n    dataset_add = vs,\n    filter_add = VSTESTCD == \"HEIGHT\",\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(HTBL = VSSTRESN, HTBLU = VSSTRESU)\n  ) %&gt;%\n  derive_vars_merged(\n    dataset_add = vs,\n    filter_add = VSTESTCD == \"WEIGHT\" & VSBLFL == \"Y\",\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(WTBL = VSSTRESN, WTBLU = VSSTRESU)\n  ) %&gt;%\n  mutate(\n    BMIBL = compute_bmi(height = HTBL, weight = WTBL),\n    BMIBLU = \"kg/m^2\"\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nCombine with ADSL\nIf needed, the other ADSL variables can now be added:\n\n# ---- Add all ADSL variables ----\n\n# Add all ADSL variables\nadpc_prefinal &lt;- adpc_baselines %&gt;%\n  derive_vars_merged(\n    dataset_add = select(adsl, !!!negate_vars(adsl_vars)),\n    by_vars = exprs(STUDYID, USUBJID)\n  )",
    "crumbs": [
      "ADaM",
      "ADPC"
    ]
  },
  {
    "objectID": "adam/adpc.html#check-data-with-metacore-and-metatools",
    "href": "adam/adpc.html#check-data-with-metacore-and-metatools",
    "title": "ADPC",
    "section": "Check Data With metacore and metatools",
    "text": "Check Data With metacore and metatools\nWe use {metacore} objects with {metatools} functions to perform a number of checks on the data. We will drop variables not in the specs and make sure all the variables from the specs are included.\n\n# Apply metadata and perform associated checks ----\nadpc &lt;- adpc_prefinal %&gt;%\n  drop_unspec_vars(metacore) %&gt;% # Drop unspecified variables from specs\n  check_variables(metacore) %&gt;% # Check all variables specified are present and no more\n  check_ct_data(metacore) %&gt;% # Checks all variables with CT only contain values within the CT\n  order_cols(metacore) %&gt;% # Orders the columns according to the spec\n  sort_by_key(metacore) # Sorts the rows by the sort keys",
    "crumbs": [
      "ADaM",
      "ADPC"
    ]
  },
  {
    "objectID": "adam/adpc.html#apply-labels-and-formats-with-xportr",
    "href": "adam/adpc.html#apply-labels-and-formats-with-xportr",
    "title": "ADPC",
    "section": "Apply Labels and Formats with xportr",
    "text": "Apply Labels and Formats with xportr\nUsing {xportr} we check variable type, assign variable length, add variable labels, add variable formats, and save a transport file. At the end you could add a call to xportr::xportr_write() to produce the XPT file.\n\ndir &lt;- tempdir() # Change to whichever directory you want to save the dataset in\n\nadpc_xpt &lt;- adpc %&gt;%\n  xportr_type(metacore, domain = \"ADPC\") %&gt;% # Coerce variable type to match spec\n  xportr_length(metacore) %&gt;% # Assigns SAS length from a variable level metadata\n  xportr_label(metacore) %&gt;% # Assigns variable label from metacore specifications\n  xportr_format(metacore) %&gt;% # Assigns variable format from metacore specifications\n  xportr_df_label(metacore) %&gt;% # Assigns dataset label from metacore specifications\n  xportr_write(file.path(dir, \"adpc.xpt\")) # Write xpt v5 transport file",
    "crumbs": [
      "ADaM",
      "ADPC"
    ]
  },
  {
    "objectID": "adam/adtte.html",
    "href": "adam/adtte.html",
    "title": "ADTTE",
    "section": "",
    "text": "Introduction\nThis article provides a step-by-step explanation for creating an ADaM ADTTE (Time-to-Event) dataset with common oncology endpoint parameters using key pharmaverse packages along with tidyverse components. ADTTE datasets often involve calculating time-to-event variables for endpoints such as Overall Survival (OS) and Progression-Free Survival (PFS).\nFor the purpose of this example, we will use the ADSL and ADRS_ONCO datasets from {pharmaverseadam}.\n\n\nLoad Required Packages\nFirst, we will load the necessary packages:\n\nlibrary(admiral)\nlibrary(admiralonco)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(metacore)\nlibrary(metatools)\nlibrary(xportr)\nlibrary(pharmaverseadam)\n\n\n\nLoad Specifications and Source Data\nWe will load our specification file into a {metacore} object to trace the dataset variables and attributes. Then, we will read the source data.\n\n# Load metacore specifications\nmetacore &lt;- spec_to_metacore(\"./metadata/onco_spec.xlsx\") %&gt;%\n  select_dataset(\"ADTTE\")\n\n# Load source datasets\nadsl &lt;- pharmaverseadam::adsl\nadrs &lt;- pharmaverseadam::adrs_onco\n\nadrs &lt;- adrs_onco\n\n\n\nDefine Event and Censoring Sources\nWe define event and censoring sources using the admiral::event_source() and admiral::censor_source() functions. This forms the basis for calculating time-to-event endpoints. Find other {admiral} functions and related variables by searching admiraldiscovery.\n\n# Define event and censoring sources\ndeath_event &lt;- event_source(\n  dataset_name = \"adrs\",\n  filter = PARAMCD == \"DEATH\" & AVALC == \"Y\" & ANL01FL == \"Y\",\n  date = ADT,\n  set_values_to = exprs(\n    EVNTDESC = \"Death\",\n    SRCDOM = \"ADRS\",\n    SRCVAR = \"ADT\"\n  )\n)\n\npd_event &lt;- event_source(\n  dataset_name = \"adrs\",\n  filter = PARAMCD == \"PD\" & ANL01FL == \"Y\",\n  date = ADT,\n  set_values_to = exprs(\n    EVNTDESC = \"Progressive Disease\",\n    SRCDOM = \"ADRS\",\n    SRCVAR = \"ADT\"\n  )\n)\n\nlastalive_censor &lt;- censor_source(\n  dataset_name = \"adsl\",\n  date = LSTALVDT,\n  set_values_to = exprs(\n    EVNTDESC = \"Last Known Alive\",\n    CNSDTDSC = \"Last Known Alive Date\",\n    SRCDOM = \"ADSL\",\n    SRCVAR = \"LSTALVDT\"\n  )\n)\n\nlasta_censor &lt;- censor_source(\n  dataset_name = \"adrs\",\n  filter = PARAMCD == \"LSTA\" & ANL01FL == \"Y\",\n  date = ADT,\n  set_values_to = exprs(\n    EVNTDESC = \"Progression Free Alive\",\n    CNSDTDSC = \"Last Tumor Assessment\",\n    SRCDOM = \"ADRS\",\n    SRCVAR = \"ADT\"\n  )\n)\n\nrand_censor &lt;- censor_source(\n  dataset_name = \"adsl\",\n  date = RANDDT,\n  set_values_to = exprs(\n    EVNTDESC = \"Randomization Date\",\n    CNSDTDSC = \"Randomization Date\",\n    SRCDOM = \"ADSL\",\n    SRCVAR = \"RANDDT\"\n  )\n)\n\n\n\nDerive Time-to-Event Parameters\nThe admiral::derive_param_tte() function is used to derive parameters such as OS (Overall Survival) and PFS (Progression-Free Survival).\n\n# Derive Overall Survival (OS)\nadtte &lt;- derive_param_tte(\n  dataset_adsl = adsl,\n  start_date = RANDDT,\n  event_conditions = list(death_event),\n  censor_conditions = list(lastalive_censor, rand_censor),\n  source_datasets = list(adsl = adsl, adrs = adrs),\n  set_values_to = exprs(PARAMCD = \"OS\", PARAM = \"Overall Survival\")\n)\n\n# Derive Progression-Free Survival (PFS)\nadtte_pfs &lt;- adtte %&gt;%\n  derive_param_tte(\n    dataset_adsl = adsl,\n    start_date = RANDDT,\n    event_conditions = list(pd_event, death_event),\n    censor_conditions = list(lasta_censor, rand_censor),\n    source_datasets = list(adsl = adsl, adrs = adrs),\n    set_values_to = exprs(PARAMCD = \"PFS\", PARAM = \"Progression-Free Survival\")\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive Analysis Value (AVAL)\nThe analysis value (AVAL) can be derived by calling the admiral::derive_vars_duration() function.\n\n# Derive analysis value\nadtte_aval &lt;- adtte_pfs %&gt;%\n  derive_vars_duration(\n    new_var = AVAL,\n    start_date = STARTDT,\n    end_date = ADT\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive Analysis Sequence Number (ASEQ)\nWe derive the sequence number for each record to uniquely identify them using the admiral::derive_var_obs_number() function.\n\n# Derive analysis sequence number\nadtte_aseq &lt;- adtte_aval %&gt;%\n  derive_var_obs_number(\n    by_vars = exprs(STUDYID, USUBJID),\n    order = exprs(PARAMCD),\n    check_type = \"error\"\n  )\n\n\n\nAdd ADSL Variables\nAdditional variables from the ADSL dataset are merged into the ADTTE dataset using the admiral::derive_vars_merged() function to enrich it.\n\n# Add ADSL variables\nadtte_adsl &lt;- adtte_aseq %&gt;%\n  derive_vars_merged(\n    dataset_add = adsl,\n    by_vars = exprs(STUDYID, USUBJID)\n  )\n\n\n\nApply Metadata and eSub Checks\nWe use {metatools} and {xportr} to perform checks, apply metadata such as types, lengths, labels, and write the dataset to an XPT file.\n\n# Apply metadata and perform checks\nadtte_adsl_checked &lt;- adtte_adsl %&gt;%\n  add_variables(metacore) %&gt;%\n  drop_unspec_vars(metacore) %&gt;%\n  check_variables(metacore) %&gt;%\n  check_ct_data(metacore) %&gt;%\n  order_cols(metacore) %&gt;%\n  sort_by_key(metacore)\n\n# Apply apply labels, formats, and export the dataset to an XPT file.\nadtte_final &lt;- adtte_adsl_checked %&gt;%\n  xportr_type(metacore, domain = \"ADTTE\") %&gt;%\n  xportr_length(metacore) %&gt;%\n  xportr_label(metacore) %&gt;%\n  xportr_df_label(metacore)\n\n# Write dataset to XPT file (optional)\ndir &lt;- tempdir()\nxportr_write(adtte_final, file.path(dir, \"adtte.xpt\"))",
    "crumbs": [
      "ADaM",
      "ADTTE"
    ]
  },
  {
    "objectID": "session.html",
    "href": "session.html",
    "title": "Session Info",
    "section": "",
    "text": "Session Info\n\nsessionInfo()\n\nR version 4.5.2 (2025-10-31)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 24.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.2    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.2       htmltools_0.5.8.1 yaml_2.3.10       rmarkdown_2.30   \n [9] knitr_1.50        jsonlite_2.0.0    xfun_0.54         digest_0.6.38    \n[13] rlang_1.1.6       evaluate_1.0.5   \n\n\n\n\nInstalled Packages\n\nknitr::kable(installed.packages()[, c(\"Package\", \"Version\")], row.names = FALSE)\n\n\n\n\nPackage\nVersion\n\n\n\n\nabind\n1.4-8\n\n\nadmiral\n1.3.1\n\n\nadmiraldev\n1.3.1\n\n\nadmiralonco\n1.3.0\n\n\narchive\n1.1.12\n\n\naskpass\n1.2.1\n\n\nassertthat\n0.2.1\n\n\nautoslider.core\n0.3.1\n\n\nbackports\n1.5.0\n\n\nbase64enc\n0.1-3\n\n\nbigD\n0.3.1\n\n\nbit\n4.6.0\n\n\nbit64\n4.6.0-1\n\n\nbitops\n1.0-9\n\n\nbrew\n1.0-10\n\n\nbrio\n1.1.5\n\n\nbroom\n1.0.10\n\n\nbsicons\n0.1.2\n\n\nbslib\n0.9.0\n\n\ncachem\n1.1.0\n\n\ncallr\n3.7.6\n\n\ncar\n3.1-3\n\n\ncarData\n3.0-5\n\n\ncards\n0.7.0\n\n\ncardx\n0.3.0\n\n\ncaTools\n1.18.3\n\n\ncellranger\n1.1.0\n\n\ncheckmate\n2.3.3\n\n\ncli\n3.6.5\n\n\nclipr\n0.8.0\n\n\ncolourpicker\n1.3.0\n\n\ncommon\n1.1.3\n\n\ncommonmark\n2.0.0\n\n\nconfintr\n1.0.2\n\n\ncorrplot\n0.95\n\n\ncowplot\n1.2.0\n\n\ncpp11\n0.5.2\n\n\ncrayon\n1.5.3\n\n\ncrosstalk\n1.2.2\n\n\ncurl\n7.0.0\n\n\ndata.table\n1.17.8\n\n\nDeriv\n4.2.0\n\n\ndesc\n1.4.3\n\n\ndiffobj\n0.3.6\n\n\ndigest\n0.6.38\n\n\ndoBy\n4.7.0\n\n\ndplyr\n1.1.4\n\n\nDT\n0.34.0\n\n\nellipsis\n0.3.2\n\n\nemmeans\n2.0.0\n\n\nestimability\n1.5.1\n\n\nevaluate\n1.0.5\n\n\nfarver\n2.1.2\n\n\nfastmap\n1.2.0\n\n\nfilelock\n1.0.3\n\n\nfilters\n0.3.1\n\n\nflextable\n0.9.10\n\n\nfontawesome\n0.5.3\n\n\nfontBitstreamVera\n0.1.1\n\n\nfontLiberation\n0.1.0\n\n\nfontquiver\n0.2.1\n\n\nforcats\n1.0.1\n\n\nforeach\n1.5.2\n\n\nformatters\n0.5.11\n\n\nFormula\n1.2-5\n\n\nfs\n1.6.6\n\n\ngdtools\n0.4.4\n\n\ngeeasy\n0.1.3\n\n\ngeeM\n0.10.1\n\n\ngeepack\n1.3.13\n\n\ngenerics\n0.1.4\n\n\nggExtra\n0.11.0\n\n\nggformula\n1.0.0\n\n\nggiraph\n0.9.2\n\n\nggplot2\n4.0.1\n\n\nggpmisc\n0.6.2\n\n\nggpp\n0.5.9\n\n\nggpubr\n0.6.2\n\n\nggrepel\n0.9.6\n\n\nggridges\n0.5.7\n\n\nggsci\n4.1.0\n\n\nggsignif\n0.6.4\n\n\ngh\n1.5.0\n\n\ngitcreds\n0.1.2\n\n\nglmnet\n4.1-10\n\n\nglue\n1.8.0\n\n\ngoftest\n1.2-3\n\n\ngridExtra\n2.3\n\n\ngt\n1.1.0\n\n\ngtable\n0.3.6\n\n\ngtsummary\n2.4.0\n\n\nhaven\n2.5.5\n\n\nhere\n1.0.2\n\n\nhighr\n0.11\n\n\nhms\n1.1.4\n\n\nhtmltools\n0.5.8.1\n\n\nhtmlwidgets\n1.6.4\n\n\nhttpuv\n1.6.16\n\n\nhttr\n1.4.7\n\n\nhttr2\n1.2.1\n\n\nini\n0.3.1\n\n\nisoband\n0.2.7\n\n\niterators\n1.0.14\n\n\njquerylib\n0.1.4\n\n\njsonlite\n2.0.0\n\n\njuicyjuice\n0.1.0\n\n\nkableExtra\n1.4.0\n\n\nkinship2\n1.9.6.2\n\n\nknitr\n1.50\n\n\nlabeling\n0.4.3\n\n\nlabelled\n2.16.0\n\n\nlater\n1.4.4\n\n\nlazyeval\n0.2.2\n\n\nlearnr\n0.11.6\n\n\nlifecycle\n1.0.4\n\n\nlitedown\n0.8\n\n\nlme4\n1.1-37\n\n\nlmodel2\n1.7-4\n\n\nlogger\n0.4.1\n\n\nlogr\n1.3.9\n\n\nlogrx\n0.4.0\n\n\nlpSolve\n5.6.23\n\n\nlubridate\n1.9.4\n\n\nmagrittr\n2.0.4\n\n\nmarkdown\n2.0\n\n\nMatrixModels\n0.5-4\n\n\nmemoise\n2.0.1\n\n\nMESS\n0.6.0\n\n\nmetacore\n0.2.1\n\n\nmetatools\n0.2.0\n\n\nmicrobenchmark\n1.5.0\n\n\nmime\n0.13\n\n\nminiUI\n0.1.2\n\n\nminqa\n1.2.8\n\n\nmmrm\n0.3.15\n\n\nmodelr\n0.1.11\n\n\nmosaicCore\n0.9.5\n\n\nmultcomp\n1.4-29\n\n\nmultcompView\n0.1-10\n\n\nmvtnorm\n1.3-3\n\n\nnestcolor\n0.1.3\n\n\nnloptr\n2.2.1\n\n\nnumDeriv\n2016.8-1.1\n\n\nofficer\n0.7.1\n\n\nopenssl\n2.3.4\n\n\notel\n0.2.0\n\n\nparallelly\n1.45.1\n\n\npbkrtest\n0.5.5\n\n\npharmaverseadam\n1.2.0\n\n\npharmaverseraw\n0.1.1\n\n\npharmaversesdtm\n1.3.1\n\n\npillar\n1.11.1\n\n\npkgbuild\n1.4.8\n\n\npkgcache\n2.2.4\n\n\npkgconfig\n2.0.3\n\n\npkgdepends\n0.9.0\n\n\npkglite\n0.2.4\n\n\npkgload\n1.4.1\n\n\nplotly\n4.11.0\n\n\nplyr\n1.8.9\n\n\npng\n0.1-8\n\n\npolynom\n1.4-1\n\n\npraise\n1.0.0\n\n\nprettyunits\n1.2.0\n\n\nprocessx\n3.8.6\n\n\nprogress\n1.2.3\n\n\npromises\n1.5.0\n\n\nps\n1.9.1\n\n\npurrr\n1.2.0\n\n\nquadprog\n1.5-8\n\n\nquantreg\n6.1\n\n\nquarto\n1.5.1\n\n\nR.cache\n0.17.0\n\n\nR.methodsS3\n1.8.2\n\n\nR.oo\n1.27.1\n\n\nR.utils\n2.13.0\n\n\nR6\n2.6.1\n\n\nragg\n1.5.0\n\n\nrappdirs\n0.3.3\n\n\nrbibutils\n2.4\n\n\nRColorBrewer\n1.1-3\n\n\nRcpp\n1.1.0\n\n\nRcppArmadillo\n15.0.2-2\n\n\nRcppEigen\n0.3.4.0.2\n\n\nRcppParallel\n5.1.11-1\n\n\nRcppTOML\n0.2.3\n\n\nRdpack\n2.6.4\n\n\nreactable\n0.4.4\n\n\nreactablefmtr\n2.0.0\n\n\nreactR\n0.6.1\n\n\nreadr\n2.1.6\n\n\nreadxl\n1.4.5\n\n\nreformulas\n0.4.2\n\n\nrematch\n2.0.0\n\n\nremotes\n2.5.0\n\n\nrenv\n1.1.5\n\n\nreticulate\n1.44.1\n\n\nrlang\n1.1.6\n\n\nrlistings\n0.2.12\n\n\nrmarkdown\n2.30\n\n\nroxygen2\n7.3.3\n\n\nrprojroot\n2.1.1\n\n\nrstatix\n0.7.3\n\n\nrstudioapi\n0.17.1\n\n\nrtables\n0.6.14\n\n\nrtables.officer\n0.1.1\n\n\nrvg\n0.4.0\n\n\nS7\n0.2.1\n\n\nsandwich\n3.1-1\n\n\nsass\n0.4.10\n\n\nscales\n1.4.0\n\n\nsdtm.oak\n0.2.0\n\n\nsessioninfo\n1.2.3\n\n\nshape\n1.4.6.1\n\n\nshiny\n1.11.1\n\n\nshinybusy\n0.3.3\n\n\nshinycssloaders\n1.1.0\n\n\nshinyjs\n2.1.0\n\n\nshinylive\n0.3.0\n\n\nshinyTree\n0.3.1\n\n\nshinyvalidate\n0.1.3\n\n\nshinyWidgets\n0.9.0\n\n\nsortable\n0.5.0\n\n\nsourcetools\n0.1.7-1\n\n\nsparkline\n2.0\n\n\nSparseM\n1.84-2\n\n\nsplus2R\n1.3-5\n\n\nstringi\n1.8.7\n\n\nstringr\n1.6.0\n\n\nstyler\n1.11.0\n\n\nsvglite\n2.2.2\n\n\nsys\n3.4.3\n\n\nsystemfonts\n1.3.1\n\n\nteal\n1.1.0\n\n\nteal.code\n0.7.0\n\n\nteal.data\n0.8.0\n\n\nteal.logger\n0.4.0\n\n\nteal.modules.clinical\n0.11.1\n\n\nteal.modules.general\n0.5.1\n\n\nteal.reporter\n0.6.0\n\n\nteal.slice\n0.7.0\n\n\nteal.transform\n0.7.0\n\n\nteal.widgets\n0.5.0\n\n\ntern\n0.9.9\n\n\ntern.gee\n0.1.5\n\n\ntern.mmrm\n0.3.3\n\n\ntestthat\n3.3.0\n\n\ntextshaping\n1.0.4\n\n\nTH.data\n1.1-5\n\n\ntibble\n3.3.0\n\n\ntidyr\n1.3.1\n\n\ntidyselect\n1.2.1\n\n\ntimechange\n0.3.0\n\n\ntinytex\n0.57\n\n\ntippy\n0.1.0\n\n\nTMB\n1.9.18\n\n\ntzdb\n0.5.0\n\n\nunglue\n0.1.0\n\n\nutf8\n1.2.6\n\n\nuuid\n1.2-1\n\n\nV8\n8.0.1\n\n\nvctrs\n0.6.5\n\n\nviridisLite\n0.4.2\n\n\nvistime\n1.2.4\n\n\nvroom\n1.6.6\n\n\nwaldo\n0.6.2\n\n\nwebshot\n0.5.5\n\n\nwhirl\n0.3.1\n\n\nwhisker\n0.4.1\n\n\nwithr\n3.0.2\n\n\nxfun\n0.54\n\n\nxml2\n1.5.0\n\n\nxportr\n0.4.3\n\n\nxtable\n1.8-4\n\n\nxts\n0.14.1\n\n\nyaml\n2.3.10\n\n\nzephyr\n0.1.3\n\n\nzip\n2.3.3\n\n\nzoo\n1.8-14\n\n\npak\n0.9.0\n\n\nbase\n4.5.2\n\n\nboot\n1.3-32\n\n\nclass\n7.3-23\n\n\ncluster\n2.1.8.1\n\n\ncodetools\n0.2-20\n\n\ncompiler\n4.5.2\n\n\ndatasets\n4.5.2\n\n\nforeign\n0.8-90\n\n\ngraphics\n4.5.2\n\n\ngrDevices\n4.5.2\n\n\ngrid\n4.5.2\n\n\nKernSmooth\n2.23-26\n\n\nlattice\n0.22-7\n\n\nMASS\n7.3-65\n\n\nMatrix\n1.7-4\n\n\nmethods\n4.5.2\n\n\nmgcv\n1.9-3\n\n\nnlme\n3.1-168\n\n\nnnet\n7.3-20\n\n\nparallel\n4.5.2\n\n\nrpart\n4.1.24\n\n\nspatial\n7.3-18\n\n\nsplines\n4.5.2\n\n\nstats\n4.5.2\n\n\nstats4\n4.5.2\n\n\nsurvival\n3.8-3\n\n\ntcltk\n4.5.2\n\n\ntools\n4.5.2\n\n\nutils\n4.5.2",
    "crumbs": [
      "Session Info"
    ]
  },
  {
    "objectID": "sdtm/dm.html",
    "href": "sdtm/dm.html",
    "title": "DM",
    "section": "",
    "text": "This article describes how to create a demographics (DM) domain using the {sdtm.oak} package.\nBefore reading this article, it is recommended that users review some of the articles in the package documentation of {sdtm.oak} to understand some of the key concepts: Algorithms & Sub-Algorithms, Creating an Interventions Domain, which provides a detailed explanation of various concepts in {sdtm.oak}, such as oak_id_vars, condition_add, etc. It also offers guidance on which mapping algorithms or functions to use for different mappings and provides a more detailed explanation of how these mapping algorithms or functions work.\nIn this article, we will dive directly into programming and provide further explanation only where it is required.",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#readdata",
    "href": "sdtm/dm.html#readdata",
    "title": "DM",
    "section": "Read in data",
    "text": "Read in data\nRead all the raw datasets into the environment. In this example, the raw datasets needed are ec_raw, ds_raw and dm_raw. Users can read them from the {pharmaverseraw} package using the below code:\n\nlibrary(sdtm.oak)\nlibrary(pharmaverseraw)\nlibrary(dplyr)\n\ndm_raw &lt;- pharmaverseraw::dm_raw\nds_raw &lt;- pharmaverseraw::ds_raw\nec_raw &lt;- pharmaverseraw::ec_raw\n\n\nDemographics Raw dataset.\n\n\nSample of Data\n\n\n\n\n\n\nDisposition Raw dataset.\n\n\nSample of Data\n\n\n\n\n\n\nStudy Drug Administration Raw dataset.\n\n\nSample of Data\n\n\n\n\n\n\nSDTM aCRF\nSDTM annotated aCRF for the raw datasets are below:\nDemographics aCRF\nExposure_as_collected aCRF\nSubject_Disposition_aCRF",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#oakidvars",
    "href": "sdtm/dm.html#oakidvars",
    "title": "DM",
    "section": "Create oak_id_vars",
    "text": "Create oak_id_vars\n\ndm_raw &lt;- dm_raw %&gt;%\n  generate_oak_id_vars(\n    pat_var = \"PATNUM\",\n    raw_src = \"dm_raw\"\n  )\n\nds_raw &lt;- ds_raw %&gt;%\n  generate_oak_id_vars(\n    pat_var = \"PATNUM\",\n    raw_src = \"ds_raw\"\n  )\n\nec_raw &lt;- ec_raw %&gt;%\n  generate_oak_id_vars(\n    pat_var = \"PATNUM\",\n    raw_src = \"ec_raw\"\n  )\n\nFor example, Demographics Raw dataset with oak_id_vars\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#readct",
    "href": "sdtm/dm.html#readct",
    "title": "DM",
    "section": "Read in CT",
    "text": "Read in CT\nControlled Terminology is part of the SDTM specification and it is prepared by the user. In this example, the study controlled terminology name is sdtm_ct.csv. Users can read it from the package using the below code:\n\nstudy_ct &lt;- read.csv(\"metadata/sdtm_ct.csv\")\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#refdates",
    "href": "sdtm/dm.html#refdates",
    "title": "DM",
    "section": "Create reference dates configuration file",
    "text": "Create reference dates configuration file\nCreate reference date configuration file, a data frame which has the details of the variables to be used for the calculation of reference dates. The data frame should have columns listed below:\n\nraw_dataset_name: Name of the raw dataset.\n\ndate_var: Date variable name from the raw dataset.\n\ntime_var: Time variable name from the raw dataset.\n\ndformat: Format of the date collected in raw data.\n\ntformat: Format of the time collected in raw data.\n\nsdtm_var_name: Reference date variable name in DM domain where the raw variable is used.\n\n\nref_date_conf_df &lt;- tibble::tribble(\n  ~raw_dataset_name, ~date_var,     ~time_var,      ~dformat,      ~tformat, ~sdtm_var_name,\n  \"ec_raw\",       \"IT.ECSTDAT\", NA_character_, \"dd-mmm-yyyy\", NA_character_,     \"RFXSTDTC\",\n  \"ec_raw\",       \"IT.ECENDAT\", NA_character_, \"dd-mmm-yyyy\", NA_character_,     \"RFXENDTC\",\n  \"ec_raw\",       \"IT.ECSTDAT\", NA_character_, \"dd-mmm-yyyy\", NA_character_,      \"RFSTDTC\",\n  \"ec_raw\",       \"IT.ECENDAT\", NA_character_, \"dd-mmm-yyyy\", NA_character_,      \"RFENDTC\",\n  \"dm_raw\",            \"IC_DT\", NA_character_,  \"mm/dd/yyyy\", NA_character_,      \"RFICDTC\",\n  \"ds_raw\",          \"DSDTCOL\",     \"DSTMCOL\",  \"mm-dd-yyyy\",         \"H:M\",     \"RFPENDTC\",\n  \"ds_raw\",          \"DEATHDT\", NA_character_,  \"mm/dd/yyyy\", NA_character_,       \"DTHDTC\"\n)\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#maptopic",
    "href": "sdtm/dm.html#maptopic",
    "title": "DM",
    "section": "Map Topic Variable",
    "text": "Map Topic Variable\nIn DM domain, SUBJID is the topic variable and it can be mapped from PATNUM using a simple dplyr::mutate() statement.\n\ndm &lt;- dm_raw %&gt;%\n  mutate(\n    SUBJID = substr(PATNUM, 5, 8)\n  ) %&gt;%\n  select(oak_id, raw_source, patient_number, SUBJID)\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#maprest",
    "href": "sdtm/dm.html#maprest",
    "title": "DM",
    "section": "Map Rest of the Variables",
    "text": "Map Rest of the Variables\nMap rest of the variables in DM domain using either sdtm.oak::assign_no_ct() or sdtm.oak::assign_ct() depending on if the variable has controlled terminologies associated.\n\ndm &lt;- dm %&gt;%\n  # Map AGE using assign_no_ct\n  assign_no_ct(\n    raw_dat = dm_raw,\n    raw_var = \"IT.AGE\",\n    tgt_var = \"AGE\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AGEU using hardcode_ct\n  hardcode_ct(\n    raw_dat = dm_raw,\n    raw_var = \"IT.AGE\",\n    tgt_var = \"AGEU\",\n    tgt_val = \"Year\",\n    ct_spec = study_ct,\n    ct_clst = \"C66781\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map SEX using assign_ct\n  assign_ct(\n    raw_dat = dm_raw,\n    raw_var = \"IT.SEX\",\n    tgt_var = \"SEX\",\n    ct_spec = study_ct,\n    ct_clst = \"C66731\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map ETHNIC using assign_ct\n  assign_ct(\n    raw_dat = dm_raw,\n    raw_var = \"IT.ETHNIC\",\n    tgt_var = \"ETHNIC\",\n    ct_spec = study_ct,\n    ct_clst = \"C66790\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map RACE using assign_ct\n  assign_ct(\n    raw_dat = dm_raw,\n    raw_var = \"IT.RACE\",\n    tgt_var = \"RACE\",\n    ct_spec = study_ct,\n    ct_clst = \"C74457\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map ARM using assign_ct\n  assign_ct(\n    raw_dat = dm_raw,\n    raw_var = \"PLANNED_ARM\",\n    tgt_var = \"ARM\",\n    ct_spec = study_ct,\n    ct_clst = \"ARM\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map ARMCD using assign_no_ct\n  assign_no_ct(\n    raw_dat = dm_raw,\n    raw_var = \"PLANNED_ARMCD\",\n    tgt_var = \"ARMCD\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map ACTARM using assign_ct\n  assign_ct(\n    raw_dat = dm_raw,\n    raw_var = \"ACTUAL_ARM\",\n    tgt_var = \"ACTARM\",\n    ct_spec = study_ct,\n    ct_clst = \"ARM\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map ACTARMCD using assign_no_ct\n  assign_no_ct(\n    raw_dat = dm_raw,\n    raw_var = \"ACTUAL_ARMCD\",\n    tgt_var = \"ACTARMCD\",\n    id_vars = oak_id_vars()\n  )\n\nℹ These terms could not be mapped per the controlled terminology: \"Placebo\" and \"Screen Failure\".\nℹ These terms could not be mapped per the controlled terminology: \"Placebo\" and \"Screen Failure\".\n\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#mapvars",
    "href": "sdtm/dm.html#mapvars",
    "title": "DM",
    "section": "Map Reference Date Variables",
    "text": "Map Reference Date Variables\nUse sdtm.oak::oak_cal_ref_dates() to calculate reference dates variables in ISO 8601 format. The function takes the raw variable names from reference date configuration file, and calculated the minimum or maximum dates based upon the min_max parameter.\nVariable RFSTDTC is the reference Start Date/time for the subject in ISO 8601 character format. Usually equivalent to date/time when subject was first exposed to study treatment. So as specified in the reference date configuration file, we need to calculate the minimum date of the IT.ECSTDAT for each subject from the ec_raw dataset. Therefore, in min_max parameter, “min” is selected for the calculation.\n\ndm &lt;- dm %&gt;%\n  # Derive RFSTDTC using oak_cal_ref_dates\n  oak_cal_ref_dates(\n    ds_in = .,\n    der_var = \"RFSTDTC\",\n    min_max = \"min\",\n    ref_date_config_df = ref_date_conf_df,\n    raw_source = list(\n      ec_raw = ec_raw,\n      ds_raw = ds_raw,\n      dm_raw = dm_raw\n    )\n  )\n\nVariable RFENDTC is the Reference end date/time for the subject in ISO 8601 character format. Usually equivalent to the date/time when subject was determined to have ended the trial, and often equivalent to date/time of last exposure to study treatment. As specified in the reference date configuration file, we need to calculate the maximum date of the IT.ECENDAT for each subject from the ec_raw dataset. Therefore, in min_max parameter, “max” is selected for the calculation.\n\ndm &lt;- dm %&gt;%\n  # Derive RFENDTC using oak_cal_ref_dates\n  oak_cal_ref_dates(\n    ds_in = .,\n    der_var = \"RFENDTC\",\n    min_max = \"max\",\n    ref_date_config_df = ref_date_conf_df,\n    raw_source = list(\n      ec_raw = ec_raw,\n      ds_raw = ds_raw,\n      dm_raw = dm_raw\n    )\n  )\n\n\n\nSample of Data\n\n\n\n\nThe same derivation logic is applicable to other reference date/time variables.\n\ndm &lt;- dm %&gt;%\n  # Derive RFXSTDTC using oak_cal_ref_dates\n  oak_cal_ref_dates(\n    ds_in = .,\n    der_var = \"RFXSTDTC\",\n    min_max = \"min\",\n    ref_date_config_df = ref_date_conf_df,\n    raw_source = list(\n      ec_raw = ec_raw,\n      ds_raw = ds_raw,\n      dm_raw = dm_raw\n    )\n  ) %&gt;%\n  # Derive RFXENDTC using oak_cal_ref_dates\n  oak_cal_ref_dates(\n    ds_in = .,\n    der_var = \"RFXENDTC\",\n    min_max = \"max\",\n    ref_date_config_df = ref_date_conf_df,\n    raw_source = list(\n      ec_raw = ec_raw,\n      ds_raw = ds_raw,\n      dm_raw = dm_raw\n    )\n  ) %&gt;%\n  # Derive RFICDTC using oak_cal_ref_dates\n  oak_cal_ref_dates(\n    ds_in = .,\n    der_var = \"RFICDTC\",\n    min_max = \"min\",\n    ref_date_config_df = ref_date_conf_df,\n    raw_source = list(\n      ec_raw = ec_raw,\n      ds_raw = ds_raw,\n      dm_raw = dm_raw\n    )\n  ) %&gt;%\n  # Derive RFPENDTC using oak_cal_ref_dates\n  oak_cal_ref_dates(\n    ds_in = .,\n    der_var = \"RFPENDTC\",\n    min_max = \"max\",\n    ref_date_config_df = ref_date_conf_df,\n    raw_source = list(\n      ec_raw = ec_raw,\n      ds_raw = ds_raw,\n      dm_raw = dm_raw\n    )\n  ) %&gt;%\n  # Map DTHDTC using oak_cal_ref_dates\n  oak_cal_ref_dates(\n    ds_in = .,\n    der_var = \"DTHDTC\",\n    min_max = \"min\",\n    ref_date_config_df = ref_date_conf_df,\n    raw_source = list(\n      ec_raw = ec_raw,\n      ds_raw = ds_raw,\n      dm_raw = dm_raw\n    )\n  )",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#derivedvars",
    "href": "sdtm/dm.html#derivedvars",
    "title": "DM",
    "section": "Create SDTM derived variables",
    "text": "Create SDTM derived variables\n\ndm &lt;- dm %&gt;%\n  mutate(\n    STUDYID = dm_raw$STUDY,\n    DOMAIN = \"DM\",\n    USUBJID = paste0(\"01-\", dm_raw$PATNUM),\n    COUNTRY = dm_raw$COUNTRY,\n    DTHFL = dplyr::if_else(is.na(DTHDTC), NA_character_, \"Y\")\n  ) %&gt;%\n  # Map DMDTC using assign_datetime\n  assign_datetime(\n    raw_dat = dm_raw,\n    raw_var = \"COL_DT\",\n    tgt_var = \"DMDTC\",\n    raw_fmt = c(\"m/d/y\"),\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Derive study day\n  derive_study_day(\n    sdtm_in = .,\n    dm_domain = .,\n    tgdt = \"DMDTC\",\n    refdt = \"RFXSTDTC\",\n    study_day_var = \"DMDY\"\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/dm.html#attributes",
    "href": "sdtm/dm.html#attributes",
    "title": "DM",
    "section": "Add Labels and Attributes",
    "text": "Add Labels and Attributes\nYet to be developed. Please refer to {metatools} package to investigate options.",
    "crumbs": [
      "SDTM",
      "DM"
    ]
  },
  {
    "objectID": "sdtm/vs.html",
    "href": "sdtm/vs.html",
    "title": "VS",
    "section": "",
    "text": "This article describes how to create a Findings SDTM domain using the {sdtm.oak} package. Examples are currently presented and tested in the context of the VS domain.\nBefore reading this article, it is recommended that users review some of the articles in the package documentation of {sdtm.oak} to understand some of the key concepts: Algorithms & Sub-Algorithms, Creating an Interventions Domain, which provides a detailed explanation of various concepts in {sdtm.oak}, such as oak_id_vars, condition_add, etc. It also offers guidance on which mapping algorithms or functions to use for different mappings and provides a more detailed explanation of how these mapping algorithms or functions work.\nIn this article, we will dive directly into programming and provide further explanation only where it is required.",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#readdata",
    "href": "sdtm/vs.html#readdata",
    "title": "VS",
    "section": "Read in data",
    "text": "Read in data\nRead all the raw datasets into the environment. In this example, the raw dataset name is vs_raw. Users can read it from the package using the below code:\n\nlibrary(sdtm.oak)\nlibrary(pharmaverseraw)\nlibrary(dplyr)\n\n# Read in input data\nvs_raw &lt;- pharmaverseraw::vs_raw\ndm &lt;- pharmaversesdtm::dm\n\nVital Signs Raw dataset\n\n\nSample of Data\n\n\n\n\n\nSDTM aCRF\nSDTM annotated CRF for the vs_raw can be viewed here:",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#oakidvars",
    "href": "sdtm/vs.html#oakidvars",
    "title": "VS",
    "section": "Create oak_id_vars",
    "text": "Create oak_id_vars\n\nvs_raw &lt;- vs_raw %&gt;%\n  generate_oak_id_vars(\n    pat_var = \"PATNUM\",\n    raw_src = \"vitals\"\n  )",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#readct",
    "href": "sdtm/vs.html#readct",
    "title": "VS",
    "section": "Read in CT",
    "text": "Read in CT\nControlled Terminology is part of the SDTM specification and it is prepared by the user. In this example, the study controlled terminology name is sdtm_ct.csv. Users can read it from the package using the below code:\n\nstudy_ct &lt;- read.csv(\"metadata/sdtm_ct.csv\")\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#maptopic",
    "href": "sdtm/vs.html#maptopic",
    "title": "VS",
    "section": "Map Topic Variable",
    "text": "Map Topic Variable\nThis raw dataset has multiple topic variables. Lets start with SYSBP. Map topic variable SYSBP from the raw variable SYS_BP.\n\n# Map topic variable SYSBP\nvs_sysbp &lt;-\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"SYS_BP\",\n    tgt_var = \"VSTESTCD\",\n    tgt_val = \"SYSBP\",\n    ct_spec = study_ct,\n    ct_clst = \"C66741\"\n  ) %&gt;%\n  # Filter for records where VSTESTCD is not empty.\n  # Only these records need qualifier mappings.\n  dplyr::filter(!is.na(.data$VSTESTCD))\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#maprest",
    "href": "sdtm/vs.html#maprest",
    "title": "VS",
    "section": "Map Rest of the Variables",
    "text": "Map Rest of the Variables\nMap rest of the variables applicable to the topic variable SYSBP. This can include qualifiers, identifier and timing variables.\n\n## Map Rest of the Variables\nvs_sysbp &lt;- vs_sysbp %&gt;%\n  # Map VSTEST using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"SYS_BP\",\n    tgt_var = \"VSTEST\",\n    tgt_val = \"Systolic Blood Pressure\",\n    ct_spec = study_ct,\n    ct_clst = \"C67153\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRES using assign_no_ct algorithm\n  assign_no_ct(\n    raw_dat = vs_raw,\n    raw_var = \"SYS_BP\",\n    tgt_var = \"VSORRES\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"SYS_BP\",\n    tgt_var = \"VSORRESU\",\n    tgt_val = \"mmHg\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSPOS using assign_ct algorithm\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"SUBPOS\",\n    tgt_var = \"VSPOS\",\n    ct_spec = study_ct,\n    ct_clst = \"C71148\",\n    id_vars = oak_id_vars()\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#repeatsteps",
    "href": "sdtm/vs.html#repeatsteps",
    "title": "VS",
    "section": "Repeat Map Topic and Map Rest",
    "text": "Repeat Map Topic and Map Rest\nThis raw data source has other topic variables DIABP, PULSE, HEIGHT, WEIGHT, TEMP and its corresponding qualifiers. Repeat mapping topic and qualifiers for each topic variable.\n\n# Repeat Map Topic and Map Rest\nvs_diabp &lt;-\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"DIA_BP\",\n    tgt_var = \"VSTESTCD\",\n    tgt_val = \"DIABP\",\n    ct_spec = study_ct,\n    ct_clst = \"C66741\"\n  ) %&gt;%\n  dplyr::filter(!is.na(.data$VSTESTCD)) %&gt;%\n  # Map VSTEST using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"DIA_BP\",\n    tgt_var = \"VSTEST\",\n    tgt_val = \"Diastolic Blood Pressure\",\n    ct_spec = study_ct,\n    ct_clst = \"C67153\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRES using assign_no_ct algorithm\n  assign_no_ct(\n    raw_dat = vs_raw,\n    raw_var = \"DIA_BP\",\n    tgt_var = \"VSORRES\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"DIA_BP\",\n    tgt_var = \"VSORRESU\",\n    tgt_val = \"mmHg\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSPOS using assign_ct algorithm\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"SUBPOS\",\n    tgt_var = \"VSPOS\",\n    ct_spec = study_ct,\n    ct_clst = \"C71148\",\n    id_vars = oak_id_vars()\n  )\n\n# Map topic variable PULSE and its qualifiers.\nvs_pulse &lt;-\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"PULSE\",\n    tgt_var = \"VSTESTCD\",\n    tgt_val = \"PULSE\",\n    ct_spec = study_ct,\n    ct_clst = \"C66741\"\n  ) %&gt;%\n  dplyr::filter(!is.na(.data$VSTESTCD)) %&gt;%\n  # Map VSTEST using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"PULSE\",\n    tgt_var = \"VSTEST\",\n    tgt_val = \"Pulse Rate\",\n    ct_spec = study_ct,\n    ct_clst = \"C67153\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRES using assign_no_ct algorithm\n  assign_no_ct(\n    raw_dat = vs_raw,\n    raw_var = \"PULSE\",\n    tgt_var = \"VSORRES\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"PULSE\",\n    tgt_var = \"VSORRESU\",\n    tgt_val = \"beats/min\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSPOS using assign_ct algorithm\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"SUBPOS\",\n    tgt_var = \"VSPOS\",\n    ct_spec = study_ct,\n    ct_clst = \"C71148\",\n    id_vars = oak_id_vars()\n  )\n\n# Map topic variable TEMP from raw variable TEMP and its qualifiers.\nvs_temp &lt;-\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.TEMP\",\n    tgt_var = \"VSTESTCD\",\n    tgt_val = \"TEMP\",\n    ct_spec = study_ct,\n    ct_clst = \"C66741\"\n  ) %&gt;%\n  dplyr::filter(!is.na(.data$VSTESTCD)) %&gt;%\n  # Map VSTEST using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.TEMP\",\n    tgt_var = \"VSTEST\",\n    tgt_val = \"Temperature\",\n    ct_spec = study_ct,\n    ct_clst = \"C67153\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRES using assign_no_ct algorithm\n  assign_no_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.TEMP\",\n    tgt_var = \"VSORRES\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.TEMP\",\n    tgt_var = \"VSORRESU\",\n    tgt_val = \"F\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSLOC from TEMPLOC using assign_ct\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.TEMP_LOC\",\n    tgt_var = \"VSLOC\",\n    ct_spec = study_ct,\n    ct_clst = \"C74456\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Create VSSTRESC by converting VSORRES from F to C\n  mutate(VSSTRESC = as.character(sprintf(\"%.2f\", (as.numeric(VSORRES) - 32) * 5 / 9))) %&gt;%\n  # Map VSSTRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.TEMP\",\n    tgt_var = \"VSSTRESU\",\n    tgt_val = \"C\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  )\n\n# Map topic variable HEIGHT from raw variable IT.HEIGHT_VSORRRES and its qualifiers.\nvs_height &lt;-\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.HEIGHT_VSORRES\",\n    tgt_var = \"VSTESTCD\",\n    tgt_val = \"HEIGHT\",\n    ct_spec = study_ct,\n    ct_clst = \"C66741\"\n  ) %&gt;%\n  dplyr::filter(!is.na(.data$VSTESTCD)) %&gt;%\n  # Map VSTEST using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.HEIGHT_VSORRES\",\n    tgt_var = \"VSTEST\",\n    tgt_val = \"Height\",\n    ct_spec = study_ct,\n    ct_clst = \"C67153\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRES using assign_no_ct algorithm\n  assign_no_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.HEIGHT_VSORRES\",\n    tgt_var = \"VSORRES\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.HEIGHT_VSORRES\",\n    tgt_var = \"VSORRESU\",\n    tgt_val = \"in\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Create VSSRESC by converting VSORRES from in to cm\n  mutate(VSSTRESC = as.character(sprintf(\"%.2f\", as.numeric(VSORRES) * 2.54))) %&gt;%\n  # Map VSSTRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.HEIGHT_VSORRES\",\n    tgt_var = \"VSSTRESU\",\n    tgt_val = \"cm\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  )\n\n# Map topic variable WEIGHT from raw variable IT.WEIGHT and its qualifiers.\nvs_weight &lt;-\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.WEIGHT\",\n    tgt_var = \"VSTESTCD\",\n    tgt_val = \"WEIGHT\",\n    ct_spec = study_ct,\n    ct_clst = \"C66741\"\n  ) %&gt;%\n  dplyr::filter(!is.na(.data$VSTESTCD)) %&gt;%\n  # Map VSTEST using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.WEIGHT\",\n    tgt_var = \"VSTEST\",\n    tgt_val = \"Weight\",\n    ct_spec = study_ct,\n    ct_clst = \"C67153\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRES using assign_no_ct algorithm\n  assign_no_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.WEIGHT\",\n    tgt_var = \"VSORRES\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSORRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.WEIGHT\",\n    tgt_var = \"VSORRESU\",\n    tgt_val = \"LB\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Create VSSTRESC by converting VSORRES from LB to KG\n  mutate(VSSTRESC = as.character(sprintf(\"%.2f\", as.numeric(VSORRES) / 2.20462))) %&gt;%\n  # Map VSSTRESU using hardcode_ct algorithm\n  hardcode_ct(\n    raw_dat = vs_raw,\n    raw_var = \"IT.WEIGHT\",\n    tgt_var = \"VSSTRESU\",\n    tgt_val = \"kg\",\n    ct_spec = study_ct,\n    ct_clst = \"C66770\",\n    id_vars = oak_id_vars()\n  )\n\nNow that all the topic variable and its qualifier mappings are complete, combine all the datasets and proceed with mapping qualifiers, identifiers and timing variables applicable to all topic variables.\n\n# Combine all the topic variables into a single data frame.\nvs_combined &lt;- dplyr::bind_rows(\n  vs_diabp, vs_height, vs_pulse,\n  vs_sysbp, vs_temp, vs_weight\n)\n\n\n# Map qualifiers common to all topic variables\nvs &lt;- vs_combined %&gt;%\n  # Map VSDTC using assign_ct algorithm\n  assign_datetime(\n    raw_dat = vs_raw,\n    raw_var = c(\"VTLD\"),\n    tgt_var = \"VSDTC\",\n    raw_fmt = c(list(c(\"d-m-y\", \"dd-mmm-yyyy\")))\n  ) %&gt;%\n  # Map VSTPT from TMPTC using assign_ct\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"TMPTC\",\n    tgt_var = \"VSTPT\",\n    ct_spec = study_ct,\n    ct_clst = \"TPT\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VSTPTNUM from TMPTC using assign_ct\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"TMPTC\",\n    tgt_var = \"VSTPTNUM\",\n    ct_spec = study_ct,\n    ct_clst = \"TPTNUM\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VISIT from INSTANCE using assign_ct\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"INSTANCE\",\n    tgt_var = \"VISIT\",\n    ct_spec = study_ct,\n    ct_clst = \"VISIT\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map VISITNUM from INSTANCE using assign_ct\n  assign_ct(\n    raw_dat = vs_raw,\n    raw_var = \"INSTANCE\",\n    tgt_var = \"VISITNUM\",\n    ct_spec = study_ct,\n    ct_clst = \"VISITNUM\",\n    id_vars = oak_id_vars()\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#derivedvars",
    "href": "sdtm/vs.html#derivedvars",
    "title": "VS",
    "section": "Create SDTM derived variables",
    "text": "Create SDTM derived variables\nCreate derived variables applicable to all topic variables.\n\nvs &lt;- vs %&gt;%\n  dplyr::mutate(\n    STUDYID = \"CDISCPILOT01\",\n    DOMAIN = \"VS\",\n    VSCAT = \"VITAL SIGNS\",\n    USUBJID = paste0(\"01\", \"-\", .data$patient_number),\n    VSSTRESC = ifelse(is.na(VSSTRESC), VSORRES, VSSTRESC),\n    VSSTRESN = as.numeric(VSSTRESC),\n    VSSTRESU = ifelse(is.na(VSSTRESU), VSORRESU, VSSTRESU),\n    VSELTM = ifelse(is.na(VSTPT), NA, paste0(\"PT\", readr::parse_number(VSTPT), \"M\")),\n    VSTPTREF = ifelse(is.na(VSPOS), NA, paste(\"PATIENT\", VSPOS))\n  ) %&gt;%\n  arrange(USUBJID, VSTESTCD, as.numeric(VISITNUM), as.numeric(VSTPTNUM)) %&gt;%\n  derive_seq(\n    tgt_var = \"VSSEQ\",\n    rec_vars = c(\"USUBJID\", \"VSTESTCD\")\n  ) %&gt;%\n  derive_study_day(\n    sdtm_in = .,\n    dm_domain = dm,\n    tgdt = \"VSDTC\",\n    refdt = \"RFXSTDTC\",\n    study_day_var = \"VSDY\"\n  ) %&gt;%\n  dplyr::select(\"STUDYID\", \"DOMAIN\", \"USUBJID\", \"VSSEQ\", \"VSTESTCD\", \"VSTEST\", \"VSPOS\", \"VSORRES\", \"VSORRESU\", \"VSSTRESC\", \"VSSTRESN\", \"VSSTRESU\", \"VSLOC\", \"VISITNUM\", \"VISIT\", \"VSDTC\", \"VSDY\", \"VSTPT\", \"VSTPTNUM\", \"VSELTM\", \"VSTPTREF\")\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "sdtm/vs.html#attributes",
    "href": "sdtm/vs.html#attributes",
    "title": "VS",
    "section": "Add Labels and Attributes",
    "text": "Add Labels and Attributes\nYet to be developed. Please refer to {metatools} package to investigate options.",
    "crumbs": [
      "SDTM",
      "VS"
    ]
  },
  {
    "objectID": "tlg/pharmacokinetic.html",
    "href": "tlg/pharmacokinetic.html",
    "title": "Pharmacokinetic",
    "section": "",
    "text": "This guide will show you how pharmaverse packages, along with some from tidyverse, can be used to create pharmacokinetic (PK) tables, listings and graphs, using the {pharmaverseadam} ADSL and ADPC data as an input.\nThe packages used with a brief description of their purpose are as follows:\n\n{rtables}: designed to create and display complex tables with R.\n{tern}: contains analysis functions to create tables and graphs used for clinical trial reporting.\n{rlistings}: contains framework for creating listings for clinical reporting.\n\nSee catalog for PK TLGs here PK TLG catalog\nSee the {admiral} Guide for creating a PK NCA ADaM for more information about the structure of ADPC. See also ADPC under the ADaM section on the left panel.",
    "crumbs": [
      "TLG",
      "Pharmacokinetic"
    ]
  },
  {
    "objectID": "tlg/pharmacokinetic.html#introduction",
    "href": "tlg/pharmacokinetic.html#introduction",
    "title": "Pharmacokinetic",
    "section": "",
    "text": "This guide will show you how pharmaverse packages, along with some from tidyverse, can be used to create pharmacokinetic (PK) tables, listings and graphs, using the {pharmaverseadam} ADSL and ADPC data as an input.\nThe packages used with a brief description of their purpose are as follows:\n\n{rtables}: designed to create and display complex tables with R.\n{tern}: contains analysis functions to create tables and graphs used for clinical trial reporting.\n{rlistings}: contains framework for creating listings for clinical reporting.\n\nSee catalog for PK TLGs here PK TLG catalog\nSee the {admiral} Guide for creating a PK NCA ADaM for more information about the structure of ADPC. See also ADPC under the ADaM section on the left panel.",
    "crumbs": [
      "TLG",
      "Pharmacokinetic"
    ]
  },
  {
    "objectID": "tlg/pharmacokinetic.html#data-preprocessing",
    "href": "tlg/pharmacokinetic.html#data-preprocessing",
    "title": "Pharmacokinetic",
    "section": "Data preprocessing",
    "text": "Data preprocessing\nHere we set up the data for the table, graph and listing. We will read ADPC and ADSL from {pharmaverseadam}. We use tern::df_explicit_na() to set missing values as categorical. In ADPC we will keep only concentration records (dropping dosing records), and for this example we will only keep plasma concentrations (dropping urine). The ADPC data also includes duplicated records for analysis with DYTPE == \"COPY\" we will drop these as well (These are removed by selecting ANL02FL == \"Y\").\n\nlibrary(pharmaverseadam)\nlibrary(tern)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(nestcolor)\nlibrary(rlistings)\n\n# Read data from pharmaverseadam\nadpc &lt;- pharmaverseadam::adpc\nadsl &lt;- pharmaverseadam::adsl\n\n# Use tern::df_explicit_na() to end encode missing values as categorical\nadsl &lt;- adsl %&gt;%\n  df_explicit_na()\n\nadpc &lt;- adpc %&gt;%\n  df_explicit_na()\n\n# For ADPC keep only concentration records and treated subjects\n# Keep only plasma records for this example\n# Remove DTYPE = COPY records with ANL02FL == \"Y\"\nadpc &lt;- adpc %&gt;%\n  filter(PARAMCD != \"DOSE\" & TRT01A != \"Placebo\" & PARCAT1 == \"PLASMA\" & ANL02FL == \"Y\")",
    "crumbs": [
      "TLG",
      "Pharmacokinetic"
    ]
  },
  {
    "objectID": "tlg/pharmacokinetic.html#pk-table",
    "href": "tlg/pharmacokinetic.html#pk-table",
    "title": "Pharmacokinetic",
    "section": "PK Table",
    "text": "PK Table\nNow we create the PK table.\n\n# Setting up the data for table\nadpc_t &lt;- adpc %&gt;%\n  mutate(\n    NFRLT = as.factor(NFRLT),\n    AVALCAT1 = as.factor(AVALCAT1),\n    NOMTPT = as.factor(paste(NFRLT, \"/\", PCTPT))\n  ) %&gt;%\n  select(NOMTPT, ACTARM, VISIT, AVAL, PARAM, AVALCAT1)\n\nadpc_t$NOMTPT &lt;- factor(\n  adpc_t$NOMTPT,\n  levels = levels(adpc_t$NOMTPT)[order(as.numeric(gsub(\".*?([0-9\\\\.]+).*\", \"\\\\1\", levels(adpc_t$NOMTPT))))]\n)\n\n# Row structure\nlyt_rows &lt;- basic_table() %&gt;%\n  split_rows_by(\n    var = \"ACTARM\",\n    split_fun = drop_split_levels,\n    split_label = \"Treatment Group\",\n    label_pos = \"topleft\"\n  ) %&gt;%\n  add_rowcounts(alt_counts = TRUE) %&gt;%\n  split_rows_by(\n    var = \"VISIT\",\n    split_fun = drop_split_levels,\n    split_label = \"Visit\",\n    label_pos = \"topleft\"\n  ) %&gt;%\n  split_rows_by(\n    var = \"NOMTPT\",\n    split_fun = drop_split_levels,\n    split_label = \"Nominal Time (hr) / Timepoint\",\n    label_pos = \"topleft\",\n    child_labels = \"hidden\"\n  )\n\nlyt &lt;- lyt_rows %&gt;%\n  analyze_vars_in_cols(\n    vars = c(\"AVAL\", \"AVALCAT1\", rep(\"AVAL\", 8)),\n    .stats = c(\"n\", \"n_blq\", \"mean\", \"sd\", \"cv\", \"geom_mean\", \"geom_cv\", \"median\", \"min\", \"max\"),\n    .formats = c(\n      n = \"xx.\", n_blq = \"xx.\", mean = format_sigfig(3), sd = format_sigfig(3), cv = \"xx.x\", median = format_sigfig(3),\n      geom_mean = format_sigfig(3), geom_cv = \"xx.x\", min = format_sigfig(3), max = format_sigfig(3)\n    ),\n    .labels = c(\n      n = \"n\", n_blq = \"Number\\nof\\nLTRs/BLQs\", mean = \"Mean\", sd = \"SD\", cv = \"CV (%) Mean\",\n      geom_mean = \"Geometric Mean\", geom_cv = \"CV % Geometric Mean\", median = \"Median\", min = \"Minimum\", max = \"Maximum\"\n    ),\n    na_str = \"NE\",\n    .aligns = \"decimal\"\n  )\n\nresult &lt;- build_table(lyt, df = adpc_t, alt_counts_df = adsl) %&gt;% prune_table()\n\n# Decorating\nmain_title(result) &lt;- \"Summary of PK Concentrations by Nominal Time and Treatment: PK Evaluable\"\nsubtitles(result) &lt;- c(\n  \"Protocol: xxxxx\",\n  paste(\"Analyte: \", unique(adpc_t$PARAM)),\n  paste(\"Treatment:\", unique(adpc_t$ACTARM))\n)\nmain_footer(result) &lt;- \"NE: Not Estimable\"\n\nresult\n\nSummary of PK Concentrations by Nominal Time and Treatment: PK Evaluable\nProtocol: xxxxx\nAnalyte:  Pharmacokinetic concentration of Xanomeline\nTreatment: Xanomeline High Dose\nTreatment: Xanomeline Low Dose\n\n———————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\nTreatment Group                           Number                                                                                                       \n  Visit                                     of                                                                                                         \n    Nominal Time (hr) / Timepoint   n    LTRs/BLQs    Mean      SD      CV (%) Mean   Geometric Mean   CV % Geometric Mean   Median   Minimum   Maximum\n———————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\nXanomeline High Dose (N=72)                                                                                                                            \n  BASELINE                                                                                                                                             \n    0 / Pre-dose                    72      72       0        0             NE              NE                 NE            0        0         0      \n    0.08 / 5 Min Post-dose          72       0       0.100    0.00489       4.9           0.100                4.9           0.100    0.0912    0.112  \n    0.5 / 30 Min Post-dose          72       0       0.544    0.0241        4.4           0.543                4.4           0.543    0.499     0.603  \n    1 / 1h Post-dose                72       0       0.927    0.0370        4.0           0.926                4.0           0.926    0.859     1.02   \n    1.5 / 1.5h Post-dose            72       0       1.20     0.0438        3.7           1.20                 3.6           1.20     1.12      1.31   \n    2 / 2h Post-dose                72       0       1.39     0.0474        3.4           1.39                 3.4           1.38     1.31      1.50   \n    4 / 4h Post-dose                72       0       1.73     0.0521        3.0           1.73                 3.0           1.73     1.65      1.84   \n    6 / 6h Post-dose                72       0       1.82     0.0538        3.0           1.82                 3.0           1.82     1.74      1.92   \n    8 / 8h Post-dose                72       0       1.84     0.0545        3.0           1.84                 3.0           1.84     1.76      1.94   \n    12 / 12h Post-dose              72       0       0.551    0.0341        6.2           0.550                6.2           0.554    0.486     0.619  \n    16 / 16h Post-dose              72       0       0.165    0.0181       11.0           0.164               11.1           0.165    0.134     0.198  \n    24 / 24h Post-dose              72       0       0.0149   0.00311      20.9           0.0145              21.5           0.0146   0.0100    0.0203 \n    36 / 36h Post-dose               0      72         NE       NE          NE              NE                 NE              NE       NE        NE   \n    48 / 48h Post-dose               0      72         NE       NE          NE              NE                 NE              NE       NE        NE   \nXanomeline Low Dose (N=96)                                                                                                                             \n  BASELINE                                                                                                                                             \n    0 / Pre-dose                    96      96       0        0             NE              NE                 NE            0        0         0      \n    0.08 / 5 Min Post-dose          96       0       0.101    0.00531       5.3           0.101                5.3           0.100    0.0906    0.111  \n    0.5 / 30 Min Post-dose          96       0       0.546    0.0263        4.8           0.545                4.8           0.544    0.495     0.597  \n    1 / 1h Post-dose                96       0       0.931    0.0406        4.4           0.930                4.4           0.927    0.852     1.01   \n    1.5 / 1.5h Post-dose            96       0       1.20     0.0481        4.0           1.20                 4.0           1.20     1.11      1.29   \n    2 / 2h Post-dose                96       0       1.39     0.0518        3.7           1.39                 3.7           1.39     1.29      1.49   \n    4 / 4h Post-dose                96       0       1.74     0.0547        3.2           1.74                 3.2           1.74     1.64      1.83   \n    6 / 6h Post-dose                96       0       1.82     0.0548        3.0           1.82                 3.0           1.82     1.73      1.91   \n    8 / 8h Post-dose                96       0       1.84     0.0548        3.0           1.84                 3.0           1.84     1.75      1.94   \n    12 / 12h Post-dose              96       0       0.549    0.0297        5.4           0.548                5.4           0.548    0.489     0.620  \n    16 / 16h Post-dose              96       0       0.163    0.0163       10.0           0.163               10.0           0.161    0.135     0.200  \n    24 / 24h Post-dose              96       0       0.0146   0.00288      19.7           0.0143              19.8           0.0142   0.0102    0.0207 \n    36 / 36h Post-dose               0      96         NE       NE          NE              NE                 NE              NE       NE        NE   \n    48 / 48h Post-dose               0      96         NE       NE          NE              NE                 NE              NE       NE        NE   \n———————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n\nNE: Not Estimable",
    "crumbs": [
      "TLG",
      "Pharmacokinetic"
    ]
  },
  {
    "objectID": "tlg/pharmacokinetic.html#pk-graph",
    "href": "tlg/pharmacokinetic.html#pk-graph",
    "title": "Pharmacokinetic",
    "section": "PK Graph",
    "text": "PK Graph\nNow we create the PK graph.\n\n# Keep only treated subjects for graph\nadsl_f &lt;- adsl %&gt;%\n  filter(SAFFL == \"Y\" & TRT01A != \"Placebo\")\n\n# Set titles and footnotes\nuse_title &lt;- \"Plot of Mean (+/- SD) Plasma Concentrations Over Time by Treatment, \\nPK Evaluable Patients\"\nuse_subtitle &lt;- \"Analyte:\"\nuse_footnote &lt;- \"Program: \\nOutput:\"\n\nresult &lt;- g_lineplot(\n  df = adpc,\n  variables = control_lineplot_vars(\n    x = \"NFRLT\",\n    y = \"AVAL\",\n    group_var = \"ARM\",\n    paramcd = \"PARAM\",\n    y_unit = \"AVALU\",\n    subject_var = \"USUBJID\"\n  ),\n  alt_counts_df = adsl_f,\n  position = ggplot2::position_dodge2(width = 0.5),\n  y_lab = \"Concentration\",\n  y_lab_add_paramcd = FALSE,\n  y_lab_add_unit = TRUE,\n  interval = \"mean_sdi\",\n  whiskers = c(\"mean_sdi_lwr\", \"mean_sdi_upr\"),\n  title = use_title,\n  subtitle = use_subtitle,\n  caption = use_footnote,\n  ggtheme = theme_nest()\n)\n\nplot &lt;- result + theme(plot.caption = element_text(hjust = 0))\nplot",
    "crumbs": [
      "TLG",
      "Pharmacokinetic"
    ]
  },
  {
    "objectID": "tlg/pharmacokinetic.html#pk-listing",
    "href": "tlg/pharmacokinetic.html#pk-listing",
    "title": "Pharmacokinetic",
    "section": "PK Listing",
    "text": "PK Listing\nNow we create an example PK listing.\n\n# Get value of Analyte\nanalyte &lt;- unique(adpc$PARAM)\n\n# Select columns for listing\nout &lt;- adpc %&gt;%\n  select(ARM, USUBJID, VISIT, NFRLT, AFRLT, AVALCAT1)\n\n# Add descriptive labels\nvar_labels(out) &lt;- c(\n  ARM = \"Treatment Group\",\n  USUBJID = \"Subject ID\",\n  VISIT = \"Visit\",\n  NFRLT = paste0(\"Nominal\\nSampling\\nTime (\", adpc$RRLTU[1], \")\"),\n  AFRLT = paste0(\"Actual Time\\nFrom First\\nDose (\", adpc$RRLTU[1], \")\"),\n  AVALCAT1 = paste0(\"Concentration\\n(\", adpc$AVALU[1], \")\")\n)\n\n# Create listing\nlsting &lt;- as_listing(\n  out,\n  key_cols = c(\"ARM\", \"USUBJID\", \"VISIT\"),\n  disp_cols = names(out),\n  default_formatting = list(\n    all = fmt_config(align = \"left\"),\n    numeric = fmt_config(\n      format = \"xx.xx\",\n      na_str = \" \",\n      align = \"right\"\n    )\n  ),\n  main_title = paste(\n    \"Listing of\",\n    analyte,\n    \"Concentration by Treatment Group, Subject and Nominal Time, PK Population\\nProtocol: xxnnnnn\"\n  ),\n  subtitles = paste(\"Analyte:\", analyte)\n)\n\nhead(lsting, 28)\n\nListing of Pharmacokinetic concentration of Xanomeline Concentration by Treatment Group, Subject and Nominal Time, PK Population\nProtocol: xxnnnnn\nAnalyte: Pharmacokinetic concentration of Xanomeline\n\n——————————————————————————————————————————————————————————————————————————————————————\n                                                Nominal    Actual Time                \n                                                Sampling   From First    Concentration\n  Treatment Group      Subject ID     Visit     Time (h)    Dose (h)        (ug/ml)   \n——————————————————————————————————————————————————————————————————————————————————————\nXanomeline High Dose   01-701-1028   BASELINE       0.00         -0.50   &lt;BLQ         \n                                                    0.08          0.08   0.102        \n                                                    0.50          0.50   0.547        \n                                                    1.00          1.00   0.925        \n                                                    1.50          1.50   1.19         \n                                                    2.00          2.00   1.37         \n                                                    4.00          4.00   1.68         \n                                                    6.00          6.00   1.76         \n                                                    8.00          8.00   1.77         \n                                                   12.00         12.00   0.495        \n                                                   16.00         16.00   0.138        \n                                                   24.00         24.00   0.0107       \n                                                   36.00         36.00   &lt;BLQ         \n                                                   48.00         48.00   &lt;BLQ         \n                       01-701-1034   BASELINE       0.00         -0.50   &lt;BLQ         \n                                                    0.08          0.08   0.105        \n                                                    0.50          0.50   0.569        \n                                                    1.00          1.00   0.967        \n                                                    1.50          1.50   1.25         \n                                                    2.00          2.00   1.44         \n                                                    4.00          4.00   1.79         \n                                                    6.00          6.00   1.88         \n                                                    8.00          8.00   1.9          \n                                                   12.00         12.00   0.556        \n                                                   16.00         16.00   0.162        \n                                                   24.00         24.00   0.0138       \n                                                   36.00         36.00   &lt;BLQ         \n                                                   48.00         48.00   &lt;BLQ",
    "crumbs": [
      "TLG",
      "Pharmacokinetic"
    ]
  },
  {
    "objectID": "tlg/adverse_events.html",
    "href": "tlg/adverse_events.html",
    "title": "Adverse Events",
    "section": "",
    "text": "This guide will show you how pharmaverse packages, along with some from tidyverse, can be used to create an Adverse Events table, using the {pharmaverseadam} ADSL and ADAE data as an input.\nThe packages used with a brief description of their purpose are as follows:\n\n{rtables}: designed to create and display complex tables with R.\n{tern}: contains analysis functions to create tables and graphs used for clinical trial reporting.",
    "crumbs": [
      "TLG",
      "Adverse Events"
    ]
  },
  {
    "objectID": "tlg/adverse_events.html#introduction",
    "href": "tlg/adverse_events.html#introduction",
    "title": "Adverse Events",
    "section": "",
    "text": "This guide will show you how pharmaverse packages, along with some from tidyverse, can be used to create an Adverse Events table, using the {pharmaverseadam} ADSL and ADAE data as an input.\nThe packages used with a brief description of their purpose are as follows:\n\n{rtables}: designed to create and display complex tables with R.\n{tern}: contains analysis functions to create tables and graphs used for clinical trial reporting.",
    "crumbs": [
      "TLG",
      "Adverse Events"
    ]
  },
  {
    "objectID": "tlg/adverse_events.html#load-data-and-required-pharmaverse-package",
    "href": "tlg/adverse_events.html#load-data-and-required-pharmaverse-package",
    "title": "Adverse Events",
    "section": "Load Data and Required pharmaverse Package",
    "text": "Load Data and Required pharmaverse Package\nAfter installation of packages, the first step is to load our pharmaverse packages and input data. Here, we are going to encode missing entries in a data frame adsl and adae.\nNote that {tern} depends on {rtables} so the latter is automatically attached.\n\nlibrary(pharmaverseadam)\nlibrary(tern)\nlibrary(dplyr)\n\nadsl &lt;- adsl %&gt;%\n  df_explicit_na()\n\nadae &lt;- adae %&gt;%\n  df_explicit_na()",
    "crumbs": [
      "TLG",
      "Adverse Events"
    ]
  },
  {
    "objectID": "tlg/adverse_events.html#start-preprocessing",
    "href": "tlg/adverse_events.html#start-preprocessing",
    "title": "Adverse Events",
    "section": "Start preprocessing",
    "text": "Start preprocessing\nNow we will add some pre-processing to add labels ready for display in the table and how the output will be split.\n\nadae &lt;- adae %&gt;%\n  var_relabel(\n    AEBODSYS = \"MedDRA System Organ Class\",\n    AEDECOD = \"MedDRA Preferred Term\"\n  ) %&gt;%\n  filter(SAFFL == \"Y\")\n\n# Define the split function\nsplit_fun &lt;- drop_split_levels",
    "crumbs": [
      "TLG",
      "Adverse Events"
    ]
  },
  {
    "objectID": "tlg/adverse_events.html#adverse-events-table",
    "href": "tlg/adverse_events.html#adverse-events-table",
    "title": "Adverse Events",
    "section": "Adverse Events table",
    "text": "Adverse Events table\nNow we create the Adverse Events table.\n\nlyt &lt;- basic_table(show_colcounts = TRUE) %&gt;%\n  split_cols_by(var = \"ACTARM\") %&gt;%\n  add_overall_col(label = \"All Patients\") %&gt;%\n  analyze_num_patients(\n    vars = \"USUBJID\",\n    .stats = c(\"unique\", \"nonunique\"),\n    .labels = c(\n      unique = \"Total number of patients with at least one adverse event\",\n      nonunique = \"Overall total number of events\"\n    )\n  ) %&gt;%\n  split_rows_by(\n    \"AEBODSYS\",\n    child_labels = \"visible\",\n    nested = FALSE,\n    split_fun = split_fun,\n    label_pos = \"topleft\",\n    split_label = obj_label(adae$AEBODSYS)\n  ) %&gt;%\n  summarize_num_patients(\n    var = \"USUBJID\",\n    .stats = c(\"unique\", \"nonunique\"),\n    .labels = c(\n      unique = \"Total number of patients with at least one adverse event\",\n      nonunique = \"Total number of events\"\n    )\n  ) %&gt;%\n  count_occurrences(\n    vars = \"AEDECOD\",\n    .indent_mods = -1L\n  ) %&gt;%\n  append_varlabels(adae, \"AEDECOD\", indent = 1L)\n\nresult &lt;- build_table(lyt, df = adae, alt_counts_df = adsl)\n\nresult\n\nMedDRA System Organ Class                                              Placebo     Xanomeline High Dose   Xanomeline Low Dose   All Patients\n  MedDRA Preferred Term                                                 (N=86)            (N=72)                (N=96)            (N=306)   \n————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\nTotal number of patients with at least one adverse event              69 (80.2%)        70 (97.2%)            86 (89.6%)        225 (73.5%) \nOverall total number of events                                           301               436                    454               1191    \nCARDIAC DISORDERS                                                                                                                           \n  Total number of patients with at least one adverse event            13 (15.1%)        15 (20.8%)            16 (16.7%)         44 (14.4%) \n  Total number of events                                                  27                30                    34                 91     \n  ATRIAL FIBRILLATION                                                  1 (1.2%)          2 (2.8%)              2 (2.1%)           5 (1.6%)  \n  ATRIAL FLUTTER                                                          0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  ATRIAL HYPERTROPHY                                                   1 (1.2%)             0                      0              1 (0.3%)  \n  ATRIOVENTRICULAR BLOCK FIRST DEGREE                                  1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  ATRIOVENTRICULAR BLOCK SECOND DEGREE                                 2 (2.3%)          1 (1.4%)              2 (2.1%)           5 (1.6%)  \n  BRADYCARDIA                                                          1 (1.2%)             0                      0              1 (0.3%)  \n  BUNDLE BRANCH BLOCK LEFT                                             1 (1.2%)             0                      0              1 (0.3%)  \n  BUNDLE BRANCH BLOCK RIGHT                                            1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  CARDIAC DISORDER                                                        0              1 (1.4%)                  0              1 (0.3%)  \n  CARDIAC FAILURE CONGESTIVE                                           1 (1.2%)             0                      0              1 (0.3%)  \n  MYOCARDIAL INFARCTION                                                4 (4.7%)          4 (5.6%)              2 (2.1%)          10 (3.3%)  \n  PALPITATIONS                                                            0                 0                  2 (2.1%)           2 (0.7%)  \n  SINUS ARRHYTHMIA                                                     1 (1.2%)             0                      0              1 (0.3%)  \n  SINUS BRADYCARDIA                                                    2 (2.3%)         8 (11.1%)              7 (7.3%)          17 (5.6%)  \n  SUPRAVENTRICULAR EXTRASYSTOLES                                       1 (1.2%)          1 (1.4%)              1 (1.0%)           3 (1.0%)  \n  SUPRAVENTRICULAR TACHYCARDIA                                            0                 0                  1 (1.0%)           1 (0.3%)  \n  TACHYCARDIA                                                          1 (1.2%)             0                      0              1 (0.3%)  \n  VENTRICULAR EXTRASYSTOLES                                               0              1 (1.4%)              2 (2.1%)           3 (1.0%)  \n  VENTRICULAR HYPERTROPHY                                              1 (1.2%)             0                      0              1 (0.3%)  \n  WOLFF-PARKINSON-WHITE SYNDROME                                          0                 0                  1 (1.0%)           1 (0.3%)  \nCONGENITAL, FAMILIAL AND GENETIC DISORDERS                                                                                                  \n  Total number of patients with at least one adverse event                0              2 (2.8%)              1 (1.0%)           3 (1.0%)  \n  Total number of events                                                  0                 2                      1                 3      \n  VENTRICULAR SEPTAL DEFECT                                               0              2 (2.8%)              1 (1.0%)           3 (1.0%)  \nEAR AND LABYRINTH DISORDERS                                                                                                                 \n  Total number of patients with at least one adverse event             1 (1.2%)          1 (1.4%)              2 (2.1%)           4 (1.3%)  \n  Total number of events                                                  2                 1                      3                 6      \n  CERUMEN IMPACTION                                                       0                 0                  1 (1.0%)           1 (0.3%)  \n  EAR PAIN                                                             1 (1.2%)             0                      0              1 (0.3%)  \n  TINNITUS                                                                0                 0                  1 (1.0%)           1 (0.3%)  \n  VERTIGO                                                                 0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \nEYE DISORDERS                                                                                                                               \n  Total number of patients with at least one adverse event             4 (4.7%)          1 (1.4%)              2 (2.1%)           7 (2.3%)  \n  Total number of events                                                  8                 2                      2                 12     \n  CONJUNCTIVAL HAEMORRHAGE                                                0                 0                  1 (1.0%)           1 (0.3%)  \n  CONJUNCTIVITIS                                                       2 (2.3%)             0                      0              2 (0.7%)  \n  EYE ALLERGY                                                          1 (1.2%)             0                      0              1 (0.3%)  \n  EYE PRURITUS                                                         1 (1.2%)             0                      0              1 (0.3%)  \n  EYE SWELLING                                                         1 (1.2%)             0                      0              1 (0.3%)  \n  GLAUCOMA                                                             1 (1.2%)             0                      0              1 (0.3%)  \n  VISION BLURRED                                                          0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \nGASTROINTESTINAL DISORDERS                                                                                                                  \n  Total number of patients with at least one adverse event            17 (19.8%)        20 (27.8%)            16 (16.7%)         53 (17.3%) \n  Total number of events                                                  26                35                    26                 87     \n  ABDOMINAL DISCOMFORT                                                    0              1 (1.4%)                  0              1 (0.3%)  \n  ABDOMINAL PAIN                                                       1 (1.2%)          1 (1.4%)              3 (3.1%)           5 (1.6%)  \n  CONSTIPATION                                                         1 (1.2%)             0                      0              1 (0.3%)  \n  DIARRHOEA                                                           9 (10.5%)          3 (4.2%)              6 (6.2%)          18 (5.9%)  \n  DYSPEPSIA                                                            1 (1.2%)          1 (1.4%)              1 (1.0%)           3 (1.0%)  \n  DYSPHAGIA                                                               0                 0                  1 (1.0%)           1 (0.3%)  \n  FLATULENCE                                                           1 (1.2%)             0                      0              1 (0.3%)  \n  GASTROINTESTINAL HAEMORRHAGE                                            0              1 (1.4%)                  0              1 (0.3%)  \n  GASTROOESOPHAGEAL REFLUX DISEASE                                     1 (1.2%)             0                      0              1 (0.3%)  \n  GLOSSITIS                                                            1 (1.2%)             0                      0              1 (0.3%)  \n  HIATUS HERNIA                                                        1 (1.2%)             0                      0              1 (0.3%)  \n  NAUSEA                                                               3 (3.5%)          6 (8.3%)              3 (3.1%)          12 (3.9%)  \n  RECTAL HAEMORRHAGE                                                      0                 0                  1 (1.0%)           1 (0.3%)  \n  SALIVARY HYPERSECRETION                                                 0              4 (5.6%)                  0              4 (1.3%)  \n  STOMACH DISCOMFORT                                                      0              1 (1.4%)                  0              1 (0.3%)  \n  VOMITING                                                             3 (3.5%)          6 (8.3%)              4 (4.2%)          13 (4.2%)  \nGENERAL DISORDERS AND ADMINISTRATION SITE CONDITIONS                                                                                        \n  Total number of patients with at least one adverse event            21 (24.4%)        36 (50.0%)            51 (53.1%)        108 (35.3%) \n  Total number of events                                                  48               118                    126               292     \n  APPLICATION SITE BLEEDING                                               0                 0                  1 (1.0%)           1 (0.3%)  \n  APPLICATION SITE DERMATITIS                                          5 (5.8%)          7 (9.7%)              9 (9.4%)          21 (6.9%)  \n  APPLICATION SITE DESQUAMATION                                           0                 0                  1 (1.0%)           1 (0.3%)  \n  APPLICATION SITE DISCHARGE                                              0              1 (1.4%)                  0              1 (0.3%)  \n  APPLICATION SITE DISCOLOURATION                                         0                 0                  1 (1.0%)           1 (0.3%)  \n  APPLICATION SITE ERYTHEMA                                            3 (3.5%)         14 (19.4%)            13 (13.5%)         30 (9.8%)  \n  APPLICATION SITE INDURATION                                          1 (1.2%)             0                      0              1 (0.3%)  \n  APPLICATION SITE IRRITATION                                          3 (3.5%)         9 (12.5%)              9 (9.4%)          21 (6.9%)  \n  APPLICATION SITE PAIN                                                   0              2 (2.8%)                  0              2 (0.7%)  \n  APPLICATION SITE PERSPIRATION                                           0              2 (2.8%)                  0              2 (0.7%)  \n  APPLICATION SITE PRURITUS                                            6 (7.0%)         21 (29.2%)            23 (24.0%)         50 (16.3%) \n  APPLICATION SITE REACTION                                            1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \n  APPLICATION SITE SWELLING                                               0              2 (2.8%)              1 (1.0%)           3 (1.0%)  \n  APPLICATION SITE URTICARIA                                              0              1 (1.4%)              2 (2.1%)           3 (1.0%)  \n  APPLICATION SITE VESICLES                                            1 (1.2%)          5 (6.9%)              5 (5.2%)          11 (3.6%)  \n  APPLICATION SITE WARMTH                                                 0                 0                  1 (1.0%)           1 (0.3%)  \n  ASTHENIA                                                             1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  CHEST DISCOMFORT                                                        0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  CHEST PAIN                                                              0              2 (2.8%)                  0              2 (0.7%)  \n  CHILLS                                                               1 (1.2%)          1 (1.4%)              1 (1.0%)           3 (1.0%)  \n  CYST                                                                    0                 0                  1 (1.0%)           1 (0.3%)  \n  FATIGUE                                                              1 (1.2%)          5 (6.9%)              5 (5.2%)          11 (3.6%)  \n  FEELING ABNORMAL                                                        0              1 (1.4%)                  0              1 (0.3%)  \n  FEELING COLD                                                            0              1 (1.4%)                  0              1 (0.3%)  \n  INFLAMMATION                                                            0                 0                  1 (1.0%)           1 (0.3%)  \n  MALAISE                                                                 0              2 (2.8%)              1 (1.0%)           3 (1.0%)  \n  OEDEMA                                                                  0                 0                  2 (2.1%)           2 (0.7%)  \n  OEDEMA PERIPHERAL                                                    2 (2.3%)          2 (2.8%)              1 (1.0%)           5 (1.6%)  \n  PAIN                                                                    0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  PYREXIA                                                              2 (2.3%)             0                  1 (1.0%)           3 (1.0%)  \n  SECRETION DISCHARGE                                                     0                 0                  1 (1.0%)           1 (0.3%)  \n  SUDDEN DEATH                                                            0                 0                  1 (1.0%)           1 (0.3%)  \n  SWELLING                                                                0                 0                  1 (1.0%)           1 (0.3%)  \n  ULCER                                                                   0                 0                  1 (1.0%)           1 (0.3%)  \nHEPATOBILIARY DISORDERS                                                                                                                     \n  Total number of patients with at least one adverse event             1 (1.2%)             0                      0              1 (0.3%)  \n  Total number of events                                                  1                 0                      0                 1      \n  HYPERBILIRUBINAEMIA                                                  1 (1.2%)             0                      0              1 (0.3%)  \nIMMUNE SYSTEM DISORDERS                                                                                                                     \n  Total number of patients with at least one adverse event                0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  Total number of events                                                  0                 1                      2                 3      \n  HYPERSENSITIVITY                                                        0                 0                  1 (1.0%)           1 (0.3%)  \n  SEASONAL ALLERGY                                                        0              1 (1.4%)                  0              1 (0.3%)  \nINFECTIONS AND INFESTATIONS                                                                                                                 \n  Total number of patients with at least one adverse event            16 (18.6%)        13 (18.1%)            10 (10.4%)         39 (12.7%) \n  Total number of events                                                  35                20                    18                 73     \n  BRONCHITIS                                                           1 (1.2%)             0                      0              1 (0.3%)  \n  CELLULITIS                                                              0                 0                  1 (1.0%)           1 (0.3%)  \n  CERVICITIS                                                           1 (1.2%)             0                      0              1 (0.3%)  \n  CYSTITIS                                                             1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \n  EAR INFECTION                                                        2 (2.3%)             0                      0              2 (0.7%)  \n  GASTROENTERITIS VIRAL                                                1 (1.2%)             0                      0              1 (0.3%)  \n  HORDEOLUM                                                               0              1 (1.4%)                  0              1 (0.3%)  \n  INFLUENZA                                                            1 (1.2%)          1 (1.4%)              1 (1.0%)           3 (1.0%)  \n  LOCALISED INFECTION                                                  1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  LOWER RESPIRATORY TRACT INFECTION                                       0              1 (1.4%)                  0              1 (0.3%)  \n  NASOPHARYNGITIS                                                      2 (2.3%)          6 (8.3%)              4 (4.2%)          12 (3.9%)  \n  ONYCHOMYCOSIS                                                           0                 0                  1 (1.0%)           1 (0.3%)  \n  PNEUMONIA                                                               0                 0                  1 (1.0%)           1 (0.3%)  \n  RHINITIS                                                                0              1 (1.4%)                  0              1 (0.3%)  \n  UPPER RESPIRATORY TRACT INFECTION                                    6 (7.0%)          3 (4.2%)              1 (1.0%)          10 (3.3%)  \n  URINARY TRACT INFECTION                                              2 (2.3%)          1 (1.4%)                  0              3 (1.0%)  \n  VAGINAL MYCOSIS                                                      1 (1.2%)             0                      0              1 (0.3%)  \n  VIRAL INFECTION                                                         0                 0                  1 (1.0%)           1 (0.3%)  \nINJURY, POISONING AND PROCEDURAL COMPLICATIONS                                                                                              \n  Total number of patients with at least one adverse event             4 (4.7%)          5 (6.9%)              5 (5.2%)          14 (4.6%)  \n  Total number of events                                                  9                 8                     12                 29     \n  CONTUSION                                                            1 (1.2%)          2 (2.8%)              1 (1.0%)           4 (1.3%)  \n  EXCORIATION                                                          2 (2.3%)          1 (1.4%)              1 (1.0%)           4 (1.3%)  \n  FACIAL BONES FRACTURE                                                   0              1 (1.4%)                  0              1 (0.3%)  \n  FALL                                                                 1 (1.2%)          1 (1.4%)              2 (2.1%)           4 (1.3%)  \n  HIP FRACTURE                                                         1 (1.2%)          2 (2.8%)                  0              3 (1.0%)  \n  JOINT DISLOCATION                                                       0                 0                  1 (1.0%)           1 (0.3%)  \n  SKIN LACERATION                                                      1 (1.2%)             0                  2 (2.1%)           3 (1.0%)  \n  WOUND                                                                   0                 0                  1 (1.0%)           1 (0.3%)  \nINVESTIGATIONS                                                                                                                              \n  Total number of patients with at least one adverse event            10 (11.6%)         5 (6.9%)              8 (8.3%)          23 (7.5%)  \n  Total number of events                                                  19                6                     15                 40     \n  BIOPSY                                                                  0              1 (1.4%)                  0              1 (0.3%)  \n  BIOPSY PROSTATE                                                         0              1 (1.4%)                  0              1 (0.3%)  \n  BLOOD ALKALINE PHOSPHATASE INCREASED                                 1 (1.2%)             0                      0              1 (0.3%)  \n  BLOOD CHOLESTEROL INCREASED                                             0              1 (1.4%)                  0              1 (0.3%)  \n  BLOOD CREATINE PHOSPHOKINASE INCREASED                               1 (1.2%)             0                      0              1 (0.3%)  \n  BLOOD GLUCOSE INCREASED                                                 0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  BLOOD URINE PRESENT                                                  1 (1.2%)             0                      0              1 (0.3%)  \n  BODY TEMPERATURE INCREASED                                              0                 0                  1 (1.0%)           1 (0.3%)  \n  CYSTOSCOPY                                                           1 (1.2%)             0                      0              1 (0.3%)  \n  ELECTROCARDIOGRAM ST SEGMENT DEPRESSION                              4 (4.7%)             0                  1 (1.0%)           5 (1.6%)  \n  ELECTROCARDIOGRAM T WAVE AMPLITUDE DECREASED                         1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  ELECTROCARDIOGRAM T WAVE INVERSION                                   2 (2.3%)          1 (1.4%)              1 (1.0%)           4 (1.3%)  \n  HEART RATE INCREASED                                                 1 (1.2%)             0                      0              1 (0.3%)  \n  HEART RATE IRREGULAR                                                 1 (1.2%)             0                      0              1 (0.3%)  \n  NASAL MUCOSA BIOPSY                                                     0                 0                  1 (1.0%)           1 (0.3%)  \n  NEUTROPHIL COUNT INCREASED                                              0                 0                  1 (1.0%)           1 (0.3%)  \n  URINE ANALYSIS ABNORMAL                                                 0                 0                  1 (1.0%)           1 (0.3%)  \n  WEIGHT DECREASED                                                        0                 0                  1 (1.0%)           1 (0.3%)  \n  WHITE BLOOD CELL COUNT INCREASED                                        0                 0                  1 (1.0%)           1 (0.3%)  \nMETABOLISM AND NUTRITION DISORDERS                                                                                                          \n  Total number of patients with at least one adverse event             6 (7.0%)          3 (4.2%)              1 (1.0%)          10 (3.3%)  \n  Total number of events                                                  8                 5                      1                 14     \n  DECREASED APPETITE                                                   1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \n  DEHYDRATION                                                          1 (1.2%)             0                      0              1 (0.3%)  \n  DIABETES MELLITUS                                                    1 (1.2%)             0                      0              1 (0.3%)  \n  FOOD CRAVING                                                         1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  HYPERCHOLESTEROLAEMIA                                                   0              1 (1.4%)                  0              1 (0.3%)  \n  HYPONATRAEMIA                                                        1 (1.2%)             0                      0              1 (0.3%)  \n  INCREASED APPETITE                                                   1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \nMUSCULOSKELETAL AND CONNECTIVE TISSUE DISORDERS                                                                                             \n  Total number of patients with at least one adverse event             5 (5.8%)         8 (11.1%)              7 (7.3%)          20 (6.5%)  \n  Total number of events                                                  8                 11                    10                 29     \n  ARTHRALGIA                                                           1 (1.2%)          1 (1.4%)              2 (2.1%)           4 (1.3%)  \n  ARTHRITIS                                                            1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \n  BACK PAIN                                                            1 (1.2%)          3 (4.2%)              1 (1.0%)           5 (1.6%)  \n  FLANK PAIN                                                              0              2 (2.8%)                  0              2 (0.7%)  \n  MUSCLE SPASMS                                                           0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  MUSCULAR WEAKNESS                                                       0                 0                  1 (1.0%)           1 (0.3%)  \n  MYALGIA                                                                 0              1 (1.4%)                  0              1 (0.3%)  \n  PAIN IN EXTREMITY                                                    1 (1.2%)             0                      0              1 (0.3%)  \n  SHOULDER PAIN                                                        1 (1.2%)             0                  2 (2.1%)           3 (1.0%)  \nNEOPLASMS BENIGN, MALIGNANT AND UNSPECIFIED (INCL CYSTS AND POLYPS)                                                                         \n  Total number of patients with at least one adverse event                0              1 (1.4%)              2 (2.1%)           3 (1.0%)  \n  Total number of events                                                  0                 1                      3                 4      \n  COLON CANCER                                                            0                 0                  1 (1.0%)           1 (0.3%)  \n  MALIGNANT FIBROUS HISTIOCYTOMA                                          0                 0                  1 (1.0%)           1 (0.3%)  \n  PROSTATE CANCER                                                         0              1 (1.4%)                  0              1 (0.3%)  \nNERVOUS SYSTEM DISORDERS                                                                                                                    \n  Total number of patients with at least one adverse event            12 (14.0%)        25 (34.7%)            22 (22.9%)         59 (19.3%) \n  Total number of events                                                  16                43                    42                101     \n  AMNESIA                                                                 0              1 (1.4%)                  0              1 (0.3%)  \n  BALANCE DISORDER                                                        0                 0                  1 (1.0%)           1 (0.3%)  \n  BURNING SENSATION                                                       0              2 (2.8%)                  0              2 (0.7%)  \n  COGNITIVE DISORDER                                                      0              1 (1.4%)                  0              1 (0.3%)  \n  COMPLEX PARTIAL SEIZURES                                                0                 0                  1 (1.0%)           1 (0.3%)  \n  COORDINATION ABNORMAL                                                   0                 0                  1 (1.0%)           1 (0.3%)  \n  DIZZINESS                                                            2 (2.3%)         11 (15.3%)             9 (9.4%)          22 (7.2%)  \n  HEADACHE                                                             7 (8.1%)          6 (8.3%)              3 (3.1%)          16 (5.2%)  \n  HEMIANOPIA HOMONYMOUS                                                   0                 0                  1 (1.0%)           1 (0.3%)  \n  HYPERSOMNIA                                                             0              1 (1.4%)                  0              1 (0.3%)  \n  LETHARGY                                                                0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  PARAESTHESIA                                                            0              1 (1.4%)                  0              1 (0.3%)  \n  PARAESTHESIA ORAL                                                       0                 0                  1 (1.0%)           1 (0.3%)  \n  PARKINSON'S DISEASE                                                  1 (1.2%)             0                      0              1 (0.3%)  \n  PAROSMIA                                                                0              1 (1.4%)                  0              1 (0.3%)  \n  PARTIAL SEIZURES WITH SECONDARY GENERALISATION                          0              1 (1.4%)                  0              1 (0.3%)  \n  PSYCHOMOTOR HYPERACTIVITY                                            1 (1.2%)             0                      0              1 (0.3%)  \n  SOMNOLENCE                                                           2 (2.3%)          1 (1.4%)              3 (3.1%)           6 (2.0%)  \n  STUPOR                                                                  0                 0                  1 (1.0%)           1 (0.3%)  \n  SYNCOPE                                                                 0              2 (2.8%)              5 (5.2%)           7 (2.3%)  \n  SYNCOPE VASOVAGAL                                                       0              1 (1.4%)                  0              1 (0.3%)  \n  TRANSIENT ISCHAEMIC ATTACK                                              0              1 (1.4%)              2 (2.1%)           3 (1.0%)  \nPSYCHIATRIC DISORDERS                                                                                                                       \n  Total number of patients with at least one adverse event            10 (11.6%)        8 (11.1%)             11 (11.5%)         29 (9.5%)  \n  Total number of events                                                  14                11                    15                 40     \n  AGITATION                                                            2 (2.3%)             0                  3 (3.1%)           5 (1.6%)  \n  ANXIETY                                                              1 (1.2%)             0                  3 (3.1%)           4 (1.3%)  \n  COMPLETED SUICIDE                                                    1 (1.2%)             0                      0              1 (0.3%)  \n  CONFUSIONAL STATE                                                    2 (2.3%)          1 (1.4%)              3 (3.1%)           6 (2.0%)  \n  DELIRIUM                                                                0              1 (1.4%)                  0              1 (0.3%)  \n  DELUSION                                                             1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \n  DEPRESSED MOOD                                                          0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  DISORIENTATION                                                       1 (1.2%)             0                      0              1 (0.3%)  \n  HALLUCINATION                                                           0              1 (1.4%)                  0              1 (0.3%)  \n  HALLUCINATION, VISUAL                                                   0              1 (1.4%)                  0              1 (0.3%)  \n  INSOMNIA                                                             2 (2.3%)          2 (2.8%)                  0              4 (1.3%)  \n  IRRITABILITY                                                         1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  LIBIDO DECREASED                                                        0              1 (1.4%)                  0              1 (0.3%)  \n  LISTLESS                                                                0              1 (1.4%)                  0              1 (0.3%)  \n  NIGHTMARE                                                               0              1 (1.4%)                  0              1 (0.3%)  \n  RESTLESSNESS                                                            0                 0                  1 (1.0%)           1 (0.3%)  \nRENAL AND URINARY DISORDERS                                                                                                                 \n  Total number of patients with at least one adverse event             4 (4.7%)          3 (4.2%)              4 (4.2%)          11 (3.6%)  \n  Total number of events                                                  5                 4                      4                 13     \n  CALCULUS URETHRAL                                                       0              1 (1.4%)                  0              1 (0.3%)  \n  DYSURIA                                                              1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  ENURESIS                                                                0                 0                  1 (1.0%)           1 (0.3%)  \n  INCONTINENCE                                                            0                 0                  1 (1.0%)           1 (0.3%)  \n  MICTURITION URGENCY                                                  1 (1.2%)          1 (1.4%)              1 (1.0%)           3 (1.0%)  \n  NEPHROLITHIASIS                                                      1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \n  POLLAKIURIA                                                          1 (1.2%)             0                      0              1 (0.3%)  \nREPRODUCTIVE SYSTEM AND BREAST DISORDERS                                                                                                    \n  Total number of patients with at least one adverse event             2 (2.3%)          1 (1.4%)                  0              3 (1.0%)  \n  Total number of events                                                  4                 1                      0                 5      \n  BENIGN PROSTATIC HYPERPLASIA                                         1 (1.2%)          1 (1.4%)                  0              2 (0.7%)  \n  PELVIC PAIN                                                          1 (1.2%)             0                      0              1 (0.3%)  \nRESPIRATORY, THORACIC AND MEDIASTINAL DISORDERS                                                                                             \n  Total number of patients with at least one adverse event            10 (11.6%)        10 (13.9%)            10 (10.4%)         30 (9.8%)  \n  Total number of events                                                  15                22                    16                 53     \n  ALLERGIC GRANULOMATOUS ANGIITIS                                         0              1 (1.4%)                  0              1 (0.3%)  \n  COUGH                                                                3 (3.5%)          5 (6.9%)              6 (6.2%)          14 (4.6%)  \n  DYSPHONIA                                                               0                 0                  1 (1.0%)           1 (0.3%)  \n  DYSPNOEA                                                             1 (1.2%)          1 (1.4%)              1 (1.0%)           3 (1.0%)  \n  EMPHYSEMA                                                            1 (1.2%)             0                      0              1 (0.3%)  \n  EPISTAXIS                                                               0              2 (2.8%)              1 (1.0%)           3 (1.0%)  \n  HAEMOPTYSIS                                                          1 (1.2%)             0                      0              1 (0.3%)  \n  NASAL CONGESTION                                                     3 (3.5%)          3 (4.2%)              1 (1.0%)           7 (2.3%)  \n  PHARYNGEAL ERYTHEMA                                                     0              1 (1.4%)                  0              1 (0.3%)  \n  PHARYNGOLARYNGEAL PAIN                                                  0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  POSTNASAL DRIP                                                       1 (1.2%)             0                      0              1 (0.3%)  \n  PRODUCTIVE COUGH                                                        0              1 (1.4%)                  0              1 (0.3%)  \n  RALES                                                                1 (1.2%)             0                      0              1 (0.3%)  \n  RESPIRATORY TRACT CONGESTION                                            0              1 (1.4%)                  0              1 (0.3%)  \n  RHINORRHOEA                                                             0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \nSKIN AND SUBCUTANEOUS TISSUE DISORDERS                                                                                                      \n  Total number of patients with at least one adverse event            21 (24.4%)        42 (58.3%)            42 (43.8%)        105 (34.3%) \n  Total number of events                                                  47               111                    118               276     \n  ACTINIC KERATOSIS                                                       0              1 (1.4%)                  0              1 (0.3%)  \n  ALOPECIA                                                             1 (1.2%)             0                      0              1 (0.3%)  \n  BLISTER                                                                 0              1 (1.4%)              5 (5.2%)           6 (2.0%)  \n  COLD SWEAT                                                           1 (1.2%)             0                      0              1 (0.3%)  \n  DERMATITIS ATOPIC                                                    1 (1.2%)             0                      0              1 (0.3%)  \n  DERMATITIS CONTACT                                                      0                 0                  1 (1.0%)           1 (0.3%)  \n  DRUG ERUPTION                                                        1 (1.2%)             0                      0              1 (0.3%)  \n  ERYTHEMA                                                            9 (10.5%)         14 (19.4%)            15 (15.6%)         38 (12.4%) \n  HYPERHIDROSIS                                                        2 (2.3%)         8 (11.1%)              4 (4.2%)          14 (4.6%)  \n  PRURITUS                                                             8 (9.3%)         26 (36.1%)            23 (24.0%)         57 (18.6%) \n  PRURITUS GENERALISED                                                    0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \n  RASH                                                                 5 (5.8%)         11 (15.3%)            13 (13.5%)         29 (9.5%)  \n  RASH ERYTHEMATOUS                                                       0                 0                  2 (2.1%)           2 (0.7%)  \n  RASH MACULO-PAPULAR                                                     0              1 (1.4%)                  0              1 (0.3%)  \n  RASH PAPULAR                                                            0              1 (1.4%)                  0              1 (0.3%)  \n  RASH PRURITIC                                                           0              2 (2.8%)              1 (1.0%)           3 (1.0%)  \n  SKIN EXFOLIATION                                                        0                 0                  1 (1.0%)           1 (0.3%)  \n  SKIN IRRITATION                                                      3 (3.5%)          5 (6.9%)              6 (6.2%)          14 (4.6%)  \n  SKIN ODOUR ABNORMAL                                                     0              1 (1.4%)                  0              1 (0.3%)  \n  SKIN ULCER                                                           1 (1.2%)             0                      0              1 (0.3%)  \n  URTICARIA                                                               0              1 (1.4%)              1 (1.0%)           2 (0.7%)  \nSOCIAL CIRCUMSTANCES                                                                                                                        \n  Total number of patients with at least one adverse event                0              1 (1.4%)                  0              1 (0.3%)  \n  Total number of events                                                  0                 1                      0                 1      \n  ALCOHOL USE                                                             0              1 (1.4%)                  0              1 (0.3%)  \nSURGICAL AND MEDICAL PROCEDURES                                                                                                             \n  Total number of patients with at least one adverse event             2 (2.3%)          2 (2.8%)              1 (1.0%)           5 (1.6%)  \n  Total number of events                                                  2                 2                      1                 5      \n  ACROCHORDON EXCISION                                                    0              1 (1.4%)                  0              1 (0.3%)  \n  CATARACT OPERATION                                                   1 (1.2%)             0                  1 (1.0%)           2 (0.7%)  \n  EYE LASER SURGERY                                                    1 (1.2%)             0                      0              1 (0.3%)  \n  SKIN LESION EXCISION                                                    0              1 (1.4%)                  0              1 (0.3%)  \nVASCULAR DISORDERS                                                                                                                          \n  Total number of patients with at least one adverse event             3 (3.5%)          1 (1.4%)              4 (4.2%)           8 (2.6%)  \n  Total number of events                                                  7                 1                      5                 13     \n  HOT FLUSH                                                               0                 0                  1 (1.0%)           1 (0.3%)  \n  HYPERTENSION                                                         1 (1.2%)             0                  2 (2.1%)           3 (1.0%)  \n  HYPOTENSION                                                          2 (2.3%)             0                  1 (1.0%)           3 (1.0%)  \n  ORTHOSTATIC HYPOTENSION                                              1 (1.2%)             0                      0              1 (0.3%)  \n  WOUND HAEMORRHAGE                                                       0              1 (1.4%)                  0              1 (0.3%)",
    "crumbs": [
      "TLG",
      "Adverse Events"
    ]
  },
  {
    "objectID": "digit_files/docx.html",
    "href": "digit_files/docx.html",
    "title": "Documents",
    "section": "",
    "text": "Below is a step-by-step guide demonstrating how to use {rtables.officer} for creating and exporting a clinical trial results table as a docx document.",
    "crumbs": [
      "Documents",
      "Documents"
    ]
  },
  {
    "objectID": "digit_files/docx.html#advanced-customizations",
    "href": "digit_files/docx.html#advanced-customizations",
    "title": "Documents",
    "section": "Advanced Customizations",
    "text": "Advanced Customizations\nYou can further customize your tables, such as setting column widths, handling pagination, and more.\n\nColumn Widths\n\ncw &lt;- propose_column_widths(result)\ncw &lt;- cw / sum(cw)\ncw &lt;- c(0.6, 0.1, 0.1, 0.1, 0.1)\nspd &lt;- section_properties_default(orientation = \"landscape\")\nfin_cw &lt;- cw * spd$page_size$width / 2 / sum(cw)\n\nflex_tbl &lt;- tt_to_flextable(result,\n  total_page_width = spd$page_size$width / 2,\n  counts_in_newline = TRUE,\n  autofit_to_page = FALSE,\n  bold_titles = TRUE,\n  colwidths = cw\n)\n\nexport_as_docx(flex_tbl, file = tf)\n\nWarning in FUN(X[[i]], ...): The total table width does not match the page\nwidth. The column widths will be resized to fit the page. Please consider\nmodifying the parameter total_page_width in tt_to_flextable().\n\nflex_tbl\n\nAlanine Aminotransferase MeasurementThis is a subtitle.This is another subtitle.ParameterPlacebo(N=1946)Xanomeline High Dose(N=1472)  Analysis VisitValue at VisitChange from BaselineValue at VisitChange from BaselineAlanine Aminotransferase (U/L)    Ambul Ecg Removal    n0000Mean (SD)NE (NE)NE (NE)NE (NE)NE (NE)MedianNENENENEMin - MaxNE - NENE - NENE - NENE - NEBaseline    n86 72 Mean (SD)17.57 (9.22) 19.17 (10.25) Median15.00 16.50 Min - Max7.00 - 69.00 6.00 - 64.00 POST-BASELINE LAST    n83837272Mean (SD)16.64 (10.83)-0.96 (8.08)18.90 (6.49)-0.15 (8.14)Median14.00-1.0018.501.00Min - Max3.00 - 95.00-31.00 - 45.008.00 - 43.00-38.00 - 18.00POST-BASELINE MAXIMUM    n83837272Mean (SD)23.94 (18.05)6.34 (14.68)26.67 (16.13)7.61 (14.55)Median19.004.0023.005.00Min - Max8.00 - 124.00-10.00 - 111.0011.00 - 129.00-10.00 - 119.00POST-BASELINE MINIMUM    n83837272Mean (SD)13.40 (10.41)-4.20 (7.69)16.12 (5.60)-2.93 (7.05)Median12.00-3.0015.00-2.00Min - Max3.00 - 95.00-34.00 - 45.007.00 - 35.00-38.00 - 9.00Retrieval    n0000Mean (SD)NE (NE)NE (NE)NE (NE)NE (NE)MedianNENENENEMin - MaxNE - NENE - NENE - NENE - NEUnscheduled 1.1    n8866Mean (SD)22.12 (13.78)0.00 (0.00)24.00 (18.58)0.50 (1.22)Median17.000.0016.500.00Min - Max14.00 - 55.000.00 - 0.0012.00 - 61.000.00 - 3.00Unscheduled 1.2    n1111Mean (SD)18.00 (NE (NE))0.00 (NE (NE))14.00 (NE (NE))0.00 (NE (NE))Median18.000.0014.000.00Min - Max18.00 - 18.000.00 - 0.0014.00 - 14.000.00 - 0.00Unscheduled 1.3    n1100Mean (SD)11.00 (NE (NE))0.00 (NE (NE))NE (NE)NE (NE)Median11.000.00NENEMin - Max11.00 - 11.000.00 - 0.00NE - NENE - NEUnscheduled 12.1    n1100Mean (SD)12.00 (NE (NE))-3.00 (NE (NE))NE (NE)NE (NE)Median12.00-3.00NENEMin - Max12.00 - 12.00-3.00 - -3.00NE - NENE - NEUnscheduled 13.1    n0000Mean (SD)NE (NE)NE (NE)NE (NE)NE (NE)MedianNENENENEMin - MaxNE - NENE - NENE - NENE - NEUnscheduled 4.1    n1100Mean (SD)95.00 (NE (NE))45.00 (NE (NE))NE (NE)NE (NE)Median95.0045.00NENEMin - Max95.00 - 95.0045.00 - 45.00NE - NENE - NEUnscheduled 4.2    n1100Mean (SD)92.00 (NE (NE))42.00 (NE (NE))NE (NE)NE (NE)Median92.0042.00NENEMin - Max92.00 - 92.0042.00 - 42.00NE - NENE - NEUnscheduled 5.1    n1100Mean (SD)73.00 (NE (NE))23.00 (NE (NE))NE (NE)NE (NE)Median73.0023.00NENEMin - Max73.00 - 73.0023.00 - 23.00NE - NENE - NEUnscheduled 6.1    n1100Mean (SD)17.00 (NE (NE))-5.00 (NE (NE))NE (NE)NE (NE)Median17.00-5.00NENEMin - Max17.00 - 17.00-5.00 - -5.00NE - NENE - NEUnscheduled 7.1    n0011Mean (SD)NE (NE)NE (NE)12.00 (NE (NE))1.00 (NE (NE))MedianNENE12.001.00Min - MaxNE - NENE - NE12.00 - 12.001.00 - 1.00Unscheduled 8.2    n1111Mean (SD)13.00 (NE (NE))1.00 (NE (NE))42.00 (NE (NE))32.00 (NE (NE))Median13.001.0042.0032.00Min - Max13.00 - 13.001.00 - 1.0042.00 - 42.0032.00 - 32.00Unscheduled 9.2    n1100Mean (SD)9.00 (NE (NE))0.00 (NE (NE))NE (NE)NE (NE)Median9.000.00NENEMin - Max9.00 - 9.000.00 - 0.00NE - NENE - NEWeek 12    n67675050Mean (SD)18.00 (9.16)0.16 (7.39)20.98 (10.18)0.90 (8.78)Median16.000.0019.001.00Min - Max6.00 - 64.00-21.00 - 34.009.00 - 70.00-38.00 - 20.00Week 16    n68683737Mean (SD)17.06 (7.39)-0.65 (6.84)19.57 (7.61)-0.03 (7.20)Median15.000.0019.001.00Min - Max5.00 - 48.00-34.00 - 14.007.00 - 38.00-26.00 - 17.00Week 2    n83837070Mean (SD)17.99 (12.53)0.29 (7.80)21.17 (8.87)2.19 (6.55)Median15.00-1.0019.002.00Min - Max6.00 - 104.00-14.00 - 54.008.00 - 49.00-31.00 - 17.00Week 20    n65653131Mean (SD)16.06 (6.56)-1.75 (6.24)19.58 (6.82)-0.26 (8.33)Median14.00-1.0019.001.00Min - Max7.00 - 48.00-34.00 - 18.009.00 - 35.00-26.00 - 13.00Week 24    n57573030Mean (SD)17.86 (15.61)-0.14 (16.19)20.97 (8.70)0.27 (8.00)Median14.00-2.0018.500.00Min - Max5.00 - 124.00-28.00 - 111.009.00 - 43.00-24.00 - 15.00Week 26    n57572727Mean (SD)16.02 (5.98)-1.84 (6.41)18.85 (7.02)-1.93 (6.65)Median15.00-1.0018.00-1.00Min - Max3.00 - 31.00-31.00 - 12.008.00 - 39.00-22.00 - 8.00Week 4    n79797272Mean (SD)18.66 (12.91)0.80 (8.50)21.31 (9.51)2.25 (7.00)Median16.000.0020.001.00Min - Max6.00 - 107.00-13.00 - 57.008.00 - 61.00-28.00 - 21.00Week 6    n73736666Mean (SD)16.96 (9.92)-0.37 (7.23)21.23 (9.49)1.71 (6.01)Median15.00-1.0019.002.00Min - Max4.00 - 76.00-15.00 - 46.0010.00 - 60.00-19.00 - 15.00Week 8    n72725656Mean (SD)16.72 (9.34)-0.96 (5.33)22.79 (17.49)3.34 (17.22)Median15.00-1.0018.001.00Min - Max7.00 - 63.00-17.00 - 14.0010.00 - 129.00-29.00 - 119.00Creatinine Kinase (U/L)    Ambul Ecg Removal    n0000Mean (SD)NE (NE)NE (NE)NE (NE)NE (NE)MedianNENENENEMin - MaxNE - NENE - NENE - NENE - NEBaseline    n86 72 Mean (SD)86.94 (43.71) 105.39 (73.94) Median80.00 81.00 Min - Max27.00 - 239.00 28.00 - 444.00 POST-BASELINE LAST    n83837272Mean (SD)104.99 (167.15)19.04 (159.63)96.31 (65.39)-9.17 (66.52)Median77.001.0079.50-6.50Min - Max18.00 - 1556.00-156.00 - 1414.0025.00 - 429.00-332.00 - 306.00POST-BASELINE MAXIMUM    n83837272Mean (SD)163.60 (215.36)77.65 (202.06)152.79 (218.53)47.32 (174.68)Median100.0026.00104.0018.50Min - Max29.00 - 1556.00-150.00 - 1414.0038.00 - 1860.00-92.00 - 1416.00POST-BASELINE MINIMUM    n83837272Mean (SD)66.78 (29.37)-19.17 (28.88)74.40 (37.17)-31.07 (50.64)Median62.00-13.0066.50-18.00Min - Max18.00 - 140.00-164.00 - 51.0025.00 - 212.00-344.00 - 25.00Retrieval    n0000Mean (SD)NE (NE)NE (NE)NE (NE)NE (NE)MedianNENENENEMin - MaxNE - NENE - NENE - NENE - NEUnscheduled 1.1    n8866Mean (SD)71.50 (17.11)0.00 (0.00)100.17 (53.82)-4.33 (10.61)Median69.500.0079.000.00Min - Max41.00 - 92.000.00 - 0.0068.00 - 209.00-26.00 - 0.00Unscheduled 1.2    n1111Mean (SD)182.00 (NE (NE))0.00 (NE (NE))108.00 (NE (NE))0.00 (NE (NE))Median182.000.00108.000.00Min - Max182.00 - 182.000.00 - 0.00108.00 - 108.000.00 - 0.00Unscheduled 1.3    n1100Mean (SD)85.00 (NE (NE))0.00 (NE (NE))NE (NE)NE (NE)Median85.000.00NENEMin - Max85.00 - 85.000.00 - 0.00NE - NENE - NEUnscheduled 12.1    n1100Mean (SD)59.00 (NE (NE))-2.00 (NE (NE))NE (NE)NE (NE)Median59.00-2.00NENEMin - Max59.00 - 59.00-2.00 - -2.00NE - NENE - NEUnscheduled 13.1    n0000Mean (SD)NE (NE)NE (NE)NE (NE)NE (NE)MedianNENENENEMin - MaxNE - NENE - NENE - NENE - NEUnscheduled 4.1    n1100Mean (SD)52.00 (NE (NE))11.00 (NE (NE))NE (NE)NE (NE)Median52.0011.00NENEMin - Max52.00 - 52.0011.00 - 11.00NE - NENE - NEUnscheduled 4.2    n1100Mean (SD)42.00 (NE (NE))1.00 (NE (NE))NE (NE)NE (NE)Median42.001.00NENEMin - Max42.00 - 42.001.00 - 1.00NE - NENE - NEUnscheduled 5.1    n1100Mean (SD)40.00 (NE (NE))-1.00 (NE (NE))NE (NE)NE (NE)Median40.00-1.00NENEMin - Max40.00 - 40.00-1.00 - -1.00NE - NENE - NEUnscheduled 6.1    n1100Mean (SD)85.00 (NE (NE))-5.00 (NE (NE))NE (NE)NE (NE)Median85.00-5.00NENEMin - Max85.00 - 85.00-5.00 - -5.00NE - NENE - NEUnscheduled 7.1    n0011Mean (SD)NE (NE)NE (NE)50.00 (NE (NE))7.00 (NE (NE))MedianNENE50.007.00Min - MaxNE - NENE - NE50.00 - 50.007.00 - 7.00Unscheduled 8.2    n1111Mean (SD)36.00 (NE (NE))7.00 (NE (NE))41.00 (NE (NE))-10.00 (NE (NE))Median36.007.0041.00-10.00Min - Max36.00 - 36.007.00 - 7.0041.00 - 41.00-10.00 - -10.00Unscheduled 9.2    n1100Mean (SD)52.00 (NE (NE))-15.00 (NE (NE))NE (NE)NE (NE)Median52.00-15.00NENEMin - Max52.00 - 52.00-15.00 - -15.00NE - NENE - NEWeek 12    n67675050Mean (SD)101.81 (78.66)11.07 (68.81)96.62 (60.55)-2.28 (65.26)Median77.003.0084.50-4.00Min - Max31.00 - 532.00-160.00 - 434.0026.00 - 316.00-332.00 - 243.00Week 16    n68683737Mean (SD)104.85 (66.37)14.90 (53.61)86.14 (47.70)-0.95 (23.02)Median89.004.0076.00-3.00Min - Max27.00 - 365.00-157.00 - 213.0031.00 - 276.00-70.00 - 51.00Week 2    n83837070Mean (SD)90.29 (66.11)4.10 (57.83)94.13 (51.91)-12.29 (53.50)Median75.00-4.0075.50-1.50Min - Max22.00 - 536.00-162.00 - 421.0031.00 - 325.00-344.00 - 92.00Week 20    n65653131Mean (SD)93.80 (46.56)3.34 (38.86)97.55 (68.57)7.65 (28.73)Median87.002.0082.004.00Min - Max30.00 - 209.00-150.00 - 121.0029.00 - 352.00-56.00 - 99.00Week 24    n57573030Mean (SD)127.37 (207.98)35.61 (199.06)90.87 (53.97)1.17 (22.13)Median86.003.0072.003.50Min - Max24.00 - 1556.00-158.00 - 1414.0041.00 - 287.00-52.00 - 56.00Week 26    n57572727Mean (SD)94.09 (51.03)3.37 (42.85)92.96 (59.94)3.89 (44.82)Median79.002.0077.00-2.00Min - Max18.00 - 233.00-156.00 - 94.0025.00 - 302.00-118.00 - 130.00Week 4    n79797272Mean (SD)96.89 (124.45)10.28 (115.77)100.61 (58.39)-4.86 (53.87)Median76.000.0079.500.50Min - Max20.00 - 1125.00-164.00 - 985.0030.00 - 300.00-321.00 - 126.00Week 6    n73736666Mean (SD)88.01 (42.36)0.88 (38.63)123.55 (227.36)17.18 (187.49)Median80.000.0076.00-7.00Min - Max25.00 - 224.00-161.00 - 100.0027.00 - 1860.00-281.00 - 1416.00Week 8    n72725656Mean (SD)93.85 (45.84)3.31 (42.58)91.75 (52.25)-8.84 (58.42)Median83.501.5077.00-3.50Min - Max28.00 - 260.00-156.00 - 168.0037.00 - 317.00-299.00 - 173.00This is a demo table for illustration purpose.Program: demo_poc_docx.RDate: 2024-11-06Version: 0.0.1",
    "crumbs": [
      "Documents",
      "Documents"
    ]
  },
  {
    "objectID": "digit_files/autoslider.html",
    "href": "digit_files/autoslider.html",
    "title": "Slides",
    "section": "",
    "text": "AutoslideR functions that are used for slide rendering and workflow are already open-sourced with the autoslider.core package. In this example, we show the general autoslideR workflow, how you can create functions from our templates and produce study-specific outputs, and how you can integrate them into the autoslideR framework to automate slide generation.",
    "crumbs": [
      "Documents",
      "Slides"
    ]
  },
  {
    "objectID": "digit_files/autoslider.html#file-structure",
    "href": "digit_files/autoslider.html#file-structure",
    "title": "Slides",
    "section": "File structure",
    "text": "File structure\nThe folder structure could look something like:\n├── programs\n│   ├── run_script.R\n│   ├── R   \n|   |   ├── template_functions.R\n|   |   ├── output_functions.R\n├── outputs\n├── spec.yml\n├── filters.yml\nThe autoslideR workflow would be implemented in the run_script.R file. This workflow does not require the files in programs/R/. However, if custom output_functions.R are implemented, programs/R/ would be the place to put them.\nThe autoslideR workflow has four main aspects:",
    "crumbs": [
      "Documents",
      "Slides"
    ]
  },
  {
    "objectID": "digit_files/autoslider.html#the-specifications-specs.yml",
    "href": "digit_files/autoslider.html#the-specifications-specs.yml",
    "title": "Slides",
    "section": "The specifications specs.yml",
    "text": "The specifications specs.yml\nThis file contains the specifications of all outputs you would like to create.\nFor each output we define specific information, namely the program name, the footnotes & titles, the paper (this indicates the orientation, P for portrait and L for landscape, the number indicates the font size), the suffix and args.\nIt could look something like that:\n- program: t_dm_slide\n  titles: Patient Demographics and Baseline Characteristics\n  footnotes: 't_dm_slide footnote'\n  paper: L6\n  suffix: SE\n  args:\n    arm: \"TRT01A\"\n    vars: [\"SEX\", \"AGE\"]\n\nThe program name refers to a function that produces an output. This could be one of the template functions provided in autoslider.core or a custom function. See vignette adding_templates for a detailed guide on using templates.\nTitles and footnotes are added once the outputs are created. We refer to that as decorating the outputs.\nThe suffix specifies the name of the filters that are applied to the data, before the data is funneled into the function (program). The filters themselves are specified in the filters.yml file.",
    "crumbs": [
      "Documents",
      "Slides"
    ]
  },
  {
    "objectID": "digit_files/autoslider.html#the-filters-filters.yml",
    "href": "digit_files/autoslider.html#the-filters-filters.yml",
    "title": "Slides",
    "section": "The filters filters.yml",
    "text": "The filters filters.yml\nIn filters.yml we specify the names of the filters used across the outputs. Each filter has a name (e.g. FAS), a title (Full Analysis Set), and then the filtering condition on a target dataset. The filter title may be appended to the output title. For the t_dm_slide slide above all filter titles that target the adsl dataset would be included in the brackets. We would thus expect the title to read: “Patient Demographics and Baseline Characteristics (Full Analysis Set)”.\nAs you can see, we don’t just have population filters, but also filters on serious adverse events. We can thus produce SAE tables by just supplying the serious adverse events to the AE table function. This concept generalizes also to PARAMCD values.\nITT:\n  title: Intent to Treat Population\n  condition: ITTFL == \"Y\"\n  target: adsl\n  type: slref\nSAS:\n  title: Secondary Analysis Set\n  condition: SASFL == \"Y\"\n  target: adsl\n  type: slref\nSE:\n  title: Safety Evaluable Population\n  condition: SAFFL == \"Y\"\n  target: adsl\n  type: slref\nSER:\n  title: Serious Adverse Events\n  condition: AESER == \"Y\"\n  target: adae\n  type: anl",
    "crumbs": [
      "Documents",
      "Slides"
    ]
  },
  {
    "objectID": "tlg/demographic.html",
    "href": "tlg/demographic.html",
    "title": "Demographic Table",
    "section": "",
    "text": "This guide will show you how pharmaverse packages, along with some from tidyverse, can be used to create a Demographic table, using the {pharmaverseadam} ADSL data as an input.\nIn the examples below, we illustrate two general approaches for creating a demographics table. The first utilizes Analysis Results Datasets—part of the emerging CDISC Analysis Results Standard. The second is the classic method of creating summary tables directly from a data set.",
    "crumbs": [
      "TLG",
      "Demographic Table"
    ]
  },
  {
    "objectID": "tlg/demographic.html#introduction",
    "href": "tlg/demographic.html#introduction",
    "title": "Demographic Table",
    "section": "",
    "text": "This guide will show you how pharmaverse packages, along with some from tidyverse, can be used to create a Demographic table, using the {pharmaverseadam} ADSL data as an input.\nIn the examples below, we illustrate two general approaches for creating a demographics table. The first utilizes Analysis Results Datasets—part of the emerging CDISC Analysis Results Standard. The second is the classic method of creating summary tables directly from a data set.",
    "crumbs": [
      "TLG",
      "Demographic Table"
    ]
  },
  {
    "objectID": "tlg/demographic.html#data-preprocessing",
    "href": "tlg/demographic.html#data-preprocessing",
    "title": "Demographic Table",
    "section": "Data preprocessing",
    "text": "Data preprocessing\nNow we will add some pre-processing to create some extra formatted variables ready for display in the table.\n\nlibrary(dplyr)\n\n# Create categorical variables, remove screen failures, and assign column labels\nadsl &lt;- pharmaverseadam::adsl |&gt;\n  filter(!ACTARM %in% \"Screen Failure\") |&gt;\n  mutate(\n    SEX = case_match(SEX, \"M\" ~ \"MALE\", \"F\" ~ \"FEMALE\"),\n    AGEGR1 =\n      case_when(\n        between(AGE, 18, 40) ~ \"18-40\",\n        between(AGE, 41, 64) ~ \"41-64\",\n        AGE &gt; 64 ~ \"&gt;=65\"\n      ) |&gt;\n        factor(levels = c(\"18-40\", \"41-64\", \"&gt;=65\"))\n  ) |&gt;\n  labelled::set_variable_labels(\n    AGE = \"Age (yr)\",\n    AGEGR1 = \"Age group\",\n    SEX = \"Sex\",\n    RACE = \"Race\"\n  )",
    "crumbs": [
      "TLG",
      "Demographic Table"
    ]
  },
  {
    "objectID": "tlg/demographic.html#gtsummary-cards",
    "href": "tlg/demographic.html#gtsummary-cards",
    "title": "Demographic Table",
    "section": "{gtsummary} & {cards}",
    "text": "{gtsummary} & {cards}\nIn the example below, we will use the {gtsummary} and {cards} packages to create a demographics tables.\n\nThe {cards} package creates Analysis Results Datasets (ARDs, which are a part of the CDISC Analysis Results Standard).\nThe {gtsummary} utilizes ARDs to create tables.\n\n\nARD ➡ Table\nIn the example below, we first build an ARD with the needed summary statistics using {cards}. Then, we use the ARD to build the demographics table with {gtsummary}.\n\nlibrary(cards)\nlibrary(gtsummary)\ntheme_gtsummary_compact() # reduce default padding and font size for a gt table\n\n# build the ARD with the needed summary statistics using {cards}\nard &lt;-\n  ard_stack(\n    adsl,\n    ard_continuous(variables = AGE),\n    ard_categorical(variables = c(AGEGR1, SEX, RACE)),\n    .by = ACTARM, # split results by treatment arm\n    .attributes = TRUE # optionally include column labels in the ARD\n  )\n\n# use the ARD to create a demographics table using {gtsummary}\ntbl_ard_summary(\n  cards = ard,\n  by = ACTARM,\n  include = c(AGE, AGEGR1, SEX, RACE),\n  type = AGE ~ \"continuous2\",\n  statistic = AGE ~ c(\"{N}\", \"{mean} ({sd})\", \"{median} ({p25}, {p75})\", \"{min}, {max}\")\n) |&gt;\n  bold_labels() |&gt;\n  modify_header(all_stat_cols() ~ \"**{level}**  \\nN = {n}\") |&gt; # add Ns to header\n  modify_footnote(everything() ~ NA) # remove default footnote\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nPlacebo\nN = 86\nXanomeline High Dose\nN = 72\nXanomeline Low Dose\nN = 96\n\n\n\n\nAge (yr)\n\n\n\n\n\n\n\n\n    N\n86\n72\n96\n\n\n    Mean (SD)\n75.2 (8.6)\n73.8 (7.9)\n76.0 (8.1)\n\n\n    Median (Q1, Q3)\n76.0 (69.0, 82.0)\n75.5 (70.0, 79.0)\n78.0 (71.0, 82.0)\n\n\n    Min, Max\n52.0, 89.0\n56.0, 88.0\n51.0, 88.0\n\n\nAge group\n\n\n\n\n\n\n\n\n    18-40\n0 (0.0%)\n0 (0.0%)\n0 (0.0%)\n\n\n    41-64\n14 (16.3%)\n11 (15.3%)\n8 (8.3%)\n\n\n    &gt;=65\n72 (83.7%)\n61 (84.7%)\n88 (91.7%)\n\n\nSex\n\n\n\n\n\n\n\n\n    FEMALE\n53 (61.6%)\n35 (48.6%)\n55 (57.3%)\n\n\n    MALE\n33 (38.4%)\n37 (51.4%)\n41 (42.7%)\n\n\nRace\n\n\n\n\n\n\n\n\n    AMERICAN INDIAN OR ALASKA NATIVE\n0 (0.0%)\n1 (1.4%)\n0 (0.0%)\n\n\n    BLACK OR AFRICAN AMERICAN\n8 (9.3%)\n9 (12.5%)\n6 (6.3%)\n\n\n    WHITE\n78 (90.7%)\n62 (86.1%)\n90 (93.8%)\n\n\n\n\n\n\n\n\n\nTable ➡ ARD\nOne may also build the demographics in the classic way using gtsummary::tbl_summary() from a data frame, then extract the ARD from the table object.\n\n# build demographics table directly from a data frame\ntbl &lt;- adsl |&gt; tbl_summary(by = ACTARM, include = c(AGE, AGEGR1, SEX, RACE))\n\n# extract ARD from table object\ngather_ard(tbl)[[1]] |&gt; select(-gts_column) # removing column so ARD fits on page\n\n{cards} data frame: 162 x 11\n\n\n   group1 group1_level variable variable_level stat_name stat_label  stat\n1  ACTARM      Placebo      SEX         FEMALE         n          n    53\n2  ACTARM      Placebo      SEX         FEMALE         N          N    86\n3  ACTARM      Placebo      SEX         FEMALE         p          % 0.616\n4  ACTARM      Placebo      SEX           MALE         n          n    33\n5  ACTARM      Placebo      SEX           MALE         N          N    86\n6  ACTARM      Placebo      SEX           MALE         p          % 0.384\n7  ACTARM      Placebo     RACE      AMERICAN…         n          n     0\n8  ACTARM      Placebo     RACE      AMERICAN…         N          N    86\n9  ACTARM      Placebo     RACE      AMERICAN…         p          %     0\n10 ACTARM      Placebo     RACE      BLACK OR…         n          n     8\n\n\nℹ 152 more rows\n\n\nℹ Use `print(n = ...)` to see more rows\n\n\nℹ 4 more variables: context, fmt_fun, warning, error",
    "crumbs": [
      "TLG",
      "Demographic Table"
    ]
  },
  {
    "objectID": "tlg/demographic.html#rtables-tern",
    "href": "tlg/demographic.html#rtables-tern",
    "title": "Demographic Table",
    "section": "{rtables} & {tern}",
    "text": "{rtables} & {tern}\nThe packages used with a brief description of their purpose are as follows:\n\n{rtables}: designed to create and display complex tables with R.\n{tern}: contains analysis functions to create tables and graphs used for clinical trial reporting.\n\nAfter installation of packages, the first step is to load our pharmaverse packages and input data. Here, we are going to encode missing entries in a data frame adsl.\nNote that {tern} depends on {rtables} so the latter is automatically attached.\n\nlibrary(tern)\n\nadsl2 &lt;- adsl |&gt;\n  df_explicit_na()\n\nNow we create the demographic table.\n\nvars &lt;- c(\"AGE\", \"AGEGR1\", \"SEX\", \"RACE\")\nvar_labels &lt;- c(\n  \"Age (yr)\",\n  \"Age group\",\n  \"Sex\",\n  \"Race\"\n)\n\nlyt &lt;- basic_table(show_colcounts = TRUE) |&gt;\n  split_cols_by(var = \"ACTARM\") |&gt;\n  add_overall_col(\"All Patients\") |&gt;\n  analyze_vars(\n    vars = vars,\n    var_labels = var_labels\n  )\n\nresult &lt;- build_table(lyt, adsl2)\n\nresult\n\n                                       Placebo     Xanomeline High Dose   Xanomeline Low Dose   All Patients\n                                       (N=86)             (N=72)                (N=96)            (N=254)   \n————————————————————————————————————————————————————————————————————————————————————————————————————————————\nAge (yr)                                                                                                    \n  n                                      86                 72                    96                254     \n  Mean (SD)                          75.2 (8.6)         73.8 (7.9)            76.0 (8.1)         75.1 (8.2) \n  Median                                76.0               75.5                  78.0               77.0    \n  Min - Max                          52.0 - 89.0       56.0 - 88.0            51.0 - 88.0       51.0 - 89.0 \nAge group                                                                                                   \n  n                                      86                 72                    96                254     \n  18-40                                   0                 0                      0                 0      \n  41-64                              14 (16.3%)         11 (15.3%)             8 (8.3%)           33 (13%)  \n  &gt;=65                               72 (83.7%)         61 (84.7%)            88 (91.7%)         221 (87%)  \nSex                                                                                                         \n  n                                      86                 72                    96                254     \n  FEMALE                             53 (61.6%)         35 (48.6%)            55 (57.3%)        143 (56.3%) \n  MALE                               33 (38.4%)         37 (51.4%)            41 (42.7%)        111 (43.7%) \nRace                                                                                                        \n  n                                      86                 72                    96                254     \n  AMERICAN INDIAN OR ALASKA NATIVE        0              1 (1.4%)                  0              1 (0.4%)  \n  BLACK OR AFRICAN AMERICAN           8 (9.3%)          9 (12.5%)              6 (6.2%)          23 (9.1%)  \n  WHITE                              78 (90.7%)         62 (86.1%)            90 (93.8%)        230 (90.6%)",
    "crumbs": [
      "TLG",
      "Demographic Table"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pharmaverse examples",
    "section": "",
    "text": "The true beauty of pharmaverse (and open source in general) is when efforts from various different developers come together to complement each other as a whole greater than the sum of the individual parts. By design in R, no single package will ever completely cover all your needs, but by piecing them together we can make complex tasks increasingly simple.\nThis book contains end-to-end examples of using pharmaverse packages together to achieve common clinical reporting analyses, such as SDTM, ADaM and Tables/Listings/Graphs. The examples use consistent source test raw datasets from {pharmaverseraw}, SDTMs and ADaMs from {pharmaversesdtm} and {pharmaverseadam} respectively.\nWe’ll endeavour to include a selection of examples here over time, e.g. to help users when trying out the packages for PK/PD or Therapeutic Area specific (such as Oncology or Vaccines) analyses.\nNote that this examples book should only be used to show how collections of packages can be used in conjunction - more thorough examples of individual package usages would always be covered in the package site vignettes and no need to repeat here.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#running-the-examples",
    "href": "index.html#running-the-examples",
    "title": "pharmaverse examples",
    "section": "Running the examples",
    "text": "Running the examples\n\nPosit Cloud\nEach example can be explored via a live and interactive Posit Cloud environment (preconfigured with all required package installations). Click here: “Launch Posit Cloud” to try out any of the examples code. You can do this by clicking File: Open File: and then choosing whichever example script, e.g. adam/adsl.R. Feel free to try out customizing any of the examples to better fit any of your own internal clinical reporting workflows!\n\n\nLocally\nTo run examples locally, download the repository and run the following in the R console inside the project folder to install dependencies\nif(!require(pak)) {\n  install.packages(\"pak\")\n}\npak::pak()\nNote: the R scripts are generated from .qmd files automatically using knitr::purl.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "pharmaverse examples",
    "section": "Contributing",
    "text": "Contributing\nIf you are interesting in contributing an article to this book, then see more in our GitHub repo README.\nYou can see a list of current contributors via our GitHub repo DESCRIPTION file.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "sdtm/ae.html",
    "href": "sdtm/ae.html",
    "title": "AE",
    "section": "",
    "text": "This article describes how to create an events SDTM domain using the {sdtm.oak} package. Examples are currently presented and tested in the context of the AE domain.\nBefore reading this article, it is recommended that users review some of the articles in the package documentation of {sdtm.oak} to understand some of the key concepts: Algorithms & Sub-Algorithms, Creating an Interventions Domain, which provides a detailed explanation of various concepts in {sdtm.oak}, such as oak_id_vars, condition_add, etc. It also offers guidance on which mapping algorithms or functions to use for different mappings and provides a more detailed explanation of how these mapping algorithms or functions work.\nIn this article, we will dive directly into programming and provide further explanation only where it is required.",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#readdata",
    "href": "sdtm/ae.html#readdata",
    "title": "AE",
    "section": "Read in data",
    "text": "Read in data\nRead all the raw datasets into the environment. In this example, the raw dataset name is ae_raw. Users can read them from the {pharmaverseraw} package using the below code:\n\nlibrary(sdtm.oak)\nlibrary(pharmaverseraw)\nlibrary(dplyr)\n\nae_raw &lt;- pharmaverseraw::ae_raw\n\nAdverse Events Raw dataset\n\n\nSample of Data\n\n\n\n\nRead in the DM domain\n\ndm &lt;- pharmaversesdtm::dm\n\n\nSDTM aCRF\nThe mock up of the Adverse Events aCRF can be viewed here:",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#oakidvars",
    "href": "sdtm/ae.html#oakidvars",
    "title": "AE",
    "section": "Create oak_id_vars",
    "text": "Create oak_id_vars\n\nae_raw &lt;- ae_raw %&gt;%\n  generate_oak_id_vars(\n    pat_var = \"PATNUM\",\n    raw_src = \"ae_raw\"\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#readct",
    "href": "sdtm/ae.html#readct",
    "title": "AE",
    "section": "Read in CT",
    "text": "Read in CT\nControlled Terminology is part of the SDTM specification and it is prepared by the user. In this example, the study controlled terminology name is sdtm_ct.csv. Users can read it from the package using the below code:\n\nstudy_ct &lt;- read.csv(\"metadata/sdtm_ct.csv\")\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#maptopic",
    "href": "sdtm/ae.html#maptopic",
    "title": "AE",
    "section": "Map Topic Variable",
    "text": "Map Topic Variable\nThe topic variable is mapped as a first step in the mapping process. It is the primary variable in the SDTM domain. The rest of the variables add further definition to the topic variable. In this example, the topic variable is AETERM. It is mapped from the raw dataset column IT.AETERM. The mapping logic is Map the collected value in the ae_raw dataset IT.AETERM variable to AE.AETERM.\nThis mapping does not involve any controlled terminology. The sdtm.oak::assign_no_ct() function is used for mapping. Once the topic variable is mapped, the Qualifier, Identifier, and Timing variables can be mapped.\n\nae &lt;-\n  # Derive topic variable\n  # Map AETERM using assign_no_ct, raw_var=IT.AETERM, tgt_var=AETERM\n  assign_no_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AETERM\",\n    tgt_var = \"AETERM\",\n    id_vars = oak_id_vars()\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#maprest",
    "href": "sdtm/ae.html#maprest",
    "title": "AE",
    "section": "Map Rest of the Variables",
    "text": "Map Rest of the Variables\nThe Qualifiers, Identifiers, and Timing Variables can be mapped in any order.\n\nae &lt;- ae %&gt;%\n  # Map AEOUT using assign_ct, raw_var=AEOUTCOME, tgt_var=AEOUT\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"AEOUTCOME\",\n    tgt_var = \"AEOUT\",\n    ct_spec = study_ct,\n    ct_clst = \"C66768\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESEV using assign_no_ct, raw_var=IT.AESEV, tgt_var=AESEV\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AESEV\",\n    tgt_var = \"AESEV\",\n    ct_spec = study_ct,\n    ct_clst = \"C66769\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESER using assign_no_ct, raw_var=IT.AESER, tgt_var=AESER\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AESER\",\n    tgt_var = \"AESER\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AEACN using assign_no_ct, raw_var=IT.AEACN, tgt_var=AEACN\n  assign_no_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AEACN\",\n    tgt_var = \"AEACN\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AEREL using assign_ct, raw_var=IT.AEREL, tgt_var=AEREL\n  # User-added codelist is in the ct,\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AEREL\",\n    tgt_var = \"AEREL\",\n    ct_spec = study_ct,\n    ct_clst = \"AEREL\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESCAN using assign_ct, raw_var=AESCAN, tgt_var=AESCAN\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"AESCAN\",\n    tgt_var = \"AESCAN\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESCNO using assign_ct, raw_var=AESCNO, tgt_var=AESCNO\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"AESCNO\",\n    tgt_var = \"AESCONG\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AEDIS using assign_ct, raw_var=AEDIS, tgt_var=AEDIS\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"AEDIS\",\n    tgt_var = \"AESDISAB\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESDTH using assign_ct, raw_var=IT.AESDTH, tgt_var=AESDTH\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AESDTH\",\n    tgt_var = \"AESDTH\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESHOSP using assign_ct, raw_var=IT.AESHOSP, tgt_var=AESHOSP\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AESHOSP\",\n    tgt_var = \"AESHOSP\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESLIFE using assign_ct, raw_var=IT.AESLIFE, tgt_var=AESLIFE\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AESLIFE\",\n    tgt_var = \"AESLIFE\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AESOD using assign_ct, raw_var=AESOD, tgt_var=AESOD\n  assign_ct(\n    raw_dat = ae_raw,\n    raw_var = \"AESOD\",\n    tgt_var = \"AESOD\",\n    ct_spec = study_ct,\n    ct_clst = \"C66742\",\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AEDTC using assign_datetime, raw_var=AEDTCOL\n  assign_datetime(\n    raw_dat = ae_raw,\n    raw_var = \"AEDTCOL\",\n    tgt_var = \"AEDTC\",\n    raw_fmt = c(\"m/d/y\")\n  ) %&gt;%\n  # Map AESTDTC using assign_datetime, raw_var=IT.AESTDAT\n  assign_datetime(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AESTDAT\",\n    tgt_var = \"AESTDTC\",\n    raw_fmt = c(\"m/d/y\"),\n    id_vars = oak_id_vars()\n  ) %&gt;%\n  # Map AEENDTC using assign_datetime, raw_var=IT.AEENDAT\n  assign_datetime(\n    raw_dat = ae_raw,\n    raw_var = \"IT.AEENDAT\",\n    tgt_var = \"AEENDTC\",\n    raw_fmt = c(\"m/d/y\"),\n    id_vars = oak_id_vars()\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#repeatsteps",
    "href": "sdtm/ae.html#repeatsteps",
    "title": "AE",
    "section": "Repeat Map Topic and Map Rest",
    "text": "Repeat Map Topic and Map Rest\nThere is only one topic variable in this raw data source, and there are no additional topic variable mappings. Users can proceed to the next step. This is required only if there is more than one topic variable to map.",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#derivedvars",
    "href": "sdtm/ae.html#derivedvars",
    "title": "AE",
    "section": "Create SDTM derived variables",
    "text": "Create SDTM derived variables\nThe SDTM derived variables or any SDTM mapping that is applicable to all the records in the ae dataset produced in the previous step cam be created now.\n\nae &lt;- ae %&gt;%\n  dplyr::mutate(\n    STUDYID = ae_raw$STUDY,\n    DOMAIN = \"AE\",\n    USUBJID = paste0(\"01-\", ae_raw$PATNUM),\n    AELLT = ae_raw$AELLT,\n    AELLTCD = ae_raw$AELLTCD,\n    AEDECOD = ae_raw$AEDECOD,\n    AEPTCD = ae_raw$AEPTCD,\n    AEHLT = ae_raw$AEHLT,\n    AEHLTCD = ae_raw$AEHLTCD,\n    AEHLGT = ae_raw$AEHLGT,\n    AEHLGTCD = ae_raw$AEHLGTCD,\n    AEBODSYS = ae_raw$AEBODSYS,\n    AEBDSYCD = ae_raw$AEBDSYCD,\n    AESOC = ae_raw$AESOC,\n    AESOCCD = ae_raw$AESOCCD,\n    AETERM = toupper(AETERM)\n  ) %&gt;%\n  derive_seq(\n    tgt_var = \"AESEQ\",\n    rec_vars = c(\"USUBJID\", \"AETERM\")\n  ) %&gt;%\n  derive_study_day(\n    sdtm_in = .,\n    dm_domain = dm,\n    tgdt = \"AESTDTC\",\n    refdt = \"RFXSTDTC\",\n    study_day_var = \"AESTDY\"\n  ) %&gt;%\n  derive_study_day(\n    sdtm_in = .,\n    dm_domain = dm,\n    tgdt = \"AEENDTC\",\n    refdt = \"RFXENDTC\",\n    study_day_var = \"AEENDY\"\n  ) %&gt;%\n  select(\n    \"STUDYID\", \"DOMAIN\", \"USUBJID\", \"AESEQ\", \"AETERM\", \"AELLT\", \"AELLTCD\", \"AEDECOD\", \"AEPTCD\", \"AEHLT\", \"AEHLTCD\", \"AEHLGT\",\n    \"AEHLGTCD\", \"AEBODSYS\", \"AEBDSYCD\", \"AESOC\", \"AESOCCD\", \"AESEV\", \"AESER\", \"AEACN\", \"AEREL\", \"AEOUT\", \"AESCAN\", \"AESCONG\",\n    \"AESDISAB\", \"AESDTH\", \"AESHOSP\", \"AESLIFE\", \"AESOD\", \"AEDTC\", \"AESTDTC\", \"AEENDTC\", \"AESTDY\", \"AEENDY\"\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "sdtm/ae.html#attributes",
    "href": "sdtm/ae.html#attributes",
    "title": "AE",
    "section": "Add Labels and Attributes",
    "text": "Add Labels and Attributes\nYet to be developed. Please refer to {metatools} package to investigate options.",
    "crumbs": [
      "SDTM",
      "AE"
    ]
  },
  {
    "objectID": "esub/esub.html",
    "href": "esub/esub.html",
    "title": "eSubmission",
    "section": "",
    "text": "This article shares learnings from R and open source based submission experiences, and how these can be achieved using pharmaverse packages in conjunction.\nWhen considering such a submission, it is important to discuss this early on with the regulatory agency during any pre-submission correspondence.\nThe main pharmaverse packages specifically supporting eSubmission are as follows:\n\n{xportr}: delivers the SAS transport file (XPT) and eSub checks.\n{pkglite}: enables exchange of closed source R packages via text files.\n{datasetjson}: experimental package to deliver Dataset-JSON.\n\nNote that a python equivalent of {pkglite} also exists, read more at pharmaverse python.\nOf course, most of the pharmaverse packages contribute to eSubmission in some way, through their focus on enabling clinical reporting and analyses deliverables that form the backbone of any submission. There are many other examples on this site dedicated to these, so we won’t repeat here. One package we did want to call out here is {aNCA} which performs Non-Compartmental Analysis, as clinical pharmacology analyses are another important part of submissions.",
    "crumbs": [
      "eSubmission",
      "eSubmission"
    ]
  },
  {
    "objectID": "esub/esub.html#introduction",
    "href": "esub/esub.html#introduction",
    "title": "eSubmission",
    "section": "",
    "text": "This article shares learnings from R and open source based submission experiences, and how these can be achieved using pharmaverse packages in conjunction.\nWhen considering such a submission, it is important to discuss this early on with the regulatory agency during any pre-submission correspondence.\nThe main pharmaverse packages specifically supporting eSubmission are as follows:\n\n{xportr}: delivers the SAS transport file (XPT) and eSub checks.\n{pkglite}: enables exchange of closed source R packages via text files.\n{datasetjson}: experimental package to deliver Dataset-JSON.\n\nNote that a python equivalent of {pkglite} also exists, read more at pharmaverse python.\nOf course, most of the pharmaverse packages contribute to eSubmission in some way, through their focus on enabling clinical reporting and analyses deliverables that form the backbone of any submission. There are many other examples on this site dedicated to these, so we won’t repeat here. One package we did want to call out here is {aNCA} which performs Non-Compartmental Analysis, as clinical pharmacology analyses are another important part of submissions.",
    "crumbs": [
      "eSubmission",
      "eSubmission"
    ]
  },
  {
    "objectID": "esub/esub.html#r-submissions-working-group",
    "href": "esub/esub.html#r-submissions-working-group",
    "title": "eSubmission",
    "section": "R Submissions Working Group",
    "text": "R Submissions Working Group\nWithin the R Consortium, the R Submissions WG have conducted several pilots to provide open examples of submitting R-based clinical trial data/analysis packages to the FDA.\nAnyone new to R-based submissions should definitely check out the open materials from this team here.\nSince these pilots laid the foundation, several major pharma companies have submitted primarily using R to health authorities across the world, so this article includes a mix of learnings from the pilots and real submissions.",
    "crumbs": [
      "eSubmission",
      "eSubmission"
    ]
  },
  {
    "objectID": "esub/esub.html#submission-contents",
    "href": "esub/esub.html#submission-contents",
    "title": "eSubmission",
    "section": "Submission Contents",
    "text": "Submission Contents\nThe areas of eSubmission that pharmaverse packages are most useful for would be data, readable code, and documentation.\nEach of the sections below talk in more detail of these areas, plus specific mention of validation which is a common topic raised around usage of open source.\n\nData\nThe main 2 forms of dataset for CDISC clinical trial submission are SDTM and ADaM. Refer to the separate example articles on this site for how best to go about producing these.\nFor eSubmission the most common transport file format used to deliver these to health authorities is as xpt files, and for this we use {xportr}. This package works well with {metacore} harmonized specification objects as shown in the ADaM articles on this site.\nHere is an example call using a synthetic ADSL ADaM from {pharmaverseadam} that shows how to produce xpt files, as well as how certain {xportr} functions can be used to take attributes directly from specifications so as to ensure specification to dataset consistency. This helps to ensure eSubmission-readiness. Additionally the package includes a number of built-in CDISC conformance checks as detailed on the site.\n\nlibrary(metacore)\nlibrary(xportr)\nlibrary(pharmaverseadam)\nlibrary(dplyr)\n\n# Read in metacore object\nmetacore &lt;- spec_to_metacore(\n  path = \"./metadata/safety_specs.xlsx\",\n  # All datasets are described in the same sheet\n  where_sep_sheet = FALSE\n) %&gt;%\n  select_dataset(\"ADSL\")\n\ndir &lt;- tempdir() # Specify the directory for saving the XPT file\n\nadsl &lt;- pharmaverseadam::adsl %&gt;%\n  # Coerce variable type to match specification\n  xportr_type(metacore) %&gt;%\n  # Assigns variable label from metacore specifications\n  xportr_label(metacore) %&gt;%\n  # Assigns dataset label from metacore specifications\n  xportr_df_label(metacore) %&gt;%\n  # Assigns SAS length from a variable level metadata\n  xportr_length(metacore) %&gt;%\n  # Assigns variable format from metacore specifications\n  xportr_format(metadata = metacore) %&gt;%\n  # Write xpt v5 transport file\n  xportr_write(file.path(dir, \"adsl.xpt\"), metadata = metacore, domain = \"ADSL\")\n\n\n# We can examine that the attributes have been correctly applied, for example\n# as follows for the dataset label\nattr(adsl, \"label\")\n\n[1] \"Subject-Level Analysis Dataset\"\n\n\nNow here’s an example where the checks would help to identify future possible eSubmission challenges. Note the console messages explaining the issues.\n\nadsl_challenges &lt;- pharmaverseadam::adsl %&gt;%\n  # Make a numeric variable as character, which conflicts with specifications\n  mutate(AGE = as.character(AGE)) %&gt;%\n  # Add a variable that is name &gt;8 characters which is not allowed for xpt v5\n  mutate(REGIONCAT = REGION1)\n\nadsl_challenges &lt;- adsl_challenges %&gt;%\n  # Coerce variable type to match specification\n  # This time we use the verbose argument to add a warning to the console\n  xportr_type(metacore, verbose = \"warn\") %&gt;%\n  # Write xpt v5 transport file\n  xportr_write(file.path(dir, \"adsl.xpt\"), metadata = metacore, domain = \"ADSL\")\n\n\n\n\n── Variable type mismatches found. ──\n\n\n\n\n\n✔ 1 variable coerced\n\n\nWarning: Variable type(s) in dataframe don't match metadata: `AGE`\n- `AGE` was coerced to &lt;numeric&gt;. (type in data: character, type in metadata: integer)\ni Types in metadata considered as character (xportr.character_metadata_types option): 'character', 'char', 'text', 'date', 'posixct', 'posixt', 'datetime', 'time', 'partialdate', 'partialtime', 'partialdatetime', 'incompletedatetime', 'durationdatetime', and 'intervaldatetime'\ni Types in metadata considered as numeric (xportr.numeric_metadata_types option): 'integer', 'numeric', 'num', and 'float'\ni Types in data considered as character (xportr.character_types option): 'character'\ni Types in data considered as numeric (xportr.numeric_types option): 'integer', 'float', 'numeric', 'posixct', 'posixt', 'time', 'date', and 'hms'\n\n\nWarning: The following validation checks failed:\n• Variable `REGIONCAT` must be 8 characters or less.\n\n\nFurthermore, the package functions also include certain arguments that you can use to help shape to your specific submission needs.\nThe below shows how some specific FDA requirements can be achieved using the length_source argument from xportr::xportr_length() and the max_size_gb argument from xportr::xportr_write(), as detailed in the code comments. In this case, the dataset splits would be very unlikely to occur in practice for ADSL but would be much more likely on a BDS dataset such as ADLB for a large study.\n\nadsl_example &lt;- pharmaverseadam::adsl %&gt;%\n  # Coerce variable type to match specification\n  xportr_type(metacore) %&gt;%\n  # Assigns variable label from metacore specifications\n  xportr_label(metacore) %&gt;%\n  # Assigns dataset label from metacore specifications\n  xportr_df_label(metacore) %&gt;%\n  # Assigns length from the maximum length of any value of the variable as per FDA data minimization guidance\n  xportr_length(metadata = metacore, length_source = \"data\") %&gt;%\n  # Assigns variable format from metacore specifications\n  xportr_format(metadata = metacore) %&gt;%\n  # Write xpt v5 transport file but split into smaller subsets if greater than 5GB\n  # according to the FDA cutoff size\n  xportr_write(file.path(dir, \"adsl.xpt\"), metadata = metacore, domain = \"ADSL\", max_size_gb = 5)\n\n\n\n\n── Variable labels missing from metadata. ──\n\n\n\n\n\n✔ 13 labels skipped\n\n\n\n\n\n── Variable length is shorter than the length specified in the metadata. ──\n\n\n\n\n\n── Variable lengths missing from metadata. ──\n\n\n\n\n\n✔ 13 lengths resolved `RFSTDTC`, `RFENDTC`, `RFXSTDTC`, `RFXENDTC`, `RFICDTC`, `RFPENDTC`, `DMDTC`, `DMDY`, `LSTALVDT`, `LDDTHGR1`, `DTH30FL`, `DTHA30FL`, and `DTHB30FL`\n\n\nData frame exported to 1 xpt files.\n\n\nAs an alternative to xpt, we also have {datasetjson} which enables the emerging new submission data exchange standard Dataset-JSON detailed here. As this package is still experimental, we don’t include code examples here but over time and as momentum grows we can add extra examples to this article. See R Submissions WG pilot 5 for a pilot submission using Dataset-JSON.\n\n\nReadable Code\nWhen using internal company-specific closed source tools and codebases, we often face challenges around providing readable code to health authorities as internal single company solutions are by nature not easily accessible and understandable. This is one of the benefits of using open source codebases in the submission setting as it enables review teams to look deeper into the functions used, plus they have the same open solutions available to use themselves as part of their review. As more of the industry embraces open source, we may even see more harmonization of submission packages across the industry as the same packages are re-used, and this should lead to greater familiarity from review teams easing their critical submission dossier review.\nThe nature of R packages and functions, as well as influence from {tidyverse}, has encouraged most pharmaverse package development teams to embrace modular strategy to their code. So when you use packages like {admiral}, you’ll see that the ADaM templates have been built with readability in mind specifically to aid with eSubmission.\n\n\nDocumentation\nWhen using R for submission there are some important recommendations around documentation you should include as part of the eSubmission package. Most companies include these in the Reviewer’s Guide documents (the PHUSE Advance Hub offers example templates for these), but you might also choose to use a programTOC document.\nHere’s the information we recommend including:\n\nR version used\nDescriptions of the main open source R package used, the version of each that you used, and where these are available from (especially if anywhere other than CRAN)\nDescriptions of any closed source packages used (see details below)\nBasic installation instructions of the R version used and how to install the package versions that you used (e.g. from CRAN). The R installation instructions should cover installation from Windows.\n\nHere is an example extract of what the documentation of the open source packages used might look like:\n\n\n\nExample Reviewer’s Guide Table\n\n\nFor closed source packages, if you plan to submit the code then there are 2 main options - {pkglite} to create txt files, or zip files (as were successfully used in later R Submission WG pilots).\nHere is an example taken from the R Submission WG pilot 1 around how they used pkglite::pack() to provide packages as txt files. On the other side pkglite::unpack() could then be used to unpack.\n\nlibrary(pkglite)\n\n# Using pkglite to pack proprietary R package and saved into ectd/r0pkg.txt\npath$home %&gt;%\n  collate(file_ectd(), file_auto(\"inst\")) %&gt;%\n  prune(\"R/zzz.R\") %&gt;%\n  pack(output = \"ectd/r0pkg.txt\")\n\nYou can also check the following example Reviewer’s Guides as used for these pilots:\n\nPilot 1, using {pkglite}\nPilot 3, using compressed .zip approach\n\nFor further Reviewer’s Guide guidance, regardless of the programming language used for regulatory submissions, refer to the completion guidelines found at this PHUSE ADRG Package WG. As we progress on this open source submission journey, it is worth monitoring this PHUSE Open-Source Metadata Documentation WG to see how the guidance continues to evolve in this space.\n\n\nValidation\nLast but not least, through the submission process you might be asked to provide evidence of why you consider the open source code used to be accurate and reliable.\nThis of course is a huge topic and one where you should first refer to guidance from the R Validation Hub.\nPharmaverse also offers a selection of recommended packages that can help with this via our Developers page under Package Validation. Under CI/CD it also offers thevalidatoR which is a GitHub action that can be used to produce standardized validation reports, such as this example from an earlier version of {admiral}.",
    "crumbs": [
      "eSubmission",
      "eSubmission"
    ]
  },
  {
    "objectID": "adam/advs.html",
    "href": "adam/advs.html",
    "title": "ADVS",
    "section": "",
    "text": "This article provides a step-by-step explanation for creating an ADaM ADVS (Vital Signs) dataset using key pharmaverse packages along with tidyverse components.\nFor the purpose of this example, we will use the ADSL dataset from {pharmaverseadam} and vs domain from {pharmaversesdtm}.\n\n\n\nLoad Data and Required pharmaverse Packages\nLoad Specifications for Metacore\nSelect ADSL Variables\nStart Building Derivations\nAssign PARAMCD, PARAM, PARAMN\nDerive Results and Units (AVAL, AVALU)\nDerive Additional Parameters (e.g. MAP, BMI or BSA for ADVS)\nDerive Timing Variables (e.g. AVISIT, ATPT, ATPTN)\nDerive summary records (e.g. mean of the triplicates at each time point)\nTiming Flag Variables (e.g. ONTRTFL)\nAssign Reference Range Indicator (ANRIND)\nDerive Baseline (BASETYPE, ABLFL, BASE, BNRIND)\nDerive Change from Baseline (CHG, PCHG)\nDerive Analysis Flags (e.g. ANL01FL)\nAssign Treatment (TRTA, TRTP)\nAssign ASEQ\nDerive Categorization Variables (AVALCATy)\nAssign Parameter Level Values (PARAM, PARAMN)\nAdd ADSL variables\nApply Metadata and eSub Checks",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#programming-flow",
    "href": "adam/advs.html#programming-flow",
    "title": "ADVS",
    "section": "",
    "text": "Load Data and Required pharmaverse Packages\nLoad Specifications for Metacore\nSelect ADSL Variables\nStart Building Derivations\nAssign PARAMCD, PARAM, PARAMN\nDerive Results and Units (AVAL, AVALU)\nDerive Additional Parameters (e.g. MAP, BMI or BSA for ADVS)\nDerive Timing Variables (e.g. AVISIT, ATPT, ATPTN)\nDerive summary records (e.g. mean of the triplicates at each time point)\nTiming Flag Variables (e.g. ONTRTFL)\nAssign Reference Range Indicator (ANRIND)\nDerive Baseline (BASETYPE, ABLFL, BASE, BNRIND)\nDerive Change from Baseline (CHG, PCHG)\nDerive Analysis Flags (e.g. ANL01FL)\nAssign Treatment (TRTA, TRTP)\nAssign ASEQ\nDerive Categorization Variables (AVALCATy)\nAssign Parameter Level Values (PARAM, PARAMN)\nAdd ADSL variables\nApply Metadata and eSub Checks",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#paramvars",
    "href": "adam/advs.html#paramvars",
    "title": "ADVS",
    "section": "Assign PARAMCD, PARAM, PARAMN",
    "text": "Assign PARAMCD, PARAM, PARAMN\nTo assign parameter level values such as PARAMCD, PARAM, PARAMN, etc., a lookup can be created to join to the source data.\nFor example, when creating ADVS, a lookup based on the SDTM --TESTCD value may be created:\n\n\n\nVSTESTCD\nPARAMCD\nPARAM\nPARAMN\n\n\n\n\nSYSBP\nSYSBP\nSystolic Blood Pressure (mmHg)\n1\n\n\nDIABP\nDIABP\nDiastolic Blood Pressure (mmHg)\n2\n\n\nPULSE\nPULSE\nPulse Rate (beats/min)\n3\n\n\nWEIGHT\nWEIGHT\nWeight (kg)\n4\n\n\nHEIGHT\nHEIGHT\nHeight (cm)\n5\n\n\nTEMP\nTEMP\nTemperature (C)\n6\n\n\nMAP\nMAP\nMean Arterial Pressure\n7\n\n\nBMI\nBMI\nBody Mass Index(kg/m^2)\n8\n\n\nBSA\nBSA\nBody Surface Area(m^2)\n9\n\n\n\nThis lookup may now be joined to the source data:\nAt this stage, only PARAMCD is required to perform the derivations. Additional derived parameters may be added, so only PARAMCD is joined to the datasets at this point. All other variables related to PARAMCD (e.g. PARAM, PARAMN, …) will be added when all PARAMCD are derived.\n\nadvs &lt;- advs %&gt;%\n  # Add PARAMCD only - add PARAM etc later\n  derive_vars_merged_lookup(\n    dataset_add = param_lookup,\n    new_vars = exprs(PARAMCD),\n    by_vars = exprs(VSTESTCD),\n    # Below arguments are default values and not necessary to add in our case\n    print_not_mapped = TRUE # Printing whether some parameters are not mapped\n  )\n\nAll `VSTESTCD` are mapped.\n\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#avalvars",
    "href": "adam/advs.html#avalvars",
    "title": "ADVS",
    "section": "Derive Results and Units (AVAL, AVALU)",
    "text": "Derive Results and Units (AVAL, AVALU)\nThe mapping of AVAL and AVALU is left to the ADaM programmer. An example mapping may be:\n\nadvs &lt;- advs %&gt;%\n  mutate(\n    AVAL = VSSTRESN,\n    AVALU = VSSTRESU\n  )\n\n\n\nSample of Data\n\n\n\n\nIn this example, as is often the case for ADVS, all AVAL values are numeric without any corresponding non-redundant text value for AVALC. Per recommendation in ADaMIG v1.3 we do not map AVALC.",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#addparams",
    "href": "adam/advs.html#addparams",
    "title": "ADVS",
    "section": "Derive Additional Parameters (e.g. MAP, BMI or BSA for ADVS)",
    "text": "Derive Additional Parameters (e.g. MAP, BMI or BSA for ADVS)\nOptionally derive new parameters creating PARAMCD and AVAL. Note that only variables specified in the by_vars argument will be populated in the newly created records. This is relevant to the functions admiral::derive_param_map, admiral::derive_param_bsa, admiral::derive_param_bmi, and admiral::derive_param_qtc.\nBelow is an example of creating Mean Arterial Pressure for ADVS using the wrapper function admiral::derive_param_map()\n\nadvs &lt;- advs %&gt;%\n  derive_param_map(\n    by_vars = exprs(STUDYID, USUBJID, !!!adsl_vars, VISIT, VISITNUM, ADT, ADY, VSTPT, VSTPTNUM, AVALU), # Other variables than the defined ones here won't be populated\n    set_values_to = exprs(PARAMCD = \"MAP\"),\n    get_unit_expr = VSSTRESU,\n    filter = VSSTAT != \"NOT DONE\" | is.na(VSSTAT),\n    # Below arguments are default values and not necessary to add in our case\n    sysbp_code = \"SYSBP\",\n    diabp_code = \"DIABP\",\n    hr_code = NULL\n  )\n\nSimilarly we could create Body Mass Index (BMI) for ADVS using the wrapper function admiral::derive_param_bmi(), instead we will see in below example how to use the more generic function admiral::derive_param_computed() Note that if height is collected only once use constant_parameters to define the corresponding parameter which will be merged to the other parameters and constant_by_vars to specify the subject-level variable to merge on. Otherwise BMI is only calculated for visits where both parameters HEIGHT and WEIGHT are collected.\n\nadvs &lt;- advs %&gt;%\n  derive_param_computed(\n    by_vars = exprs(STUDYID, USUBJID, VISIT, VISITNUM, ADT, ADY, VSTPT, VSTPTNUM),\n    parameters = \"WEIGHT\",\n    set_values_to = exprs(\n      AVAL = AVAL.WEIGHT / (AVAL.HEIGHT / 100)^2,\n      PARAMCD = \"BMI\",\n      AVALU = \"kg/m^2\"\n    ),\n    constant_parameters = c(\"HEIGHT\"),\n    constant_by_vars = exprs(USUBJID)\n  )\n\nLikewise, wrapper function admiral::derive_param_bsa() call below, to create parameter Body Surface Area (BSA) for ADVS domain. Note that if height is collected only once use constant_by_vars to specify the subject-level variable to merge on. Otherwise BSA is only calculated for visits where both parameters HEIGHT and WEIGHT are collected.\n\nadvs &lt;- advs %&gt;%\n  derive_param_bsa(\n    by_vars = exprs(STUDYID, USUBJID, !!!adsl_vars, VISIT, VISITNUM, ADT, ADY, VSTPT, VSTPTNUM),\n    method = \"Mosteller\",\n    set_values_to = exprs(\n      PARAMCD = \"BSA\",\n      AVALU = \"m^2\"\n    ),\n    get_unit_expr = VSSTRESU,\n    filter = VSSTAT != \"NOT DONE\" | is.na(VSSTAT),\n    constant_by_vars = exprs(USUBJID),\n    # Below arguments are default values and not necessary to add in our case\n    height_code = \"HEIGHT\",\n    weight_code = \"WEIGHT\"\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nSample of Data\n\n\n\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#timingvars",
    "href": "adam/advs.html#timingvars",
    "title": "ADVS",
    "section": "Derive Timing Variables (e.g. AVISIT, ATPT, ATPTN)",
    "text": "Derive Timing Variables (e.g. AVISIT, ATPT, ATPTN)\nCategorical timing variables are protocol and analysis dependent. Below is a simple example.\n\nadvs &lt;- advs %&gt;%\n  mutate(\n    ATPTN = VSTPTNUM,\n    ATPT = VSTPT,\n    AVISIT = case_when(\n      str_detect(VISIT, \"SCREEN|UNSCHED|RETRIEVAL|AMBUL\") ~ NA_character_,\n      !is.na(VISIT) ~ str_to_title(VISIT),\n      TRUE ~ NA_character_\n    ),\n    AVISITN = as.numeric(case_when(\n      VISIT == \"BASELINE\" ~ \"0\",\n      str_detect(VISIT, \"WEEK\") ~ str_trim(str_replace(VISIT, \"WEEK\", \"\")),\n      TRUE ~ NA_character_\n    ))\n  )\n\nFor assigning visits based on time windows and deriving periods, subperiods, and phase variables see the “Visit and Period Variables” vignette.",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#summaryrec",
    "href": "adam/advs.html#summaryrec",
    "title": "ADVS",
    "section": "Derive summary records (e.g. mean of the triplicates at each time point)",
    "text": "Derive summary records (e.g. mean of the triplicates at each time point)\nFor adding new records based on aggregating records admiral::derive_summary_records() can be used. For the new records only the variables specified by by_vars and set_values_to are populated.\nFor each subject, Vital Signs parameter, visit, and date add a record holding the average value for observations on that date. Set DTYPE to AVERAGE.\n\nadvs &lt;- derive_summary_records(\n  dataset = advs,\n  dataset_add = advs, # Observations from the specified dataset are going to be used to calculate and added as new records to the input dataset.\n  by_vars = exprs(STUDYID, USUBJID, !!!adsl_vars, PARAMCD, AVISITN, AVISIT, ADT, ADY, AVALU),\n  filter_add = !is.na(AVAL),\n  set_values_to = exprs(\n    AVAL = mean(AVAL),\n    DTYPE = \"AVERAGE\"\n  )\n)",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#ontrtfl",
    "href": "adam/advs.html#ontrtfl",
    "title": "ADVS",
    "section": "Timing Flag Variables (e.g. ONTRTFL)",
    "text": "Timing Flag Variables (e.g. ONTRTFL)\nIn some analyses, it may be necessary to flag an observation as on-treatment. The admiral function admiral::derive_var_ontrtfl() can be used.\nFor example, if on-treatment is defined as any observation between treatment start and treatment end, the flag may be derived as:\n\nadvs &lt;- derive_var_ontrtfl(\n  advs,\n  start_date = ADT,\n  ref_start_date = TRTSDT,\n  ref_end_date = TRTEDT,\n  filter_pre_timepoint = toupper(AVISIT) == \"BASELINE\" # Observations as not on-treatment\n)\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#rangeind",
    "href": "adam/advs.html#rangeind",
    "title": "ADVS",
    "section": "Assign Reference Range Indicator (ANRIND)",
    "text": "Assign Reference Range Indicator (ANRIND)\nThe admiral function derive_var_anrind() may be used to derive the reference range indicator ANRIND.\nThis function requires the reference range boundaries to exist on the data frame (ANRLO, ANRHI) and also accommodates the additional boundaries A1LO and A1HI.\nThe function is called as:\n\nadvs &lt;- derive_var_anrind(\n  advs,\n  # Below arguments are default values and not necessary to add in our case\n  signif_dig = get_admiral_option(\"signif_digits\"),\n  use_a1hia1lo = FALSE\n)\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#baselinevars",
    "href": "adam/advs.html#baselinevars",
    "title": "ADVS",
    "section": "Derive Baseline (BASETYPE, ABLFL, BASE, BNRIND)",
    "text": "Derive Baseline (BASETYPE, ABLFL, BASE, BNRIND)\nThe BASETYPE should be derived using the function admiral::derive_basetype_records(). The parameter basetypes of this function requires a named list of expression detailing how the BASETYPE should be assigned. Note, if a record falls into multiple expressions within the basetypes expression, a row will be produced for each BASETYPE.\n\nadvs &lt;- derive_basetype_records(\n  dataset = advs,\n  basetypes = exprs(\n    \"LAST: AFTER LYING DOWN FOR 5 MINUTES\" = ATPTN == 815,\n    \"LAST: AFTER STANDING FOR 1 MINUTE\" = ATPTN == 816,\n    \"LAST: AFTER STANDING FOR 3 MINUTES\" = ATPTN == 817,\n    \"LAST\" = is.na(ATPTN)\n  )\n)\n\ncount(advs, ATPT, ATPTN, BASETYPE)\n\n# A tibble: 4 × 4\n  ATPT                           ATPTN BASETYPE                                n\n  &lt;chr&gt;                          &lt;dbl&gt; &lt;chr&gt;                               &lt;int&gt;\n1 AFTER LYING DOWN FOR 5 MINUTES   815 LAST: AFTER LYING DOWN FOR 5 MINUT… 10944\n2 AFTER STANDING FOR 1 MINUTE      816 LAST: AFTER STANDING FOR 1 MINUTE   10938\n3 AFTER STANDING FOR 3 MINUTES     817 LAST: AFTER STANDING FOR 3 MINUTES  10942\n4 &lt;NA&gt;                              NA LAST                                29184\n\n\nIt is important to derive BASETYPE first so that it can be utilized in subsequent derivations. This will be important if the data frame contains multiple values for BASETYPE.\nNext, the analysis baseline flag ABLFL can be derived using the {admiral} function admiral::derive_var_extreme_flag(). For example, if baseline is defined as the last non-missing AVAL prior or on TRTSDT, the function call for ABLFL would be:\n\nadvs &lt;- restrict_derivation(\n  advs,\n  derivation = derive_var_extreme_flag,\n  args = params(\n    by_vars = exprs(STUDYID, USUBJID, BASETYPE, PARAMCD),\n    order = exprs(ADT, VISITNUM, VSSEQ),\n    new_var = ABLFL,\n    mode = \"last\", # Determines of the first or last observation is flagged\n    # Below arguments are default values and not necessary to add in our case\n    true_value = \"Y\"\n  ),\n  filter = (!is.na(AVAL) &\n    ADT &lt;= TRTSDT & !is.na(BASETYPE) & is.na(DTYPE)\n  )\n)\n\n\n\nSample of Data\n\n\n\n\nLastly, the BASE, and BNRIND columns can be derived using the {admiral} function admiral::derive_var_base(). Example calls are:\n\nadvs &lt;- derive_var_base(\n  advs,\n  by_vars = exprs(STUDYID, USUBJID, PARAMCD, BASETYPE),\n  source_var = AVAL,\n  new_var = BASE,\n  # Below arguments are default values and not necessary to add in our case\n  filter = ABLFL == \"Y\"\n)\n\nadvs &lt;- derive_var_base(\n  advs,\n  by_vars = exprs(STUDYID, USUBJID, PARAMCD, BASETYPE),\n  source_var = ANRIND,\n  new_var = BNRIND\n)\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#chgpchg",
    "href": "adam/advs.html#chgpchg",
    "title": "ADVS",
    "section": "Derive Change from Baseline (CHG, PCHG)",
    "text": "Derive Change from Baseline (CHG, PCHG)\nChange and percent change from baseline can be derived using the {admiral} functions admiral::derive_var_chg() and admiral::derive_var_pchg(). These functions expect AVAL and BASE to exist in the data frame. The CHG is simply AVAL - BASE and the PCHG is (AVAL - BASE) / absolute value (BASE) * 100. If the variables should not be derived for all records, e.g., for post-baseline records only, admiral::restrict_derivation() can be used. Examples calls are:\n\nadvs &lt;- restrict_derivation(\n  advs,\n  derivation = derive_var_chg,\n  filter = AVISITN &gt; 0\n)\n\nadvs &lt;- restrict_derivation(\n  advs,\n  derivation = derive_var_pchg,\n  filter = AVISITN &gt; 0\n)\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#anl01fl",
    "href": "adam/advs.html#anl01fl",
    "title": "ADVS",
    "section": "Derive Analysis Flags (e.g. ANL01FL)",
    "text": "Derive Analysis Flags (e.g. ANL01FL)\nIn most finding ADaMs, an analysis flag is derived to identify the appropriate observation(s) to use for a particular analysis when a subject has multiple observations within a particular timing period.\nIn this situation, an analysis flag (e.g. ANLzzFL) may be used to choose the appropriate record for analysis.\nThis flag may be derived using the {admiral} function admiral::derive_var_extreme_flag(). For this example, we will assume we would like to choose within the Post-Baseline records the latest and highest value by USUBJID, PARAMCD, AVISIT, and ATPT.\n\nadvs &lt;- restrict_derivation(\n  advs,\n  derivation = derive_var_extreme_flag,\n  args = params(\n    new_var = ANL01FL,\n    by_vars = exprs(STUDYID, USUBJID, PARAMCD, AVISIT, ATPT, DTYPE),\n    order = exprs(ADT, AVAL),\n    mode = \"last\", # Determines of the first or last observation is flagged - As seen while deriving ABLFL\n    # Below arguments are default values and not necessary to add in our case\n    true_value = \"Y\"\n  ),\n  filter = !is.na(AVISITN) & ONTRTFL == \"Y\"\n)\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#treatmentvars",
    "href": "adam/advs.html#treatmentvars",
    "title": "ADVS",
    "section": "Assign Treatment (TRTA, TRTP)",
    "text": "Assign Treatment (TRTA, TRTP)\nTRTA and TRTP must match at least one value of the character treatment variables in ADSL (e.g., TRTxxA/TRTxxP, TRTSEQA/TRTSEQP, TRxxAGy/TRxxPGy).\nAn example of a simple implementation for a study without periods could be:\n\nadvs &lt;- advs %&gt;%\n  mutate(\n    TRTP = TRT01P,\n    TRTA = TRT01A\n  )\n\ncount(advs, TRTP, TRTA, TRT01P, TRT01A)\n\n# A tibble: 5 × 5\n  TRTP                 TRTA                 TRT01P               TRT01A        n\n  &lt;chr&gt;                &lt;chr&gt;                &lt;chr&gt;                &lt;chr&gt;     &lt;int&gt;\n1 Placebo              Placebo              Placebo              Placebo   22102\n2 Xanomeline High Dose Xanomeline High Dose Xanomeline High Dose Xanomeli… 16782\n3 Xanomeline High Dose Xanomeline Low Dose  Xanomeline High Dose Xanomeli…  1038\n4 Xanomeline Low Dose  Xanomeline Low Dose  Xanomeline Low Dose  Xanomeli… 17986\n5 &lt;NA&gt;                 &lt;NA&gt;                 &lt;NA&gt;                 &lt;NA&gt;       4100\n\n\nFor studies with periods see the “Visit and Period Variables” vignette.",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#aseq",
    "href": "adam/advs.html#aseq",
    "title": "ADVS",
    "section": "Assign ASEQ",
    "text": "Assign ASEQ\nThe {admiral} function admiral::derive_var_obs_number() can be used to derive ASEQ. An example call is:\n\nadvs &lt;- derive_var_obs_number(\n  advs,\n  new_var = ASEQ,\n  by_vars = exprs(STUDYID, USUBJID),\n  order = exprs(PARAMCD, ADT, AVISITN, VISITNUM, ATPTN, DTYPE),\n  check_type = \"error\"\n)\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#categorizationvars",
    "href": "adam/advs.html#categorizationvars",
    "title": "ADVS",
    "section": "Derive Categorization Variables (AVALCATy)",
    "text": "Derive Categorization Variables (AVALCATy)\nWe can use the admiral::derive_vars_cat() function to derive the categorization variables.\n\navalcat_lookup &lt;- exprs(\n  ~PARAMCD,  ~condition,   ~AVALCAT1, ~AVALCA1N,\n  \"HEIGHT\",  AVAL &gt; 140,   \"&gt;140 cm\",         1,\n  \"HEIGHT\", AVAL &lt;= 140, \"&lt;= 140 cm\",         2\n)\n\nadvs &lt;- advs %&gt;%\n  derive_vars_cat(\n    definition = avalcat_lookup,\n    by_vars = exprs(PARAMCD)\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#paramval",
    "href": "adam/advs.html#paramval",
    "title": "ADVS",
    "section": "Assign Parameter Level Values (PARAM, PARAMN)",
    "text": "Assign Parameter Level Values (PARAM, PARAMN)\nWhen all PARAMCD have been derived and added to the dataset, the other information from the look-up table (PARAM, PARAMN,…) should be added using admiral::derive_vars_merged() function.\nAnother way to assign parameter-level values is by using the metatools package with the {metacore} objects we created at the beginning. To use the metatools::create_var_from_codelist() function, as shown in the example below, certain prerequisites must be met. Specifically, this function relies on code/decode pairs from a {metacore} object. Therefore, these pairs must be defined in the corresponding ADaMs specifications before creating the {metacore} object.\nWe can look into the {metacore} object and see these pairs for the PARAM variable.\n\nget_control_term(metacore, variable = PARAM)\n\n# A tibble: 9 × 2\n  code   decode                  \n  &lt;chr&gt;  &lt;chr&gt;                   \n1 SYSBP  Systolic Blood Pressure \n2 DIABP  Diastolic Blood Pressure\n3 PULSE  Pulse Rate              \n4 WEIGHT Weight                  \n5 HEIGHT Height                  \n6 TEMP   Temperature             \n7 MAP    Mean Arterial Pressure  \n8 BMI    Body Mass Index (kg/m^2)\n9 BSA    Body Surface Area (m^2) \n\n\n\nadvs &lt;- advs %&gt;%\n  create_var_from_codelist(\n    metacore,\n    input_var = PARAMCD,\n    out_var = PARAM,\n    decode_to_code = FALSE # input_var is the code column of the codelist\n  ) %&gt;%\n  create_var_from_codelist(\n    metacore,\n    input_var = PARAMCD,\n    out_var = PARAMN\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/advs.html#addadsl",
    "href": "adam/advs.html#addadsl",
    "title": "ADVS",
    "section": "Add ADSL variables",
    "text": "Add ADSL variables\nIf needed, the other ADSL variables can now be added. List of ADSL variables already merged held in vector adsl_vars\n\nadvs &lt;- advs %&gt;%\n  derive_vars_merged(\n    dataset_add = select(adsl, !!!negate_vars(adsl_vars)),\n    by_vars = exprs(STUDYID, USUBJID)\n  )\n\n\n\nSample of Data",
    "crumbs": [
      "ADaM",
      "ADVS"
    ]
  },
  {
    "objectID": "adam/adsl.html",
    "href": "adam/adsl.html",
    "title": "ADSL",
    "section": "",
    "text": "This guide will show you how four pharmaverse packages, along with some from tidyverse, can be used to create an ADaM such as ADSL end-to-end, using {pharmaversesdtm} SDTM data as input.\nThe four packages used with a brief description of their purpose are as follows:\n\n{metacore}: provides harmonized metadata/specifications object.\n{metatools}: uses the provided metadata to build/enhance and check the dataset.\n{admiral}: provides the ADaM derivations. (Find functions and related variables by searching admiraldiscovery)\n{xportr}: delivers the SAS transport file (XPT) and eSub checks.\n\nIt is important to understand {metacore} objects by reading through the above linked package site, as these are fundamental to being able to use {metatools} and {xportr}. Each company may need to build a specification reader to create these objects from their source standard specification templates.",
    "crumbs": [
      "ADaM",
      "ADSL"
    ]
  },
  {
    "objectID": "adam/adsl.html#introduction",
    "href": "adam/adsl.html#introduction",
    "title": "ADSL",
    "section": "",
    "text": "This guide will show you how four pharmaverse packages, along with some from tidyverse, can be used to create an ADaM such as ADSL end-to-end, using {pharmaversesdtm} SDTM data as input.\nThe four packages used with a brief description of their purpose are as follows:\n\n{metacore}: provides harmonized metadata/specifications object.\n{metatools}: uses the provided metadata to build/enhance and check the dataset.\n{admiral}: provides the ADaM derivations. (Find functions and related variables by searching admiraldiscovery)\n{xportr}: delivers the SAS transport file (XPT) and eSub checks.\n\nIt is important to understand {metacore} objects by reading through the above linked package site, as these are fundamental to being able to use {metatools} and {xportr}. Each company may need to build a specification reader to create these objects from their source standard specification templates.",
    "crumbs": [
      "ADaM",
      "ADSL"
    ]
  },
  {
    "objectID": "adam/adsl.html#programming-flow",
    "href": "adam/adsl.html#programming-flow",
    "title": "ADSL",
    "section": "Programming Flow",
    "text": "Programming Flow\n\nLoad Data and Required pharmaverse Packages\nStart Building Derivations\nGrouping Variables\nExposure Derivations\nDerive Treatment Variables\nDerive Disposition Variables\nDerive Cause of Death\nDerive Other Grouping Variables\nApply Metadata to Create an eSub XPT and Perform Associated Checks",
    "crumbs": [
      "ADaM",
      "ADSL"
    ]
  },
  {
    "objectID": "adam/adsl.html#loaddata",
    "href": "adam/adsl.html#loaddata",
    "title": "ADSL",
    "section": "Load Data and Required pharmaverse Packages",
    "text": "Load Data and Required pharmaverse Packages\nThe first step is to load our pharmaverse packages and input data.\n\nlibrary(metacore)\nlibrary(metatools)\nlibrary(pharmaversesdtm)\nlibrary(admiral)\nlibrary(xportr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(stringr)\n\n# Read in input SDTM data\ndm &lt;- pharmaversesdtm::dm\nds &lt;- pharmaversesdtm::ds\nex &lt;- pharmaversesdtm::ex\nae &lt;- pharmaversesdtm::ae\nvs &lt;- pharmaversesdtm::vs\nsuppdm &lt;- pharmaversesdtm::suppdm\n\n# When SAS datasets are imported into R using haven::read_sas(), missing\n# character values from SAS appear as \"\" characters in R, instead of appearing\n# as NA values. Further details can be obtained via the following link:\n# https://pharmaverse.github.io/admiral/articles/admiral.html#handling-of-missing-values\ndm &lt;- convert_blanks_to_na(dm)\nds &lt;- convert_blanks_to_na(ds)\nex &lt;- convert_blanks_to_na(ex)\nae &lt;- convert_blanks_to_na(ae)\nvs &lt;- convert_blanks_to_na(vs)\nsuppdm &lt;- convert_blanks_to_na(suppdm)\n\nWhile loading our input data, we can combine the dm domain and the suppdm supplementary domain for easier use in the next steps. Using the metatools::combine_supp() function avoids the need to manually transpose and merge the supplementary dataset with the corresponding domain.\n\n# Combine Parent and Supp - very handy! ----\ndm_suppdm &lt;- combine_supp(dm, suppdm)\n\nNext we need to load the specification file in the form of a {metacore} object.\n\n# Read in metacore object\nmetacore &lt;- spec_to_metacore(\n  path = \"./metadata/safety_specs.xlsx\",\n  # All datasets are described in the same sheet\n  where_sep_sheet = FALSE\n) %&gt;%\n  select_dataset(\"ADSL\")\n\n✔ Metadata successfully imported\n\n\nℹ To use the Metacore object with metatools package, first subset a dataset\n  using `metacore::select_dataset()`\n\n\n✔ ADSL dataset successfully selected",
    "crumbs": [
      "ADaM",
      "ADSL"
    ]
  },
  {
    "objectID": "adam/adsl.html#dmvars",
    "href": "adam/adsl.html#dmvars",
    "title": "ADSL",
    "section": "Start Building Derivations",
    "text": "Start Building Derivations\nThe first derivation step we are going to do is to pull through all the columns that come directly from the SDTM datasets. In this case, all the required columns come from DM and SUPPDM, so these are the only datasets we will pass into metatools::build_from_derived(). As previously mentioned, we have combined DMand SUPPDM data for easier use. Specifically, the parameters from SUPPDM, contained within the [SUPPDM.QNAM] variable, have been transposed into separate variables. However the ADaMs specifications still reference DM and SUPPDM as the provenance of the variables. Setting ds_list = list(\"dm\" = dm_suppdm) alone does not retrieve the variables from SUPPDM. Therefore, it is necessary to call these two references separately within the metatools::build_from_derived() function, even though they ultimately point to the same combined dm_suppdm dataset.\nThe resulting dataset has all the columns combined and any columns that needed renaming between SDTM and ADaM are renamed.\n\nadsl_preds &lt;- build_from_derived(metacore,\n  ds_list = list(\"dm\" = dm_suppdm, \"suppdm\" = dm_suppdm),\n  predecessor_only = FALSE, keep = FALSE\n)\n\nNot all datasets provided. Only variables from DM, SUPPDM will be gathered.\n\n\n\n\nSample of Data\n\n\n\n\n\nGrouping Variables\nNow we have the base dataset, we can start to create some variables. There are a few options to create grouping variables and their corresponding numeric variables.\nOption 1: We can start with creating the subgroups using the admiral::derive_vars_cat() function available since {admiral} v1.2.0. This function is especially useful if more than one variable needs to be created for each condition, e.g., AGEGR1 and AGEGR1N. Additionally, one needs to be careful when considering the order of the conditions in the lookup table. The category is assigned based on the first match. That means catch-all conditions must come after specific conditions, e.g. !is.na(AGE) must come after between(AGE, 18, 64).\n\nagegr1_lookup &lt;- exprs(\n  ~condition,            ~AGEGR1, ~AGEGR1N,\n  is.na(AGE),          \"Missing\",        4,\n  AGE &lt; 18,                \"&lt;18\",        1,\n  between(AGE, 18, 64),  \"18-64\",        2,\n  !is.na(AGE),             \"&gt;64\",        3\n)\n\nadsl_cat &lt;- derive_vars_cat(\n  dataset = adsl_preds,\n  definition = agegr1_lookup\n)\n\n\n\nSample of Data\n\n\n\n\nOption 2: We can also create the subgroups using the controlled terminology, in this case AGEGR1. The metacore object holds all the metadata needed to make ADSL. Part of that metadata is the controlled terminology, which can help automate the creation of subgroups. We can look into the {metacore} object and see the controlled terminology for AGEGR1.\n\nget_control_term(metacore, variable = AGEGR1)\n\n# A tibble: 3 × 2\n  code  decode\n  &lt;chr&gt; &lt;chr&gt; \n1 &lt;18   &lt;18   \n2 18-64 18-64 \n3 &gt;64   &gt;64   \n\n\nBecause this controlled terminology is written in a fairly standard format we can automate the creation of AGEGR1. The function metatools::create_cat_var() takes in a {metacore} object, a reference variable - in this case AGE because that is the continuous variable AGEGR1 is created from, and the name of the sub-grouped variable. It will take the controlled terminology from the sub-grouped variable and group the reference variables accordingly.\n\nadsl_ct &lt;- adsl_preds %&gt;%\n  create_cat_var(metacore,\n    ref_var = AGE,\n    grp_var = AGEGR1, num_grp_var = AGEGR1N\n  )\n\n\n\nSample of Data\n\n\n\n\nOption 3: Another option to solve this subgroups task is to use custom functions.\n\nformat_agegr1 &lt;- function(age) {\n  case_when(\n    age &lt; 18 ~ \"&lt;18\",\n    between(age, 18, 64) ~ \"18-64\",\n    age &gt; 64 ~ \"&gt;64\",\n    TRUE ~ \"Missing\"\n  )\n}\n\nformat_agegr1n &lt;- function(age) {\n  case_when(\n    age &lt; 18 ~ 1,\n    between(age, 18, 64) ~ 2,\n    age &gt; 64 ~ 3,\n    TRUE ~ 4\n  )\n}\n\nadsl_cust &lt;- adsl_preds %&gt;%\n  mutate(\n    AGEGR1 = format_agegr1(AGE),\n    AGEGR1N = format_agegr1n(AGE)\n  )\n\n\n\nSample of Data\n\n\n\n\nUsing a similar philosophy we can create the numeric version of RACE using the controlled terminology stored in the {metacore} object with the metatools::create_var_from_codelist() function.\n\nadsl_ct &lt;- adsl_ct %&gt;%\n  create_var_from_codelist(\n    metacore = metacore,\n    input_var = RACE,\n    out_var = RACEN\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nExposure Derivations\nNow we have sorted out what we can easily do with controlled terminology it is time to start deriving some variables. Here you could refer directly to using the {admiral} template and vignette in practice, but for the purpose of this end-to-end ADaM vignette we will share a few exposure derivations from there. We derive the start and end of treatment (which requires dates to first be converted from DTC to DTM), the treatment start time, the treatment duration, and the safety population flag. Note that the populations flags are mainly company- or study-specific, therefore, no dedicated functions are provided, but in most cases they can easily be derived using admiral::derive_var_merged_exist_flag().\n\nex_ext &lt;- ex %&gt;%\n  derive_vars_dtm(\n    dtc = EXSTDTC,\n    new_vars_prefix = \"EXST\"\n  ) %&gt;%\n  derive_vars_dtm(\n    dtc = EXENDTC,\n    new_vars_prefix = \"EXEN\",\n    time_imputation = \"last\"\n  )\n\nThe default value of `ignore_seconds_flag` will change to \"TRUE\" in admiral\n1.4.0.\n\nadsl_raw &lt;- adsl_ct %&gt;%\n  # Treatment Start Datetime\n  derive_vars_merged(\n    dataset_add = ex_ext,\n    filter_add = (EXDOSE &gt; 0 |\n      (EXDOSE == 0 &\n        str_detect(EXTRT, \"PLACEBO\"))) & !is.na(EXSTDTM),\n    new_vars = exprs(TRTSDTM = EXSTDTM, TRTSTMF = EXSTTMF),\n    order = exprs(EXSTDTM, EXSEQ),\n    mode = \"first\",\n    by_vars = exprs(STUDYID, USUBJID)\n  ) %&gt;%\n  # Treatment End Datetime\n  derive_vars_merged(\n    dataset_add = ex_ext,\n    filter_add = (EXDOSE &gt; 0 |\n      (EXDOSE == 0 &\n        str_detect(EXTRT, \"PLACEBO\"))) & !is.na(EXENDTM),\n    new_vars = exprs(TRTEDTM = EXENDTM, TRTETMF = EXENTMF),\n    order = exprs(EXENDTM, EXSEQ),\n    mode = \"last\",\n    by_vars = exprs(STUDYID, USUBJID)\n  ) %&gt;%\n  # Treatment Start and End Date\n  derive_vars_dtm_to_dt(source_vars = exprs(TRTSDTM, TRTEDTM)) %&gt;% # Convert Datetime variables to date\n  # Treatment Start Time\n  derive_vars_dtm_to_tm(source_vars = exprs(TRTSDTM)) %&gt;%\n  # Treatment Duration\n  derive_var_trtdurd() %&gt;%\n  # Safety Population Flag\n  derive_var_merged_exist_flag(\n    dataset_add = ex,\n    by_vars = exprs(STUDYID, USUBJID),\n    new_var = SAFFL,\n    false_value = \"N\",\n    missing_value = \"N\",\n    condition = (EXDOSE &gt; 0 | (EXDOSE == 0 & str_detect(EXTRT, \"PLACEBO\")))\n  )\n\n\n\nSample of Data\n\n\n\n\nThis call returns the original data frame with the corresponding treatment variables added, such as TRTSDTM, TRTSTMF, TRTEDTM, TRTETMF, TRTDURD, etc., as well as the Safety Population Flag SAFFL. Exposure observations with incomplete date and zero doses of non placebo treatments are ignored. Missing time parts are imputed as first or last for start and end date respectively.\n\n\nDerive Treatment Variables\nThe mapping of the treatment variables is left to the ADaM programmer. An example mapping for a study without periods may be:\n\nadsl &lt;- adsl_raw %&gt;%\n  mutate(\n    TRT01P = if_else(ARM %in% c(\"Screen Failure\", \"Not Assigned\", \"Not Treated\"), \"No Treatment\", ARM),\n    TRT01A = if_else(ACTARM %in% c(\"Screen Failure\", \"Not Assigned\", \"Not Treated\"), \"No Treatment\", ACTARM)\n  )\n\n\n\nSample of Data\n\n\n\n\nFor studies with periods see the “Visit and Period Variables” vignette.\nThe corresponding numeric variables can be derived using the metatools package with the {metacore} objects that we created at the very beginning. The function metatools::create_var_from_codelist() is used in below example.\n\nadsl &lt;- adsl %&gt;%\n  create_var_from_codelist(metacore, input_var = TRT01P, out_var = TRT01PN) %&gt;%\n  create_var_from_codelist(metacore, input_var = TRT01A, out_var = TRT01AN)\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive Disposition Variables\nThe functions admiral::derive_vars_dt() and admiral::derive_vars_merged() can be used to derive disposition dates. First the character disposition date (DS.DSSTDTC) is converted to a numeric date (DSSTDT) calling admiral::derive_vars_dt(). The DS dataset is extended by the DSSTDT variable because the date is required by other derivations, e.g., RANDDT as well. Then the relevant disposition date is selected by adjusting the filter_add argument.\nTo add the End of Study date (EOSDT) to the input dataset, a call could be:\n\n# Convert character date to numeric date without imputation\nds_ext &lt;- derive_vars_dt(\n  ds,\n  dtc = DSSTDTC,\n  new_vars_prefix = \"DSST\"\n)\n\nadsl &lt;- adsl %&gt;%\n  derive_vars_merged(\n    dataset_add = ds_ext,\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(EOSDT = DSSTDT),\n    filter_add = DSCAT == \"DISPOSITION EVENT\" & DSDECOD != \"SCREEN FAILURE\"\n  )\n\nThe admiral::derive_vars_dt() function allows to impute partial dates as well. If imputation is needed and missing days are to be imputed to the first of the month and missing months to the first month of the year, set highest_imputation = \"M\".\nThe End of Study status (EOSSTT) based on DSCAT and DSDECOD from DS can be derived using the function admiral::derive_vars_merged(). The relevant observations are selected by adjusting the filter_add argument. A function mapping DSDECOD values to EOSSTT values can be defined and used in the new_vars argument. The mapping for the call below is\n\n\"COMPLETED\" if DSDECOD == \"COMPLETED\"\nNA_character_ if DSDECOD is \"SCREEN FAILURE\"\n\"DISCONTINUED\" otherwise\n\nExample function format_eosstt():\n\nformat_eosstt &lt;- function(x) {\n  case_when(\n    x %in% c(\"COMPLETED\") ~ \"COMPLETED\",\n    x %in% c(\"SCREEN FAILURE\") ~ NA_character_,\n    TRUE ~ \"DISCONTINUED\"\n  )\n}\n\nThe customized mapping function format_eosstt() can now be passed to the main function. For subjects without a disposition event the end of study status is set to \"ONGOING\" by specifying the missing_values argument.\n\nadsl &lt;- adsl %&gt;%\n  derive_vars_merged(\n    dataset_add = ds,\n    by_vars = exprs(STUDYID, USUBJID),\n    filter_add = DSCAT == \"DISPOSITION EVENT\",\n    new_vars = exprs(EOSSTT = format_eosstt(DSDECOD)),\n    missing_values = exprs(EOSSTT = \"ONGOING\")\n  )\n\n\n\nSample of Data\n\n\n\n\nIf the derivation must be changed, the user can create his/her own function to map DSDECOD to a suitable EOSSTT value.\nThe Imputed Death Date (DTHDT) can be derived using the admiral::derive_vars_dt() function.\n\nadsl &lt;- adsl %&gt;%\n  derive_vars_dt(\n    new_vars_prefix = \"DTH\",\n    dtc = DTHDTC,\n    highest_imputation = \"M\",\n    date_imputation = \"first\"\n  )\n\n\n\nSample of Data\n\n\n\n\nFurther dates such as Randomization Date (RANDDT), Screen fail date (SCRFDT), and Last Retrieval Date (FRVDT), can also be derived using admiral::derive_vars_merged() since these are selected dates based on filters and merged back to the original dataset.\n\nadsl &lt;- adsl %&gt;%\n  derive_vars_merged(\n    dataset_add = ds_ext,\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(RANDDT = DSSTDT),\n    filter_add = DSDECOD == \"RANDOMIZED\",\n  ) %&gt;%\n  derive_vars_merged(\n    dataset_add = ds_ext,\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(SCRFDT = DSSTDT),\n    filter_add = DSCAT == \"DISPOSITION EVENT\" & DSDECOD == \"SCREEN FAILURE\"\n  ) %&gt;%\n  derive_vars_merged(\n    dataset_add = ds_ext,\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(FRVDT = DSSTDT),\n    filter_add = DSCAT == \"OTHER EVENT\" & DSDECOD == \"FINAL RETRIEVAL VISIT\"\n  )\n\n\n\nSample of Data\n\n\n\n\nThe function admiral::derive_vars_duration() can now be used to derive duration relative to death like the Relative Day of Death (DTHADY) or the numbers of days from last dose to death (LDDTHELD).\n\nadsl &lt;- adsl %&gt;%\n  derive_vars_duration(\n    new_var = DTHADY,\n    start_date = TRTSDT,\n    end_date = DTHDT\n  ) %&gt;%\n  derive_vars_duration(\n    new_var = LDDTHELD,\n    start_date = TRTEDT,\n    end_date = DTHDT,\n    add_one = FALSE\n  )\n\n\n\nSample of Data\n\n\n\n\nHaving the Randomization Date added to the dataset also allows to derive a Population Flag. Randomized Population Flag (RANDFL) can be computed using a customized function.\n\nassign_randfl &lt;- function(x) {\n  if_else(!is.na(x), \"Y\", NA_character_)\n}\n\nadsl &lt;- adsl %&gt;%\n  mutate(\n    RANDFL = assign_randfl(RANDDT)\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive Cause of Death\nThe cause of death (DTHCAUS) can be derived using the function admiral::derive_vars_extreme_event().\nSince the cause of death could be collected/mapped in different domains (e.g. DS, AE, DD), it is important the user specifies the right source(s) to derive the cause of death from.\nFor example, if the date of death is collected in the AE form when the AE is Fatal, the cause of death would be set to the preferred term (AEDECOD) of that Fatal AE, while if the date of death is collected in the DS form, the cause of death would be set to the disposition term (DSTERM). To achieve this, the event() objects within derive_vars_extreme_event() must be specified and defined such that they fit the study requirement. The function also offers the option to add some traceability variables (e.g. DTHDOM would store the domain where the date of death is collected, and DTHSEQcould also be added to store the xxSEQ value of that domain - but let’s keep it simple with DTHDOM only). The traceability variables should be added to the event() calls and included in the new_vars parameter of derive_vars_extreme_event().\n\nadsl &lt;- adsl %&gt;%\n  derive_vars_extreme_event(\n    by_vars = exprs(STUDYID, USUBJID),\n    events = list(\n      event(\n        dataset_name = \"ae\",\n        condition = AEOUT == \"FATAL\",\n        set_values_to = exprs(DTHCAUS = AEDECOD, DTHDOM = \"AE\"),\n      ),\n      event(\n        dataset_name = \"ds\",\n        condition = DSDECOD == \"DEATH\" & grepl(\"DEATH DUE TO\", DSTERM),\n        set_values_to = exprs(DTHCAUS = DSTERM, DTHDOM = \"DS\"),\n      )\n    ),\n    source_datasets = list(ae = ae, ds = ds),\n    tmp_event_nr_var = event_nr,\n    order = exprs(event_nr),\n    mode = \"first\",\n    new_vars = exprs(DTHCAUS, DTHDOM)\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive Other Grouping Variables\nFollowing the derivation of DTHCAUS and related traceability variables, it is then possible to derive grouping variables such as death categories (DTHCGRx), region categories (REGIONx), and race categories (RACEx). As previously seen with AGEGR1, the admiral::derive_vars_cat() function available from version 1.2.0 can create such groups.\n\nregion1_lookup &lt;- exprs(\n  ~condition,                              ~REGION1, ~REGION1N,\n  COUNTRY %in% c(\"CAN\", \"USA\"),     \"North America\",         1,\n  !is.na(COUNTRY),              \"Rest of the World\",         2,\n  is.na(COUNTRY),                         \"Missing\",         3\n)\n\nracegr1_lookup &lt;- exprs(\n  ~condition, ~RACEGR1, ~RACEGR1N,\n  RACE %in% c(\"WHITE\"), \"White\", 1,\n  RACE != \"WHITE\", \"Non-white\", 2,\n  is.na(RACE), \"Missing\", 3\n)\n\ndthcgr1_lookup &lt;- exprs(\n  ~condition,                                                                                 ~DTHCGR1, ~DTHCGR1N,\n  DTHDOM == \"AE\",                                                                      \"ADVERSE EVENT\",         1,\n  !is.na(DTHDOM) & str_detect(DTHCAUS, \"(PROGRESSIVE DISEASE|DISEASE RELAPSE)\"), \"PROGRESSIVE DISEASE\",         2,\n  !is.na(DTHDOM) & !is.na(DTHCAUS),                                                            \"OTHER\",         3,\n  is.na(DTHDOM),                                                                         NA_character_,        NA\n)\n\n\nadsl &lt;- adsl %&gt;%\n  derive_vars_cat(\n    definition = region1_lookup\n  ) %&gt;%\n  derive_vars_cat(\n    definition = racegr1_lookup\n  ) %&gt;%\n  derive_vars_cat(\n    definition = dthcgr1_lookup\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nSample of Data\n\n\n\n\n\n\nApply Metadata to Create an eSub XPT and Perform Associated Checks\nNow we have all the variables defined we can run some checks before applying the necessary formatting. The top four functions performing checks and sorting/ordering come from {metatools}, whereas the others focused around applying attributes to prepare for XPT come from {xportr}. At the end you can produce the XPT file calling xportr::xportr_write().\n\ndir &lt;- tempdir() # Specify the directory for saving the XPT file\n\nadsl %&gt;%\n  check_variables(metacore) %&gt;% # Check all variables specified are present and no more\n  check_ct_data(metacore, na_acceptable = TRUE) %&gt;% # Checks all variables with CT only contain values within the CT\n  order_cols(metacore) %&gt;% # Orders the columns according to the spec\n  sort_by_key(metacore) %&gt;% # Sorts the rows by the sort keys\n  xportr_type(metacore, domain = \"ADSL\") %&gt;% # Coerce variable type to match spec\n  xportr_length(metacore) %&gt;% # Assigns SAS length from a variable level metadata\n  xportr_label(metacore) %&gt;% # Assigns variable label from metacore specifications\n  xportr_df_label(metacore) %&gt;% # Assigns dataset label from metacore specifications\n  xportr_write(file.path(dir, \"adsl.xpt\"), metadata = metacore, domain = \"ADSL\")",
    "crumbs": [
      "ADaM",
      "ADSL"
    ]
  },
  {
    "objectID": "adam/adppk.html",
    "href": "adam/adppk.html",
    "title": "ADPPK",
    "section": "",
    "text": "The Population PK Analysis Data (ADPPK) follows the CDISC Implementation Guide (https://www.cdisc.org/standards/foundational/adam/basic-data-structure-adam-poppk-implementation-guide-v1-0). Population PK models generally make use of nonlinear mixed effects models that require numeric variables. The data used in the models will include both dosing and concentration records, relative time variables, and numeric covariate variables. A DV or dependent variable is often expected. For more details see the {admiral} vignette.",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  },
  {
    "objectID": "adam/adppk.html#first-load-packages",
    "href": "adam/adppk.html#first-load-packages",
    "title": "ADPPK",
    "section": "First Load Packages",
    "text": "First Load Packages\nFirst we will load the packages required for our project. We will use {admiral} for the creation of analysis data. {admiral} requires {dplyr}, {lubridate} and {stringr}. Find other {admiral} functions and related variables by searching admiraldiscovery. We will use {metacore} and {metatools} to store and manipulate metadata from our specifications. We will use {xportr} to perform checks on the final data and export to a transport file.\nThe source SDTM data will come from the CDISC pilot study data stored in {pharmaversesdtm}.\n\n# Load Packages\nlibrary(admiral)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(stringr)\nlibrary(metacore)\nlibrary(metatools)\nlibrary(xportr)\nlibrary(readr)\nlibrary(pharmaversesdtm)\nlibrary(pharmaverseadam)",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  },
  {
    "objectID": "adam/adppk.html#next-load-specifications-for-metacore",
    "href": "adam/adppk.html#next-load-specifications-for-metacore",
    "title": "ADPPK",
    "section": "Next Load Specifications for Metacore",
    "text": "Next Load Specifications for Metacore\nWe have saved our specifications in an Excel file and will load them into {metacore} with the metacore::spec_to_metacore() function.\n\n# ---- Load Specs for Metacore ----\nmetacore &lt;- spec_to_metacore(\"./metadata/pk_spec.xlsx\") %&gt;%\n  select_dataset(\"ADPPK\")",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  },
  {
    "objectID": "adam/adppk.html#load-source-datasets",
    "href": "adam/adppk.html#load-source-datasets",
    "title": "ADPPK",
    "section": "Load Source Datasets",
    "text": "Load Source Datasets\nWe will load are SDTM data from {pharmaversesdtm}. The main components of this will be exposure data from EX and pharmacokinetic concentration data from PC. We will use ADSL for baseline characteristics and we will derive additional baselines from vital signs VS and laboratory data LB.\n\n# ---- Load source datasets ----\n# Load PC, EX, VS, LB and ADSL\n\nex &lt;- pharmaversesdtm::ex\npc &lt;- pharmaversesdtm::pc\nvs &lt;- pharmaversesdtm::vs\nlb &lt;- pharmaversesdtm::lb\n\nadsl &lt;- pharmaverseadam::adsl\n\nex &lt;- convert_blanks_to_na(ex)\npc &lt;- convert_blanks_to_na(pc)\nvs &lt;- convert_blanks_to_na(vs)\nlb &lt;- convert_blanks_to_na(lb)",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  },
  {
    "objectID": "adam/adppk.html#derivations",
    "href": "adam/adppk.html#derivations",
    "title": "ADPPK",
    "section": "Derivations",
    "text": "Derivations\n\nDerive PC Dates\nHere we use {admiral} functions for working with dates and we will also create a nominal time from first dose NFRLT for PC data based on PCTPTNUM.\n\n# ---- Derivations ----\n\n# Get list of ADSL vars required for derivations\nadsl_vars &lt;- exprs(TRTSDT, TRTSDTM, TRT01P, TRT01A)\n\npc_dates &lt;- pc %&gt;%\n  # Join ADSL with PC (need TRTSDT for ADY derivation)\n  derive_vars_merged(\n    dataset_add = adsl,\n    new_vars = adsl_vars,\n    by_vars = exprs(STUDYID, USUBJID)\n  ) %&gt;%\n  # Derive analysis date/time\n  # Impute missing time to 00:00:00\n  derive_vars_dtm(\n    new_vars_prefix = \"A\",\n    dtc = PCDTC,\n    time_imputation = \"00:00:00\"\n  ) %&gt;%\n  # Derive dates and times from date/times\n  derive_vars_dtm_to_dt(exprs(ADTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(ADTM)) %&gt;%\n  # Derive event ID and nominal relative time from first dose (NFRLT)\n  mutate(\n    EVID = 0,\n    DRUG = PCTEST,\n    NFRLT = if_else(PCTPTNUM &lt; 0, 0, PCTPTNUM), .after = USUBJID\n  )\n\nThe default value of `ignore_seconds_flag` will change to \"TRUE\" in admiral\n1.4.0.\n\n\n\n\nSample of Data\n\n\n\n\n\n\nGet Dosing Information\nHere we also create nominal time from first dose NFRLT for EX data based on VISITDY.\n\n# ---- Get dosing information ----\n\nex_dates &lt;- ex %&gt;%\n  derive_vars_merged(\n    dataset_add = adsl,\n    new_vars = adsl_vars,\n    by_vars = exprs(STUDYID, USUBJID)\n  ) %&gt;%\n  # Keep records with nonzero dose\n  filter(EXDOSE &gt; 0) %&gt;%\n  # Add time and set missing end date to start date\n  # Impute missing time to 00:00:00\n  # Note all times are missing for dosing records in this example data\n  # Derive Analysis Start and End Dates\n  derive_vars_dtm(\n    new_vars_prefix = \"AST\",\n    dtc = EXSTDTC,\n    time_imputation = \"00:00:00\"\n  ) %&gt;%\n  derive_vars_dtm(\n    new_vars_prefix = \"AEN\",\n    dtc = EXENDTC,\n    time_imputation = \"00:00:00\"\n  ) %&gt;%\n  # Derive event ID and nominal relative time from first dose (NFRLT)\n  mutate(\n    EVID = 1,\n    NFRLT = case_when(\n      VISITDY == 1 ~ 0,\n      TRUE ~ 24 * VISITDY\n    )\n  ) %&gt;%\n  # Set missing end dates to start date\n  mutate(AENDTM = case_when(\n    is.na(AENDTM) ~ ASTDTM,\n    TRUE ~ AENDTM\n  )) %&gt;%\n  # Derive dates from date/times\n  derive_vars_dtm_to_dt(exprs(ASTDTM)) %&gt;%\n  derive_vars_dtm_to_dt(exprs(AENDTM))\n\n\n\nSample of Data\n\n\n\n\n\n\nExpand Dosing Records\nSince there is a start date and end date for dosing records we need to expand the dosing records between the start date and end date using the function admiral::create_single_dose_dataset().\n\nex_exp &lt;- ex_dates %&gt;%\n  create_single_dose_dataset(\n    dose_freq = EXDOSFRQ,\n    start_date = ASTDT,\n    start_datetime = ASTDTM,\n    end_date = AENDT,\n    end_datetime = AENDTM,\n    nominal_time = NFRLT,\n    lookup_table = dose_freq_lookup,\n    lookup_column = CDISC_VALUE,\n    keep_source_vars = exprs(\n      STUDYID, USUBJID, EVID, EXDOSFRQ, EXDOSFRM,\n      NFRLT, EXDOSE, EXDOSU, EXTRT, ASTDT, ASTDTM, AENDT, AENDTM,\n      VISIT, VISITNUM, VISITDY,\n      TRT01A, TRT01P, DOMAIN, EXSEQ, !!!adsl_vars\n    )\n  ) %&gt;%\n  # Derive AVISIT based on nominal relative time\n  # Derive AVISITN to nominal time in whole days using integer division\n  # Define AVISIT based on nominal day\n  mutate(\n    AVISITN = NFRLT %/% 24 + 1,\n    AVISIT = paste(\"Day\", AVISITN),\n    ADTM = ASTDTM,\n    DRUG = EXTRT\n  ) %&gt;%\n  # Derive dates and times from datetimes\n  derive_vars_dtm_to_dt(exprs(ADTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(ADTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(ASTDTM)) %&gt;%\n  derive_vars_dtm_to_tm(exprs(AENDTM))\n\n\n\nSample of Data\n\n\n\n\n\n\nFind First Dose\nIn this section we will find the first dose for each subject and drug.\n\n# ---- Find first dose per treatment per subject ----\n# ---- Join with ADPPK data and keep only subjects with dosing ----\n\nadppk_first_dose &lt;- pc_dates %&gt;%\n  derive_vars_merged(\n    dataset_add = ex_exp,\n    filter_add = (!is.na(ADTM)),\n    new_vars = exprs(FANLDTM = ADTM, EXDOSE_first = EXDOSE),\n    order = exprs(ADTM, EXSEQ),\n    mode = \"first\",\n    by_vars = exprs(STUDYID, USUBJID, DRUG)\n  ) %&gt;%\n  filter(!is.na(FANLDTM)) %&gt;%\n  # Derive AVISIT based on nominal relative time\n  # Derive AVISITN to nominal time in whole days using integer division\n  # Define AVISIT based on nominal day\n  mutate(\n    AVISITN = NFRLT %/% 24 + 1,\n    AVISIT = paste(\"Day\", AVISITN),\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nFind Previous Dose\nFor ADPPK we will find the previous dose with respect to actual time and nominal time.\n\n# ---- Find previous dose  ----\n\nadppk_prev &lt;- adppk_first_dose %&gt;%\n  derive_vars_joined(\n    dataset_add = ex_exp,\n    by_vars = exprs(USUBJID),\n    order = exprs(ADTM),\n    new_vars = exprs(\n      ADTM_prev = ADTM, EXDOSE_prev = EXDOSE, AVISIT_prev = AVISIT,\n      AENDTM_prev = AENDTM\n    ),\n    join_vars = exprs(ADTM),\n    join_type = \"all\",\n    filter_add = NULL,\n    filter_join = ADTM &gt; ADTM.join,\n    mode = \"last\",\n    check_type = \"none\"\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nFind Previous Nominal Dose\n\nadppk_nom_prev &lt;- adppk_prev %&gt;%\n  derive_vars_joined(\n    dataset_add = ex_exp,\n    by_vars = exprs(USUBJID),\n    order = exprs(NFRLT),\n    new_vars = exprs(NFRLT_prev = NFRLT),\n    join_vars = exprs(NFRLT),\n    join_type = \"all\",\n    filter_add = NULL,\n    filter_join = NFRLT &gt; NFRLT.join,\n    mode = \"last\",\n    check_type = \"none\"\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nCombine PC and EX Data\nHere we combine PC and EX records. We will derive the relative time variables AFRLT (Actual Relative Time from First Dose), APRLT (Actual Relative Time from Previous Dose), and NPRLT (Nominal Relative Time from Previous Dose).\n\nadppk_aprlt &lt;- bind_rows(adppk_nom_prev, ex_exp) %&gt;%\n  group_by(USUBJID, DRUG) %&gt;%\n  mutate(\n    FANLDTM = min(FANLDTM, na.rm = TRUE),\n    min_NFRLT = min(NFRLT, na.rm = TRUE),\n    maxdate = max(ADT[EVID == 0], na.rm = TRUE), .after = USUBJID\n  ) %&gt;%\n  arrange(USUBJID, ADTM) %&gt;%\n  ungroup() %&gt;%\n  filter(ADT &lt;= maxdate) %&gt;%\n  # Derive Actual Relative Time from First Dose (AFRLT)\n  derive_vars_duration(\n    new_var = AFRLT,\n    start_date = FANLDTM,\n    end_date = ADTM,\n    out_unit = \"hours\",\n    floor_in = FALSE,\n    add_one = FALSE\n  ) %&gt;%\n  # Derive Actual Relative Time from Reference Dose (APRLT)\n  derive_vars_duration(\n    new_var = APRLT,\n    start_date = ADTM_prev,\n    end_date = ADTM,\n    out_unit = \"hours\",\n    floor_in = FALSE,\n    add_one = FALSE\n  ) %&gt;%\n  # Derive APRLT\n  mutate(\n    APRLT = case_when(\n      EVID == 1 ~ 0,\n      is.na(APRLT) ~ AFRLT,\n      TRUE ~ APRLT\n    ),\n    NPRLT = case_when(\n      EVID == 1 ~ 0,\n      is.na(NFRLT_prev) ~ NFRLT - min_NFRLT,\n      TRUE ~ NFRLT - NFRLT_prev\n    )\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nDerive Analysis Variables\nThe expected analysis variable for ADPPK is DV or dependent variable. For this example DV is set to the numeric concentration value PCSTRESN. We will also include AVAL equivalent to DV for consistency with CDISC ADaM standards. MDV missing dependent variable will also be included.\n\n# ---- Derive Analysis Variables ----\n# Derive actual dose DOSEA and planned dose DOSEP,\n# Derive AVAL and DV\n\nadppk_aval &lt;- adppk_aprlt %&gt;%\n  mutate(\n    # Derive Actual Dose\n    DOSEA = case_when(\n      EVID == 1 ~ EXDOSE,\n      is.na(EXDOSE_prev) ~ EXDOSE_first,\n      TRUE ~ EXDOSE_prev\n    ),\n    # Derive Planned Dose\n    DOSEP = case_when(\n      TRT01P == \"Xanomeline High Dose\" ~ 81,\n      TRT01P == \"Xanomeline Low Dose\" ~ 54,\n      TRT01P == \"Placebo\" ~ 0\n    ),\n    # Derive PARAMCD\n    PARAMCD = case_when(\n      EVID == 1 ~ \"DOSE\",\n      TRUE ~ PCTESTCD\n    ),\n    ALLOQ = PCLLOQ,\n    # Derive CMT\n    CMT = case_when(\n      EVID == 1 ~ 1,\n      PCSPEC == \"PLASMA\" ~ 2,\n      TRUE ~ 3\n    ),\n    # Derive BLQFL/BLQFN\n    BLQFL = case_when(\n      PCSTRESC == \"&lt;BLQ\" ~ \"Y\",\n      TRUE ~ \"N\"\n    ),\n    BLQFN = case_when(\n      PCSTRESC == \"&lt;BLQ\" ~ 1,\n      TRUE ~ 0\n    ),\n    AMT = case_when(\n      EVID == 1 ~ EXDOSE,\n      TRUE ~ NA_real_\n    ),\n    # Derive DV and AVAL\n    DV = PCSTRESN,\n    DVID = PCTESTCD,\n    AVAL = DV,\n    DVL = case_when(\n      DV != 0 ~ log(DV),\n      TRUE ~ NA_real_\n    ),\n    # Derive MDV\n    MDV = case_when(\n      EVID == 1 ~ 1,\n      is.na(DV) ~ 1,\n      TRUE ~ 0\n    ),\n    AVALU = case_when(\n      EVID == 1 ~ NA_character_,\n      TRUE ~ PCSTRESU\n    ),\n    RLTU = \"h\",\n    USTRESC = PCSTRESC,\n    UDTC = format_ISO8601(ADTM),\n    II = if_else(EVID == 1, 1, 0),\n    SS = if_else(EVID == 1, 1, 0),\n    ADDL = 0,\n    OCC = 1,\n  )\n\n\n\nSample of Data\n\n\n\n\n\n\nAdd ASEQ\n\n# ---- Add ASEQ ----\n\nadppk_aseq &lt;- adppk_aval %&gt;%\n  # Calculate ASEQ\n  derive_var_obs_number(\n    new_var = ASEQ,\n    by_vars = exprs(STUDYID, USUBJID),\n    order = exprs(AFRLT, EVID, CMT),\n    check_type = \"error\"\n  ) %&gt;%\n  mutate(\n    PROJID = DRUG,\n    PROJIDN = 1,\n    PART = 1,\n  )",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  },
  {
    "objectID": "adam/adppk.html#derive-covariates-using-metatools",
    "href": "adam/adppk.html#derive-covariates-using-metatools",
    "title": "ADPPK",
    "section": "Derive Covariates Using {metatools}",
    "text": "Derive Covariates Using {metatools}\nIn this step we will create our numeric covariates using the metatools::create_var_from_codelist() function.\n\n#---- Derive Covariates ----\n# Include numeric values for STUDYIDN, USUBJIDN, SEXN, RACEN etc.\n\ncovar &lt;- adsl %&gt;%\n  create_var_from_codelist(metacore, input_var = STUDYID, out_var = STUDYIDN) %&gt;%\n  create_var_from_codelist(metacore, input_var = SEX, out_var = SEXN) %&gt;%\n  create_var_from_codelist(metacore, input_var = RACE, out_var = RACEN) %&gt;%\n  create_var_from_codelist(metacore, input_var = ETHNIC, out_var = AETHNIC) %&gt;%\n  create_var_from_codelist(metacore, input_var = AETHNIC, out_var = AETHNICN) %&gt;%\n  create_var_from_codelist(metacore, input_var = ARMCD, out_var = COHORT) %&gt;%\n  create_var_from_codelist(metacore, input_var = ARMCD, out_var = COHORTC) %&gt;%\n  create_var_from_codelist(metacore, input_var = COUNTRY, out_var = COUNTRYN) %&gt;%\n  create_var_from_codelist(metacore, input_var = COUNTRY, out_var = COUNTRYL) %&gt;%\n  mutate(\n    STUDYIDN = as.numeric(word(USUBJID, 1, sep = fixed(\"-\"))),\n    SITEIDN = as.numeric(word(USUBJID, 2, sep = fixed(\"-\"))),\n    USUBJIDN = as.numeric(word(USUBJID, 3, sep = fixed(\"-\"))),\n    SUBJIDN = as.numeric(SUBJID),\n    ROUTE = unique(ex$EXROUTE),\n    FORM = unique(ex$EXDOSFRM),\n    REGION1 = COUNTRY,\n    REGION1N = COUNTRYN,\n    SUBJTYPC = \"Volunteer\",\n  ) %&gt;%\n  create_var_from_codelist(metacore, input_var = FORM, out_var = FORMN) %&gt;%\n  create_var_from_codelist(metacore, input_var = ROUTE, out_var = ROUTEN) %&gt;%\n  create_var_from_codelist(metacore, input_var = SUBJTYPC, out_var = SUBJTYP)\n\n\n\nSample of Data\n\n\n\n\n\nDerive Additional Baselines\nNext we add additional baselines from vital signs and laboratory data.\n\nlabsbl &lt;- lb %&gt;%\n  filter(LBBLFL == \"Y\" & LBTESTCD %in% c(\"CREAT\", \"ALT\", \"AST\", \"BILI\")) %&gt;%\n  mutate(LBTESTCDB = paste0(LBTESTCD, \"BL\")) %&gt;%\n  select(STUDYID, USUBJID, LBTESTCDB, LBSTRESN)\n\ncovar_vslb &lt;- covar %&gt;%\n  derive_vars_merged(\n    dataset_add = vs,\n    filter_add = VSTESTCD == \"HEIGHT\",\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(HTBL = VSSTRESN)\n  ) %&gt;%\n  derive_vars_merged(\n    dataset_add = vs,\n    filter_add = VSTESTCD == \"WEIGHT\" & VSBLFL == \"Y\",\n    by_vars = exprs(STUDYID, USUBJID),\n    new_vars = exprs(WTBL = VSSTRESN)\n  ) %&gt;%\n  derive_vars_transposed(\n    dataset_merge = labsbl,\n    by_vars = exprs(STUDYID, USUBJID),\n    key_var = LBTESTCDB,\n    value_var = LBSTRESN\n  ) %&gt;%\n  mutate(\n    BMIBL = compute_bmi(height = HTBL, weight = WTBL),\n    BSABL = compute_bsa(\n      height = HTBL,\n      weight = HTBL,\n      method = \"Mosteller\"\n    ),\n    CRCLBL = compute_egfr(\n      creat = CREATBL, creatu = \"SI\", age = AGE, weight = WTBL, sex = SEX,\n      method = \"CRCL\"\n    ),\n    EGFRBL = compute_egfr(\n      creat = CREATBL, creatu = \"SI\", age = AGE, weight = WTBL, sex = SEX,\n      method = \"CKD-EPI\"\n    )\n  ) %&gt;%\n  rename(TBILBL = BILIBL)\n\n\n\nSample of Data\n\n\n\n\n\n\nCombine with Covariates\nWe combine our covariates with the rest of the data\n\n# Combine covariates with APPPK data\n\nadppk_prefinal &lt;- adppk_aseq %&gt;%\n  derive_vars_merged(\n    dataset_add = select(covar_vslb, !!!negate_vars(adsl_vars)),\n    by_vars = exprs(STUDYID, USUBJID)\n  ) %&gt;%\n  arrange(STUDYIDN, USUBJIDN, AFRLT, EVID) %&gt;%\n  # Add RECSEQ\n  # Exclude records if needed\n  mutate(\n    RECSEQ = row_number(),\n    EXCLFCOM = \"None\"\n  ) %&gt;%\n  create_var_from_codelist(metacore, input_var = DVID, out_var = DVIDN) %&gt;%\n  create_var_from_codelist(metacore, input_var = EXCLFCOM, out_var = EXCLF)\n\nWarning: In `create_var_from_codelist()`: The following value present in the input\ndataset is not present in the codelist: NA",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  },
  {
    "objectID": "adam/adppk.html#check-data-with-metacore-and-metatools",
    "href": "adam/adppk.html#check-data-with-metacore-and-metatools",
    "title": "ADPPK",
    "section": "Check Data With metacore and metatools",
    "text": "Check Data With metacore and metatools\nWe use {metacore} objects with {metatools} functions to perform a number of checks on the data. We will drop variables not in the specs and make sure all the variables from the specs are included.\n\nadppk &lt;- adppk_prefinal %&gt;%\n  drop_unspec_vars(metacore) %&gt;% # Drop unspecified variables from specs\n  check_variables(metacore) %&gt;% # Check all variables specified are present and no more\n  check_ct_data(metacore) %&gt;% # Checks all variables with CT only contain values within the CT\n  order_cols(metacore) %&gt;% # Orders the columns according to the spec\n  sort_by_key(metacore) # Sorts the rows by the sort keys",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  },
  {
    "objectID": "adam/adppk.html#apply-labels-and-formats-with-xportr",
    "href": "adam/adppk.html#apply-labels-and-formats-with-xportr",
    "title": "ADPPK",
    "section": "Apply Labels and Formats with xportr",
    "text": "Apply Labels and Formats with xportr\nUsing {xportr} we check variable type, assign variable length, add variable labels, add variable formats, and save a transport file with xportr::xportr_write().\n\ndir &lt;- tempdir() # Change to whichever directory you want to save the dataset in\n\nadppk_xpt &lt;- adppk %&gt;%\n  xportr_type(metacore, domain = \"ADPPK\") %&gt;% # Coerce variable type to match spec\n  xportr_length(metacore) %&gt;% # Assigns SAS length from a variable level metadata\n  xportr_label(metacore) %&gt;% # Assigns variable label from metacore specifications\n  xportr_format(metacore) %&gt;% # Assigns variable format from metacore specifications\n  xportr_df_label(metacore) %&gt;% # Assigns dataset label from metacore specifications\n  xportr_write(file.path(dir, \"adppk.xpt\")) # Write xpt v5 transport file",
    "crumbs": [
      "ADaM",
      "ADPPK"
    ]
  }
]